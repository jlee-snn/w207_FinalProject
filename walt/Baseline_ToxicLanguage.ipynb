{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Submission: Toxic Language Classification \n",
    "**w207 Spring 2018 - Final Project Baseline**\n",
    "\n",
    "**Team: Paul, Walt, Yisang, Joe**\n",
    "\n",
    "\n",
    "\n",
    "### Project Description \n",
    "\n",
    "Our challenge is to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate.  The toxic language data set is sourced from Wikipedia and available as a public kaggle data set. \n",
    "\n",
    "Our goal is to use various machine learning techniques used in class to develop high quality ML models and pipelines.  \n",
    "\n",
    "1. Exercise and build upon concepts covered in class and test out at least 3 kinds of supervised models:\n",
    "    a. Regression (LASSO, Logistic)\n",
    "    b. Trees (RF, XGBoost)\n",
    "    c. DeepLearning (Tensorflow)\n",
    "2. Using stacking/ensembling methods for improving prediction metrics (K-Means, anomaly detection)\n",
    "3. Using unsupervised methods for feature engineering/selection\n",
    "\n",
    "For the baseline proposal, this file contains a first pass run through from data preprocessing to model evaluation using a regression model pipeline. \n",
    "\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burgew/Library/Python/2.7/lib/python/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/burgew/Library/Python/2.7/lib/python/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#scipy imports\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import bokeh\n",
    "#! pip install bokeh\n",
    "\n",
    "#General imports\n",
    "import pprint\n",
    "\n",
    "# target classes\n",
    "target_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training observations: 159571\n",
      "training data shape: (111968,)\n",
      "training label shape: (111968, 6)\n",
      "dev label shape: (47603, 6)\n",
      "labels names: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "# read frames localy through csv\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# Random index generator for splitting training data\n",
    "# Note: Each rerun of cell will create new splits.\n",
    "randIndexCut = np.random.rand(len(train_df)) < 0.7\n",
    "\n",
    "#S plit up data\n",
    "test_data = test_df[\"comment_text\"]\n",
    "dev_data, dev_labels = train_df[~randIndexCut][\"comment_text\"], train_df[~randIndexCut][target_names]\n",
    "train_data, train_labels = train_df[randIndexCut][\"comment_text\"], train_df[randIndexCut][target_names]\n",
    "\n",
    "print 'total training observations:', train_df.shape[0]\n",
    "print 'training data shape:', train_data.shape\n",
    "print 'training label shape:', train_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape\n",
    "print 'labels names:', target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how imblanced the label set is in order to have a better understanding with the label quality of the given data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"6016f089-37ce-4c44-8178-58dd6c86ee3e\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"6016f089-37ce-4c44-8178-58dd6c86ee3e\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"6016f089-37ce-4c44-8178-58dd6c86ee3e\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6016f089-37ce-4c44-8178-58dd6c86ee3e' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"6016f089-37ce-4c44-8178-58dd6c86ee3e\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"6016f089-37ce-4c44-8178-58dd6c86ee3e\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"6016f089-37ce-4c44-8178-58dd6c86ee3e\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6016f089-37ce-4c44-8178-58dd6c86ee3e' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"6016f089-37ce-4c44-8178-58dd6c86ee3e\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"96a6070d-12ff-48c6-99f3-0d006f3aadad\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"947efa5b-7efe-4f3c-88f6-02d923edf272\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"01bee16d-d797-43f1-9866-6a24d4e49d2e\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"d7a2d0ed-cbc2-4f77-8ffd-72afa1167ca0\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"source\":{\"id\":\"b29d2615-01b6-4a4a-819a-bd751e34fe95\",\"type\":\"ColumnDataSource\"}},\"id\":\"566a32ee-49c6-4867-a781-8f84ac433dfb\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"a6a5e7f6-4392-4345-9fa6-a94e48bc6993\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"baf19eb1-d5ae-4764-8375-6740c9b86af3\",\"type\":\"PanTool\"},{\"id\":\"1e763b09-51ff-43fc-b42e-66bd5f1f7dbe\",\"type\":\"WheelZoomTool\"},{\"id\":\"6081dd7a-e3ca-4736-aeed-5de5f4d65138\",\"type\":\"BoxZoomTool\"},{\"id\":\"39ac91c8-d5eb-495c-b121-6493df838a37\",\"type\":\"SaveTool\"},{\"id\":\"57e0f0a4-f4d9-4b10-9f94-d75e9a7ed398\",\"type\":\"ResetTool\"},{\"id\":\"01bee16d-d797-43f1-9866-6a24d4e49d2e\",\"type\":\"HelpTool\"}]},\"id\":\"3b569b7b-86e4-4821-9973-0da4a4cc059a\",\"type\":\"Toolbar\"},{\"attributes\":{\"formatter\":{\"id\":\"a6a5e7f6-4392-4345-9fa6-a94e48bc6993\",\"type\":\"CategoricalTickFormatter\"},\"plot\":{\"id\":\"0a17efb9-4975-401f-b9eb-1cd661cdff17\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b03ef714-2370-4050-b148-c8d04f98acf0\",\"type\":\"CategoricalTicker\"}},\"id\":\"1c267aff-2086-4422-a86c-465ce2ee91f9\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"898ccb9c-956b-4fd1-8e78-f73902ddb49e\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"7cd4fdef-f37a-4879-a7ee-3336ec1c7278\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"0a17efb9-4975-401f-b9eb-1cd661cdff17\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"ac228819-0ee0-45da-8c9b-95994cfd3dde\",\"type\":\"BasicTicker\"}},\"id\":\"1ff88ec0-1e59-4824-a800-e35485a4c022\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"b75ba1b9-56e8-415a-a9f1-fef92f86d996\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"b03ef714-2370-4050-b148-c8d04f98acf0\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"7cd4fdef-f37a-4879-a7ee-3336ec1c7278\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"0a17efb9-4975-401f-b9eb-1cd661cdff17\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"ac228819-0ee0-45da-8c9b-95994cfd3dde\",\"type\":\"BasicTicker\"}},\"id\":\"e3dde10f-feca-437a-ba13-4ab2972db93d\",\"type\":\"LinearAxis\"},{\"attributes\":{\"below\":[{\"id\":\"1c267aff-2086-4422-a86c-465ce2ee91f9\",\"type\":\"CategoricalAxis\"}],\"left\":[{\"id\":\"e3dde10f-feca-437a-ba13-4ab2972db93d\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1c267aff-2086-4422-a86c-465ce2ee91f9\",\"type\":\"CategoricalAxis\"},{\"id\":\"46e840e6-0164-4d22-913e-c34c1dec77b4\",\"type\":\"Grid\"},{\"id\":\"e3dde10f-feca-437a-ba13-4ab2972db93d\",\"type\":\"LinearAxis\"},{\"id\":\"1ff88ec0-1e59-4824-a800-e35485a4c022\",\"type\":\"Grid\"},{\"id\":\"0bb1fc30-9e2f-40ef-b2d7-aa93d063fb2d\",\"type\":\"BoxAnnotation\"},{\"id\":\"3db0ec86-dd76-4d12-bf19-9f62ed6a761d\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"439c420c-6bda-4017-957c-214a2684a9b0\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"3b569b7b-86e4-4821-9973-0da4a4cc059a\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"d95567a6-28f8-404c-bcb2-42c7873da565\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"d7a2d0ed-cbc2-4f77-8ffd-72afa1167ca0\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"b75ba1b9-56e8-415a-a9f1-fef92f86d996\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"898ccb9c-956b-4fd1-8e78-f73902ddb49e\",\"type\":\"LinearScale\"}},\"id\":\"0a17efb9-4975-401f-b9eb-1cd661cdff17\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"0bb1fc30-9e2f-40ef-b2d7-aa93d063fb2d\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"callback\":null,\"factors\":[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]},\"id\":\"d95567a6-28f8-404c-bcb2-42c7873da565\",\"type\":\"FactorRange\"},{\"attributes\":{\"overlay\":{\"id\":\"0bb1fc30-9e2f-40ef-b2d7-aa93d063fb2d\",\"type\":\"BoxAnnotation\"}},\"id\":\"6081dd7a-e3ca-4736-aeed-5de5f4d65138\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"ac228819-0ee0-45da-8c9b-95994cfd3dde\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"b29d2615-01b6-4a4a-819a-bd751e34fe95\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"a2f636fb-a997-4e22-8c3f-a3550b7b8ee9\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"93c5fd68-1300-46a4-8278-05ec601b1155\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"566a32ee-49c6-4867-a781-8f84ac433dfb\",\"type\":\"CDSView\"}},\"id\":\"3db0ec86-dd76-4d12-bf19-9f62ed6a761d\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1e763b09-51ff-43fc-b42e-66bd5f1f7dbe\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"baf19eb1-d5ae-4764-8375-6740c9b86af3\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"57e0f0a4-f4d9-4b10-9f94-d75e9a7ed398\",\"type\":\"ResetTool\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"439c420c-6bda-4017-957c-214a2684a9b0\",\"type\":\"Title\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"93c5fd68-1300-46a4-8278-05ec601b1155\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"39ac91c8-d5eb-495c-b121-6493df838a37\",\"type\":\"SaveTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"top\"],\"data\":{\"top\":[10829,1114,5991,353,5599,1016],\"x\":[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]}},\"id\":\"b29d2615-01b6-4a4a-819a-bd751e34fe95\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"a2f636fb-a997-4e22-8c3f-a3550b7b8ee9\",\"type\":\"VBar\"},{\"attributes\":{\"plot\":{\"id\":\"0a17efb9-4975-401f-b9eb-1cd661cdff17\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b03ef714-2370-4050-b148-c8d04f98acf0\",\"type\":\"CategoricalTicker\"}},\"id\":\"46e840e6-0164-4d22-913e-c34c1dec77b4\",\"type\":\"Grid\"}],\"root_ids\":[\"0a17efb9-4975-401f-b9eb-1cd661cdff17\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.14\"}};\n",
       "  var render_items = [{\"docid\":\"947efa5b-7efe-4f3c-88f6-02d923edf272\",\"elementid\":\"96a6070d-12ff-48c6-99f3-0d006f3aadad\",\"modelid\":\"0a17efb9-4975-401f-b9eb-1cd661cdff17\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "0a17efb9-4975-401f-b9eb-1cd661cdff17"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "2      0             0        0       0       0              0\n",
       "5      0             0        0       0       0              0\n",
       "6      1             1        1       0       1              0\n",
       "7      0             0        0       0       0              0\n",
       "8      0             0        0       0       0              0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.io import push_notebook\n",
    "from bokeh.plotting import figure, show, output_file, output_notebook\n",
    "\n",
    "target_counts = train_labels.apply(np.sum,0)\n",
    "target_counts\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "p = figure(x_range=target_names)\n",
    "p.vbar(x=target_names, top = target_counts, width=0.9)\n",
    "\n",
    "show(p)\n",
    "\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is fairly imbalanced when counting label occurrences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas to consider\n",
    "- Sampling methods\n",
    "- Custom Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering/Selection (WIP)\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary size is: 91358\n",
      "Sample vocabulary from CountVectorizer:\n",
      "              count\n",
      "00                0\n",
      "000               1\n",
      "0000              2\n",
      "00000             3\n",
      "000000            4\n",
      "00000001          5\n",
      "00000003          6\n",
      "00000050          7\n",
      "000023405011      8\n",
      "000080            9\n",
      "None\n",
      "...\n",
      "      count\n",
      "雲水    91348\n",
      "電視劇   91349\n",
      "韦安智   91350\n",
      "项目介绍  91351\n",
      "문서    91352\n",
      "보호    91353\n",
      "요청    91354\n",
      "유헌    91355\n",
      "척뉴넘   91356\n",
      "편집    91357\n",
      "None\n",
      "Number of nonzero entries in matrix: 4877898\n",
      "\n",
      "Vocabulary (tfidf) size is: 153175\n",
      "Sample vocabulary from TfidfVectorizer:\n",
      "            count\n",
      "00              0\n",
      "000             1\n",
      "0000            2\n",
      "00000           3\n",
      "000000          4\n",
      "0000000         5\n",
      "00000000        6\n",
      "0000000027      7\n",
      "000001          8\n",
      "000002          9\n",
      "None\n",
      "...\n",
      "            count\n",
      "순혈주의       153165\n",
      "잡아야        153166\n",
      "조선인민군      153167\n",
      "천리마군       153168\n",
      "칠지도        153169\n",
      "ﬂute       153170\n",
      "ａｎｏｎｔａｌｋ   153171\n",
      "ｃｏｍ        153172\n",
      "ｗｗｗ        153173\n",
      "ｳｨｷﾍﾟﾃﾞｨｱ  153174\n",
      "None\n",
      "Number of nonzero entries in matrix: 2855427\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    counts\n",
       "6        4\n",
       "12       1\n",
       "16       1\n",
       "42       4\n",
       "43       3\n",
       "44       1\n",
       "51       2\n",
       "55       4\n",
       "56       3\n",
       "58       2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "# Basic Count Vectorizer\n",
    "countVector = CountVectorizer(ngram_range=(1,1))\n",
    "train_counts = countVector.fit_transform(train_data)\n",
    "dev_counts = countVector.fit_transform(dev_data)\n",
    "\n",
    "print(\"\\nVocabulary size is: {}\").format(len(countVector.vocabulary_))\n",
    "vocab_entries = {k: countVector.vocabulary_[k] for k in countVector.vocabulary_.keys()}\n",
    "vocab_entries = pd.Series(vocab_entries).to_frame()\n",
    "vocab_entries.columns = ['count']\n",
    "vocab_entries = vocab_entries.sort_values(by='count')\n",
    "\n",
    "print(\"Sample vocabulary from CountVectorizer:\")\n",
    "print(pp.pprint(vocab_entries.head(10)))\n",
    "print(\"...\")\n",
    "print(pp.pprint(vocab_entries.tail(10)))\n",
    "print(\"Number of nonzero entries in matrix: {}\").format(train_counts.nnz)\n",
    "\n",
    "tfidfVector = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "train_tfidf_counts = tfidfVector.fit_transform(train_data)\n",
    "dev_tfidf_counts = tfidfVector.transform(dev_data)\n",
    "\n",
    "print(\"\\nVocabulary (tfidf) size is: {}\").format(len(tfidfVector.vocabulary_))\n",
    "vocab_entries = {k: tfidfVector.vocabulary_[k] for k in tfidfVector.vocabulary_.keys()}\n",
    "vocab_entries = pd.Series(vocab_entries).to_frame()\n",
    "vocab_entries.columns = ['count']\n",
    "vocab_entries = vocab_entries.sort_values(by='count')\n",
    "\n",
    "print(\"Sample vocabulary from TfidfVectorizer:\")\n",
    "print(pp.pprint(vocab_entries.head(10)))\n",
    "print(\"...\")\n",
    "print(pp.pprint(vocab_entries.tail(10)))\n",
    "print(\"Number of nonzero entries in matrix: {}\").format(train_tfidf_counts.nnz)\n",
    "\n",
    "#sample column wise sum, we can see that an observation can have multiple classes. \n",
    "count_df = pd.DataFrame(train_labels.apply(np.sum,1), columns = [\"counts\"])\n",
    "count_df = count_df[((count_df[\"counts\"] >= 1))]\n",
    "count_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling with MLPClassifier\n",
      "Training data CV score for class toxic is 0.934869669589, after 2098.69834805 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "\n",
    "print(\"Modelling with MLPClassifier\")\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    label_CV_start = time.time()\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(12,6), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(train_tfidf_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    label_CV_finish = time.time()\n",
    "    print('Training data CV score for class {} is {}, after {} seconds.'.format(name, cv_score, \n",
    "                                                                                label_CV_finish-label_CV_start))\n",
    "full_CV_finish = time.time()\n",
    "print(\"Full cross-val across all labels took {} seconds.\".format(full_cv_finish-full_CV_Start))\n",
    "print(\"Mean Training ROC_AUC for MLPClassifier: {}\".format(np.mean(scores_output)))\n",
    "      \n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    label_CV_start = time.time()\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(12,6), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(train_tfidf_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    label_CV_finish = time.time()\n",
    "    print('DEV data CV score for class {} is {}, after {} seconds.'.format(name, cv_score, \n",
    "                                                                                label_CV_finish-label_CV_start))\n",
    "full_CV_finish = time.time()\n",
    "print(\"Full cross-val across all labels took {} seconds.\".format(full_cv_finish-full_CV_Start))\n",
    "print(\"Mean DEV ROC_AUC for MLPClassifier: {}\".format(np.mean(scores_output)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### First Pass Logistic Regression with sag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'sag'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver)\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver) \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### First Pass Logistic Regression with saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver)\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver) \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Here's the same using tfidf and saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver)\n",
    "    classifier.fit(train_tfidf_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_tfidf_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver) \n",
    "    classifier.fit(dev_tfidf_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_tfidf_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Original counts with saga and L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1')\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1') \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf with saga and L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1')\n",
    "    classifier.fit(train_tfidf_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_tfidf_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1') \n",
    "    classifier.fit(dev_tfidf_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_tfidf_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "dev_Vector = CountVectorizer(ngram_range=(1,1))\n",
    "dev_counts = countVector.fit_transform(dev_data)\n",
    "\n",
    "pred_dt = pd.DataFrame()\n",
    "scores_dev = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    scores_dev.append(cv_score)\n",
    "    output = classifier.predict(dev_counts)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels[name], output)\n",
    "    print('Dev score for class {} is {}'.format(name, metrics.auc(fpr,tpr)))\n",
    "    pred_dt[name] = classifier.predict_proba(dev_counts)[:, 1]\n",
    "    \n",
    "    \n",
    "print(\"Mean(dev) ROC_AUC: {}\").format(np.mean(scores_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on dev set is worse than training set, thus evidence of overfitting and a need for performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is multi-label since each observation can be classified as multiple fields.  This is an important distinction from multi-class where each prediction can only be one label.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df\n",
    "train_labels[\"toxic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "prediction_submission = pd.DataFrame()\n",
    "prediction_submission[\"id\"] = test_df[\"id\"]\n",
    "\n",
    "# new vector object for all train data for submission\n",
    "finalTrainVector = CountVectorizer()\n",
    "finalTrainCount = finalTrainVector.fit_transform(train_df[\"comment_text\"])\n",
    "\n",
    "# TODO: Using pipelines can clean up repetitive processes\n",
    "# test set up\n",
    "#testVector = CountVectorizer()\n",
    "testCount = finalTrainVector.transform(test_df[\"comment_text\"])\n",
    "\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') #sag is one kind of solver optimize for multi-label\n",
    "    clf = classifier.fit(finalTrainCount, train_df[name])\n",
    "    prediction_submission[name] = clf.predict_proba(testCount)[:, 1]\n",
    "    #print(prediction_submission)\n",
    "\n",
    "    \n",
    "print(prediction_submission.head(10)) # print frame output \n",
    "#prediction_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame contains the output for each class and is saved in a pandas data frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
