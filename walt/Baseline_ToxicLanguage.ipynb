{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Submission: Toxic Language Classification \n",
    "**w207 Spring 2018 - Final Project Baseline**\n",
    "\n",
    "**Team: Paul, Walt, Yisang, Joe**\n",
    "\n",
    "\n",
    "\n",
    "### Project Description \n",
    "\n",
    "Our challenge is to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate.  The toxic language data set is sourced from Wikipedia and available as a public kaggle data set. \n",
    "\n",
    "Our goal is to use various machine learning techniques used in class to develop high quality ML models and pipelines.  \n",
    "\n",
    "1. Exercise and build upon concepts covered in class and test out at least 3 kinds of supervised models:\n",
    "    a. Regression (LASSO, Logistic)\n",
    "    b. Trees (RF, XGBoost)\n",
    "    c. DeepLearning (Tensorflow)\n",
    "2. Using stacking/ensembling methods for improving prediction metrics (K-Means, anomaly detection)\n",
    "3. Using unsupervised methods for feature engineering/selection\n",
    "\n",
    "For the baseline proposal, this file contains a first pass run through from data preprocessing to model evaluation using a regression model pipeline. \n",
    "\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "\n",
    "\n",
    "#scipy imports\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import bokeh\n",
    "#! pip install bokeh\n",
    "\n",
    "#General imports\n",
    "import pprint\n",
    "\n",
    "# target classes\n",
    "target_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training observations: 159571\n",
      "training data shape: (111661,)\n",
      "training label shape: (111661, 6)\n",
      "dev label shape: (47910, 6)\n",
      "labels names: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "# read frames localy through csv\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# Random index generator for splitting training data\n",
    "# Note: Each rerun of cell will create new splits.\n",
    "randIndexCut = np.random.rand(len(train_df)) < 0.7\n",
    "\n",
    "#S plit up data\n",
    "test_data = test_df[\"comment_text\"]\n",
    "dev_data, dev_labels = train_df[~randIndexCut][\"comment_text\"], train_df[~randIndexCut][target_names]\n",
    "train_data, train_labels = train_df[randIndexCut][\"comment_text\"], train_df[randIndexCut][target_names]\n",
    "\n",
    "print 'total training observations:', train_df.shape[0]\n",
    "print 'training data shape:', train_data.shape\n",
    "print 'training label shape:', train_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape\n",
    "print 'labels names:', target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how imblanced the label set is in order to have a better understanding with the label quality of the given data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"4456f4b1-f3f1-408c-9334-a4cfefa55d5d\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"4456f4b1-f3f1-408c-9334-a4cfefa55d5d\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"4456f4b1-f3f1-408c-9334-a4cfefa55d5d\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '4456f4b1-f3f1-408c-9334-a4cfefa55d5d' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"4456f4b1-f3f1-408c-9334-a4cfefa55d5d\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"4456f4b1-f3f1-408c-9334-a4cfefa55d5d\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"4456f4b1-f3f1-408c-9334-a4cfefa55d5d\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '4456f4b1-f3f1-408c-9334-a4cfefa55d5d' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"4456f4b1-f3f1-408c-9334-a4cfefa55d5d\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"2999d901-66fa-477e-a804-7ea21f2afdb8\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"2c6f982e-c187-4409-9441-9f207cfecee5\":{\"roots\":{\"references\":[{\"attributes\":{\"overlay\":{\"id\":\"5cece3bd-c8d9-4f8b-8cdb-6011c856a0ad\",\"type\":\"BoxAnnotation\"}},\"id\":\"b178525d-29c4-46b4-8fd3-818e452f94a2\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"callback\":null},\"id\":\"ed8b55c3-637a-4499-a671-ec15ec6bb640\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null,\"factors\":[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]},\"id\":\"50f7dd8a-f9bb-4cae-bb27-30a4706eebbd\",\"type\":\"FactorRange\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"top\"],\"data\":{\"top\":[10685,1125,5968,355,5579,1015],\"x\":[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]}},\"id\":\"0b1a41c2-f465-4c32-a729-fee67b72ce74\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"e2f7e13d-9b82-4866-8520-4bb648c6be38\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"d8a86c13-425e-4c9b-8191-e5dea3868812\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"64c566ad-8220-448b-b69b-a81a8384bb84\",\"type\":\"Title\"},{\"attributes\":{\"below\":[{\"id\":\"18a6f017-359b-4826-adea-284dfbd27023\",\"type\":\"CategoricalAxis\"}],\"left\":[{\"id\":\"be0dee6c-d26f-49c2-9ee1-916c8982a942\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"18a6f017-359b-4826-adea-284dfbd27023\",\"type\":\"CategoricalAxis\"},{\"id\":\"f7384255-abf1-4536-8a41-483770e14ded\",\"type\":\"Grid\"},{\"id\":\"be0dee6c-d26f-49c2-9ee1-916c8982a942\",\"type\":\"LinearAxis\"},{\"id\":\"b12576c9-aeea-421a-84f3-7701e1d79fb3\",\"type\":\"Grid\"},{\"id\":\"5cece3bd-c8d9-4f8b-8cdb-6011c856a0ad\",\"type\":\"BoxAnnotation\"},{\"id\":\"79fa2952-0478-4860-834b-6660e1118ad2\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"64c566ad-8220-448b-b69b-a81a8384bb84\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"191e4e94-c732-4f5e-9400-f20a9abde166\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"50f7dd8a-f9bb-4cae-bb27-30a4706eebbd\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"63859a70-af6f-4614-9fa2-685e0dcd14b9\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"ed8b55c3-637a-4499-a671-ec15ec6bb640\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"8c57f3d3-9110-44f5-93ca-f9a869ab3ab1\",\"type\":\"LinearScale\"}},\"id\":\"060a3788-9a45-43bd-b19a-64bbe374e57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"5cece3bd-c8d9-4f8b-8cdb-6011c856a0ad\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"source\":{\"id\":\"0b1a41c2-f465-4c32-a729-fee67b72ce74\",\"type\":\"ColumnDataSource\"}},\"id\":\"2f36e504-9a07-4dea-9a30-c4ee622bdc35\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"babce328-3a2f-42f8-8d26-738228100179\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"29b270ac-9ddd-4fa7-a477-57848e6737c2\",\"type\":\"ResetTool\"},{\"attributes\":{\"formatter\":{\"id\":\"032e0c00-c9aa-4681-9ee2-2f8f604fbf62\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"060a3788-9a45-43bd-b19a-64bbe374e57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"d8a86c13-425e-4c9b-8191-e5dea3868812\",\"type\":\"BasicTicker\"}},\"id\":\"be0dee6c-d26f-49c2-9ee1-916c8982a942\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":{\"id\":\"060a3788-9a45-43bd-b19a-64bbe374e57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a3388d2d-4b5d-48b1-8350-ab18d3f7cf6f\",\"type\":\"CategoricalTicker\"}},\"id\":\"f7384255-abf1-4536-8a41-483770e14ded\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"7bbdba63-9f12-41f7-90d7-a4cd96a55ea8\",\"type\":\"CategoricalTickFormatter\"},\"plot\":{\"id\":\"060a3788-9a45-43bd-b19a-64bbe374e57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a3388d2d-4b5d-48b1-8350-ab18d3f7cf6f\",\"type\":\"CategoricalTicker\"}},\"id\":\"18a6f017-359b-4826-adea-284dfbd27023\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"390e41ba-f43b-4a4f-bd6d-b1f69080a4e7\",\"type\":\"VBar\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"babce328-3a2f-42f8-8d26-738228100179\",\"type\":\"PanTool\"},{\"id\":\"e2f7e13d-9b82-4866-8520-4bb648c6be38\",\"type\":\"WheelZoomTool\"},{\"id\":\"b178525d-29c4-46b4-8fd3-818e452f94a2\",\"type\":\"BoxZoomTool\"},{\"id\":\"6cc60a30-6ee3-4de4-ab71-4917bc18e3dd\",\"type\":\"SaveTool\"},{\"id\":\"29b270ac-9ddd-4fa7-a477-57848e6737c2\",\"type\":\"ResetTool\"},{\"id\":\"c39cf9a8-9390-4a81-a68e-e075e154e175\",\"type\":\"HelpTool\"}]},\"id\":\"191e4e94-c732-4f5e-9400-f20a9abde166\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"6cc60a30-6ee3-4de4-ab71-4917bc18e3dd\",\"type\":\"SaveTool\"},{\"attributes\":{\"data_source\":{\"id\":\"0b1a41c2-f465-4c32-a729-fee67b72ce74\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"ba3d5bc1-5c19-451b-b5e3-fde733a148df\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"390e41ba-f43b-4a4f-bd6d-b1f69080a4e7\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"2f36e504-9a07-4dea-9a30-c4ee622bdc35\",\"type\":\"CDSView\"}},\"id\":\"79fa2952-0478-4860-834b-6660e1118ad2\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"a3388d2d-4b5d-48b1-8350-ab18d3f7cf6f\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"63859a70-af6f-4614-9fa2-685e0dcd14b9\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"8c57f3d3-9110-44f5-93ca-f9a869ab3ab1\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"ba3d5bc1-5c19-451b-b5e3-fde733a148df\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"c39cf9a8-9390-4a81-a68e-e075e154e175\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"7bbdba63-9f12-41f7-90d7-a4cd96a55ea8\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{},\"id\":\"032e0c00-c9aa-4681-9ee2-2f8f604fbf62\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"060a3788-9a45-43bd-b19a-64bbe374e57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"d8a86c13-425e-4c9b-8191-e5dea3868812\",\"type\":\"BasicTicker\"}},\"id\":\"b12576c9-aeea-421a-84f3-7701e1d79fb3\",\"type\":\"Grid\"}],\"root_ids\":[\"060a3788-9a45-43bd-b19a-64bbe374e57b\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.14\"}};\n",
       "  var render_items = [{\"docid\":\"2c6f982e-c187-4409-9441-9f207cfecee5\",\"elementid\":\"2999d901-66fa-477e-a804-7ea21f2afdb8\",\"modelid\":\"060a3788-9a45-43bd-b19a-64bbe374e57b\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "060a3788-9a45-43bd-b19a-64bbe374e57b"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0              0\n",
       "1      0             0        0       0       0              0\n",
       "2      0             0        0       0       0              0\n",
       "4      0             0        0       0       0              0\n",
       "5      0             0        0       0       0              0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.io import push_notebook\n",
    "from bokeh.plotting import figure, show, output_file, output_notebook\n",
    "\n",
    "target_counts = train_labels.apply(np.sum,0)\n",
    "target_counts\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "p = figure(x_range=target_names)\n",
    "p.vbar(x=target_names, top = target_counts, width=0.9)\n",
    "\n",
    "show(p)\n",
    "\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is fairly imbalanced when counting label occurrences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas to consider\n",
    "- Sampling methods\n",
    "- Custom Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering/Selection (WIP)\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary (tfidf) size is: 153283\n",
      "Sample vocabulary from TfidfVectorizer:\n",
      "            count\n",
      "00              0\n",
      "000             1\n",
      "0000            2\n",
      "00000           3\n",
      "000000          4\n",
      "0000000         5\n",
      "00000000        6\n",
      "0000000027      7\n",
      "00000001        8\n",
      "00000003        9\n",
      "None\n",
      "...\n",
      "            count\n",
      "잡아야        153273\n",
      "조선인민군      153274\n",
      "척뉴넘        153275\n",
      "칠지도        153276\n",
      "편집         153277\n",
      "ﬂute       153278\n",
      "ａｎｏｎｔａｌｋ   153279\n",
      "ｃｏｍ        153280\n",
      "ｗｗｗ        153281\n",
      "ｳｨｷﾍﾟﾃﾞｨｱ  153282\n",
      "None\n",
      "Number of nonzero entries in matrix: 2848397\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     counts\n",
       "6         4\n",
       "12        1\n",
       "16        1\n",
       "44        1\n",
       "55        4\n",
       "58        2\n",
       "59        1\n",
       "65        3\n",
       "86        2\n",
       "105       4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "basic=False\n",
    "\n",
    "if (basic):\n",
    "    # Basic Count Vectorizer\n",
    "    countVector0 = CountVectorizer(ngram_range=(1,1))\n",
    "    train_counts = countVector.fit_transform(train_data)\n",
    "    dev_counts = countVector.fit_transform(dev_data)\n",
    "\n",
    "    print(\"\\nVocabulary size is: {}\").format(len(countVector.vocabulary_))\n",
    "    vocab_entries = {k: countVector.vocabulary_[k] for k in countVector.vocabulary_.keys()}\n",
    "    vocab_entries = pd.Series(vocab_entries).to_frame()\n",
    "    vocab_entries.columns = ['count']\n",
    "    vocab_entries = vocab_entries.sort_values(by='count')\n",
    "\n",
    "    print(\"Sample vocabulary from CountVectorizer:\")\n",
    "    print(pp.pprint(vocab_entries.head(10)))\n",
    "    print(\"...\")\n",
    "    print(pp.pprint(vocab_entries.tail(10)))\n",
    "    print(\"Number of nonzero entries in matrix: {}\").format(train_counts.nnz)\n",
    "\n",
    "\n",
    "    \n",
    "tfidfVector = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "train_tfidf_counts = tfidfVector.fit_transform(train_data)\n",
    "dev_tfidf_counts = tfidfVector.transform(dev_data)\n",
    "\n",
    "print(\"\\nVocabulary (tfidf) size is: {}\").format(len(tfidfVector.vocabulary_))\n",
    "vocab_entries = {k: tfidfVector.vocabulary_[k] for k in tfidfVector.vocabulary_.keys()}\n",
    "vocab_entries = pd.Series(vocab_entries).to_frame()\n",
    "vocab_entries.columns = ['count']\n",
    "vocab_entries = vocab_entries.sort_values(by='count')\n",
    "\n",
    "print(\"Sample vocabulary from TfidfVectorizer:\")\n",
    "print(pp.pprint(vocab_entries.head(10)))\n",
    "print(\"...\")\n",
    "print(pp.pprint(vocab_entries.tail(10)))\n",
    "print(\"Number of nonzero entries in matrix: {}\").format(train_tfidf_counts.nnz)\n",
    "\n",
    "#sample column wise sum, we can see that an observation can have multiple classes. \n",
    "count_df = pd.DataFrame(train_labels.apply(np.sum,1), columns = [\"counts\"])\n",
    "count_df = count_df[((count_df[\"counts\"] >= 1))]\n",
    "count_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting to look at Keras -- this is not functional -- please ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scipy import sparse\n",
    "from types import FunctionType\n",
    "\n",
    "class KerasClassifier(KerasClassifier):\n",
    "    \"\"\" adds sparse matrix handling using batch generator\"\"\"\n",
    "    \n",
    "    def fit(self, x, y, **kwargs):\n",
    "        \"\"\" adds sparse matrix handling \"\"\"\n",
    "        if not sparse.issparse(x):\n",
    "            return super().fit(x, y, **kwargs)\n",
    "\n",
    "        ############ adapted from KerasClassifier.fit   ######################   \n",
    "        if self.build_fn is None:\n",
    "            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n",
    "        elif not isinstance(self.build_fn, FunctionType):\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn.__call__))\n",
    "        else:\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "        ### fit => fit_generator\n",
    "        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit_generator))\n",
    "        fit_args.update(kwargs)\n",
    "        ############################################################\n",
    "        self.model.fit_generator(\n",
    "            self.get_batch(x, y, 500),\n",
    "            samples_per_epoch=x.shape[0],**fit_args)\n",
    "        return self                               \n",
    "\n",
    "    def get_batch(self, x, y=None, batch_size=1000):\n",
    "        \"\"\" batch generator to enable sparse input \"\"\"\n",
    "        index = np.arange(x.shape[0])\n",
    "        start = 0\n",
    "        while True:\n",
    "            if start == 0 and y is not None:\n",
    "                np.random.shuffle(index)\n",
    "            batch = index[start:start+batch_size]\n",
    "            if y is not None:\n",
    "                yield x[batch].toarray(), y[batch]\n",
    "            else:\n",
    "                yield x[batch].toarray()\n",
    "            start += batch_size\n",
    "            if start >= x.shape[0]:\n",
    "                start = 0\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        \"\"\" adds sparse matrix handling \"\"\"\n",
    "        if not sparse.issparse(x):\n",
    "            return super().predict_proba(x)\n",
    "      \n",
    "        preds = self.model.predict_generator(\n",
    "            self.get_batch(x, None, 500), val_samples=x.shape[0])\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting to look at Keras -- this is not functional -- please ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling with Keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=150, steps_per_epoch=111395, verbose=0)`\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[ 70210  33136  30869 102644 110653  87776  36686  19530  46891 102084\\n  47362  71340  81013  38411   8450 105745   9102  99512  39504   2125\\n 109594 101262  99342  10408  46840  10767  43585  12963  94497   8178\\n  14571  32281  13212 103756 104097  71923  51686  19477    936  73356\\n  27578  71936  84755  87360  30875  65836  86581  93746  53268  63037\\n  50999 106091  75385 108438  81706  76184  26119  62583   5161  31516\\n  35705  52694 103545  75954  24798  94683  53472    588  99985  91294\\n  81625  66138  92253  37979   7061  84304  71558  32116  36172   2821\\n  29981  64404  29031  49208  47785   7398  28023  89834 103604  94618\\n  12057  61402  80837 109382    147  84992 103407  36610  52667  50547\\n  81769 109333  62275   6328  47018  91881  75841  59972  46730  24650\\n  97226  94984  95046  62626   9345  13486  53330  45043  42512  29833\\n  64644  47124  57897  62675 110894   9503 111024  87858  45033  99042\\n  12702  43368  53885  10788 102939 110035 108224   1617   6871  23132\\n 101059  99278  82379  21687 105042  82167  28733  20015  92662  61638\\n  82922  41070 108600   7627  20662  92612  62716  47975  20443  85793\\n  29753  24619  77087 104248  70661  39349  56406  92674 106480  59720\\n  38706  93042   7345  94611  58646  82551  77998  16341 106890    190\\n  39439  38853  12758  13436  60526  86428  94762  25519  21482 107215\\n   4971  30516  13568  89675  89613  52873  22989  73164  12756  46315\\n  84060  82658  88121  95414  95176   6476  42361  24276  34172  12101\\n  35332  41898  60493  86206  19633  21722  46530  46022  95234  15439\\n 106820  87304  46071  15796  81794  20762  81035  79687  29565  77042\\n  78199  23888  91923  11439  27907 109434  52795  36998  24204  37767\\n   7766  17180  11260  92424  34396  50568  39520  38996 108645 106841\\n  62303  57552  50915  23992  68497  59755  94009  42878  34181  17394\\n  52494  20774  22230  47284  95428 109085  85853   4703  28114  63304\\n  58966  80251  90884  26845  42517  91185  43413  11992  96239  60229\\n 106053  66800  71287 110417 103016  10556  40975  34189  42049  72714\\n  58846  23676  90383  71260  31694  21501  55290  42132  42762  32007\\n  96839  54180  99666 105030  86158   8587  88641  46205   3525  41770\\n  20264  75112   8802  85019  46652  62441 104796  40786  59592  88865\\n  51301  27754  60720  46362  35707  15817  46989  79150  60863  64155\\n   2559  34357  28339 102364  14922  43178  14552  43052  70886  50770\\n  80552  44395  97301  14570  42777  43817  95756  80174 105534  37038\\n  22365  81315  95860  15610  74811  88302  49701  39693  66658   9720\\n  37008  25334  13547  86363  84378   5299   8360  25303  90851  77613\\n  65806  81412  43142  50155  91151  34700  71196  15074  47787  91644\\n  22603  72736  59188 107985   6494  35071  17610  39751 107446  91109\\n  46161  95028  75332 101118  20402  61570  84907 108849  88638  41388\\n  82022  64303  61879  18106 106162  79064  38160 103041  82314  49066\\n  44234  16175  84926  21738  76934  66183  77852  65636  37544  47736\\n  27863  31806   3075  54221  88553  82583  21245    328  28245  92988\\n  86382  17093  61650  20702 108140  47547  38141 101241  15774  85741\\n  34739  19090  57708  28628 104662  35545  21146   3107  21360  93668\\n  24906  71362  50501  51306  34601  38350  36802  22203  53755  48204\\n  17669  67852  37423  29010  58587  16526  99485  62233  21740  34476\\n  54881  13855    127  17304   3715  66207 108127  94269  23188  25324\\n  13848 103119 109951  34767  29918  50154  63719  24253 109071  57585\\n   3384  39312 109177  79303 109546  42779 101672 105343  15832  14017] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-2ea959eadf1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_tfidf_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tfidf_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_tfidf_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-8b73c71855da>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         self.model.fit_generator(\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             samples_per_epoch=x.shape[0],**fit_args)\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36m_data_generator_task\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    656\u001b[0m                             \u001b[0;31m# => Serialize calls to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                             \u001b[0;31m# infinite iterator/generator's next() function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-8b73c71855da>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, x, y, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/burgew/Library/Python/2.7/lib/python/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/burgew/Library/Python/2.7/lib/python/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/burgew/Library/Python/2.7/lib/python/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1269\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[ 70210  33136  30869 102644 110653  87776  36686  19530  46891 102084\\n  47362  71340  81013  38411   8450 105745   9102  99512  39504   2125\\n 109594 101262  99342  10408  46840  10767  43585  12963  94497   8178\\n  14571  32281  13212 103756 104097  71923  51686  19477    936  73356\\n  27578  71936  84755  87360  30875  65836  86581  93746  53268  63037\\n  50999 106091  75385 108438  81706  76184  26119  62583   5161  31516\\n  35705  52694 103545  75954  24798  94683  53472    588  99985  91294\\n  81625  66138  92253  37979   7061  84304  71558  32116  36172   2821\\n  29981  64404  29031  49208  47785   7398  28023  89834 103604  94618\\n  12057  61402  80837 109382    147  84992 103407  36610  52667  50547\\n  81769 109333  62275   6328  47018  91881  75841  59972  46730  24650\\n  97226  94984  95046  62626   9345  13486  53330  45043  42512  29833\\n  64644  47124  57897  62675 110894   9503 111024  87858  45033  99042\\n  12702  43368  53885  10788 102939 110035 108224   1617   6871  23132\\n 101059  99278  82379  21687 105042  82167  28733  20015  92662  61638\\n  82922  41070 108600   7627  20662  92612  62716  47975  20443  85793\\n  29753  24619  77087 104248  70661  39349  56406  92674 106480  59720\\n  38706  93042   7345  94611  58646  82551  77998  16341 106890    190\\n  39439  38853  12758  13436  60526  86428  94762  25519  21482 107215\\n   4971  30516  13568  89675  89613  52873  22989  73164  12756  46315\\n  84060  82658  88121  95414  95176   6476  42361  24276  34172  12101\\n  35332  41898  60493  86206  19633  21722  46530  46022  95234  15439\\n 106820  87304  46071  15796  81794  20762  81035  79687  29565  77042\\n  78199  23888  91923  11439  27907 109434  52795  36998  24204  37767\\n   7766  17180  11260  92424  34396  50568  39520  38996 108645 106841\\n  62303  57552  50915  23992  68497  59755  94009  42878  34181  17394\\n  52494  20774  22230  47284  95428 109085  85853   4703  28114  63304\\n  58966  80251  90884  26845  42517  91185  43413  11992  96239  60229\\n 106053  66800  71287 110417 103016  10556  40975  34189  42049  72714\\n  58846  23676  90383  71260  31694  21501  55290  42132  42762  32007\\n  96839  54180  99666 105030  86158   8587  88641  46205   3525  41770\\n  20264  75112   8802  85019  46652  62441 104796  40786  59592  88865\\n  51301  27754  60720  46362  35707  15817  46989  79150  60863  64155\\n   2559  34357  28339 102364  14922  43178  14552  43052  70886  50770\\n  80552  44395  97301  14570  42777  43817  95756  80174 105534  37038\\n  22365  81315  95860  15610  74811  88302  49701  39693  66658   9720\\n  37008  25334  13547  86363  84378   5299   8360  25303  90851  77613\\n  65806  81412  43142  50155  91151  34700  71196  15074  47787  91644\\n  22603  72736  59188 107985   6494  35071  17610  39751 107446  91109\\n  46161  95028  75332 101118  20402  61570  84907 108849  88638  41388\\n  82022  64303  61879  18106 106162  79064  38160 103041  82314  49066\\n  44234  16175  84926  21738  76934  66183  77852  65636  37544  47736\\n  27863  31806   3075  54221  88553  82583  21245    328  28245  92988\\n  86382  17093  61650  20702 108140  47547  38141 101241  15774  85741\\n  34739  19090  57708  28628 104662  35545  21146   3107  21360  93668\\n  24906  71362  50501  51306  34601  38350  36802  22203  53755  48204\\n  17669  67852  37423  29010  58587  16526  99485  62233  21740  34476\\n  54881  13855    127  17304   3715  66207 108127  94269  23188  25324\\n  13848 103119 109951  34767  29918  50154  63719  24253 109071  57585\\n   3384  39312 109177  79303 109546  42779 101672 105343  15832  14017] not in index'"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "from types import *\n",
    "import copy\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"Modelling with Keras\")\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "def build_model(n_hidden=32):\n",
    "    model = Sequential([\n",
    "        Dense(n_hidden, input_dim=4),\n",
    "        Activation(\"relu\"),\n",
    "        Dense(n_hidden),\n",
    "        Activation(\"relu\"),\n",
    "        Dense(3),\n",
    "        Activation(\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "params = dict(batch_size=500)\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    # define 3-fold cross validation test harness\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "    cvscores = []\n",
    "    for train, test in kfold.split(dev_tfidf_counts, dev_labels):\n",
    "        model=KerasClassifier(build_fn=build_model, verbose=0)\n",
    "        model.fit(train_tfidf_counts, train_labels, epochs=150, verbose=0)\n",
    "        # evaluate the model\n",
    "        scores = model.evaluate(dev_tfidf_counts, dev_labels, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        cvscores.append(scores[1] * 100)\n",
    "    print(\"Summary scores for label '{}': Mean {:.2f}  SD {:.2f})\".format(name, numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting to look at Keras -- this is not functional -- please ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split \n",
    "\n",
    "def build_model(n_hidden=32):\n",
    "    model = Sequential([\n",
    "        Dense(n_hidden, input_dim=4),\n",
    "        Activation(\"relu\"),\n",
    "        Dense(n_hidden),\n",
    "        Activation(\"relu\"),\n",
    "        Dense(3),\n",
    "        Activation(\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "param_grid = {\n",
    "    \"n_hidden\": np.array([4, 8, 16]),\n",
    "    \"nb_epoch\": np.array(range(50, 61, 5))\n",
    "}\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, verbose=0)\n",
    "skf = KFold(n_splits=5).split(train_tfidf_counts, train_labels) # this yields (train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111708, 285189)\n"
     ]
    }
   ],
   "source": [
    "print(train_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier (Neural Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling with MLPClassifier\n",
      "Train data CV score for class toxic is 0.932057379203, after 20.1736497362 minutes.\n",
      "Train data CV score for class severe_toxic is 0.925718157775, after 20.1235693018 minutes.\n",
      "Train data CV score for class obscene is 0.953477908436, after 20.3226263007 minutes.\n",
      "Train data CV score for class threat is 0.939294023398, after 35.3592856526 minutes.\n",
      "Train data CV score for class insult is 0.913523731044, after 110.750495831 minutes.\n",
      "Train data CV score for class identity_hate is 0.938434700338, after 15.2087560654 minutes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'full_CV_Start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-4ebcfacd9bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                                                 (label_CV_finish-label_CV_start)/60))\n\u001b[1;32m     24\u001b[0m \u001b[0mfull_CV_finish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Full cross-val across all labels took {} minutes.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_CV_finish\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfull_CV_Start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Train ROC_AUC for MLPClassifier: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_CV_Start' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "#from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n",
    "\n",
    "\n",
    "\n",
    "print(\"Modelling with MLPClassifier\")\n",
    "\n",
    "# This is the same loop as with the below examples of Logistic Regression\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    label_CV_start = time.time()\n",
    "\n",
    "    # This Multi-Layer Perceptron classifier will be setup with hidden layers of 6 and 6 each, with tanh activation\n",
    "    # Running a 3-way cross-validation for a single label takes between 10 and 2 minutes, dependenging on the machine.\n",
    "    # Note that while there was a typo in the below code (it's gone now), in the last run that failed the individual\n",
    "    # label scores were around 93%.\n",
    "    # The really long runs where when I had unknowingly allowed my machine to go to sleep, which accounts for the time.\n",
    "    \n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(6,6), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(train_tfidf_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_tfidf_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    label_CV_finish = time.time()\n",
    "    print('Train data CV score for class {} is {}, after {} minutes.'.format(name, cv_score, \n",
    "                                                                                (label_CV_finish-label_CV_start)/60))\n",
    "full_CV_finish = time.time()\n",
    "print(\"Full cross-val across all labels took {} minutes.\".format((full_CV_finish-full_CV_start)/60))\n",
    "\n",
    "print(\"Mean Train ROC_AUC for MLPClassifier: {}\".format(np.mean(scores_output)))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    label_CV_start = time.time()\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(6,6), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(dev_tfidf_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_tfidf_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    label_CV_finish = time.time()\n",
    "    print('DEV data CV score for class {} is {}, after {} minutes.'.format(name, cv_score, \n",
    "                                                                                (label_CV_finish-label_CV_start)/60))\n",
    "full_CV_finish = time.time()\n",
    "print(\"Full cross-val across all labels took {} minutes.\".format(full_CV_finish-full_CV_start))\n",
    "print(\"Mean DEV ROC_AUC for MLPClassifier: {}\".format(np.mean(scores_output)))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras (Neural Net with GPU support) -- this is not yet functioning, and quite broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling with Keras\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (32, 152766) for Tensor u'dense_69_input:0', which has shape '(111395, 152766)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e6ead6a24f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tfidf_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_tfidf_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1113\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1114\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (32, 152766) for Tensor u'dense_69_input:0', which has shape '(111395, 152766)'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"Modelling with Keras\")\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    # define 3-fold cross validation test harness\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "    cvscores = []\n",
    "    for train, test in kfold.split(dev_tfidf_counts, dev_labels):\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(1000, batch_input_shape=train_tfidf_counts.shape, activation='relu'))\n",
    "        model.add(Dense(6, input_dim=36, activation='relu'))\n",
    "        model.add(Dense(6, input_dim=6, activation='sigmoid'))\n",
    "        # Compile model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        # Fit the model\n",
    "        model.fit(train_tfidf_counts, train_labels, epochs=150, verbose=0)\n",
    "        # evaluate the model\n",
    "        scores = model.evaluate(dev_tfidf_counts, dev_labels, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        cvscores.append(scores[1] * 100)\n",
    "    print(\"Summary scores for label '{}': Mean {:.2f}  SD {:.2f})\".format(name, numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### First Pass Logistic Regression with sag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'sag'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver)\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver) \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### First Pass Logistic Regression with saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver)\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver) \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Here's the same using tfidf and saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver)\n",
    "    classifier.fit(train_tfidf_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_tfidf_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver) \n",
    "    classifier.fit(dev_tfidf_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_tfidf_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Original counts with saga and L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1')\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1') \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf with saga and L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1')\n",
    "    classifier.fit(train_tfidf_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_tfidf_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1') \n",
    "    classifier.fit(dev_tfidf_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_tfidf_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "dev_Vector = CountVectorizer(ngram_range=(1,1))\n",
    "dev_counts = countVector.fit_transform(dev_data)\n",
    "\n",
    "pred_dt = pd.DataFrame()\n",
    "scores_dev = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    scores_dev.append(cv_score)\n",
    "    output = classifier.predict(dev_counts)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels[name], output)\n",
    "    print('Dev score for class {} is {}'.format(name, metrics.auc(fpr,tpr)))\n",
    "    pred_dt[name] = classifier.predict_proba(dev_counts)[:, 1]\n",
    "    \n",
    "    \n",
    "print(\"Mean(dev) ROC_AUC: {}\").format(np.mean(scores_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on dev set is worse than training set, thus evidence of overfitting and a need for performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is multi-label since each observation can be classified as multiple fields.  This is an important distinction from multi-class where each prediction can only be one label.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df\n",
    "train_labels[\"toxic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "prediction_submission = pd.DataFrame()\n",
    "prediction_submission[\"id\"] = test_df[\"id\"]\n",
    "\n",
    "# new vector object for all train data for submission\n",
    "finalTrainVector = CountVectorizer()\n",
    "finalTrainCount = finalTrainVector.fit_transform(train_df[\"comment_text\"])\n",
    "\n",
    "# TODO: Using pipelines can clean up repetitive processes\n",
    "# test set up\n",
    "#testVector = CountVectorizer()\n",
    "testCount = finalTrainVector.transform(test_df[\"comment_text\"])\n",
    "\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') #sag is one kind of solver optimize for multi-label\n",
    "    clf = classifier.fit(finalTrainCount, train_df[name])\n",
    "    prediction_submission[name] = clf.predict_proba(testCount)[:, 1]\n",
    "    #print(prediction_submission)\n",
    "\n",
    "    \n",
    "print(prediction_submission.head(10)) # print frame output \n",
    "#prediction_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame contains the output for each class and is saved in a pandas data frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
