{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Submission: Toxic Language Classification \n",
    "**w207 Spring 2018 - Final Project Baseline**\n",
    "\n",
    "**Team: Paul, Walt, Yisang, Joe**\n",
    "\n",
    "\n",
    "\n",
    "### Project Description \n",
    "\n",
    "Our challenge is to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate.  The toxic language data set is sourced from Wikipedia and available as a public kaggle data set. \n",
    "\n",
    "Our goal is to use various machine learning techniques used in class to develop high quality ML models and pipelines.  \n",
    "\n",
    "1. Exercise and build upon concepts covered in class and test out at least 3 kinds of supervised models:\n",
    "    a. Regression (LASSO, Logistic)\n",
    "    b. Trees (RF, XGBoost)\n",
    "    c. DeepLearning (Tensorflow)\n",
    "2. Using stacking/ensembling methods for improving prediction metrics (K-Means, anomaly detection)\n",
    "3. Using unsupervised methods for feature engineering/selection\n",
    "\n",
    "For the baseline proposal, this file contains a first pass run through from data preprocessing to model evaluation using a regression model pipeline. \n",
    "\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "\n",
    "\n",
    "#NLTK imports\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import punkt as punkt\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# These imports enable the use of NLTKPreprocessor in an sklearn Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "#scipy imports\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import bokeh\n",
    "#! pip install bokeh\n",
    "\n",
    "#General imports\n",
    "import pprint\n",
    "\n",
    "# target classes\n",
    "target_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training observations: 159571\n",
      "training data shape: (111906,)\n",
      "training label shape: (111906, 6)\n",
      "dev label shape: (47665, 6)\n",
      "labels names: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "# read frames localy through csv\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "np.random.seed(455)\n",
    "\n",
    "# Random index generator for splitting training data\n",
    "# Note: Each rerun of cell will create new splits.\n",
    "randIndexCut = np.random.rand(len(train_df)) < 0.7\n",
    "\n",
    "#S plit up data\n",
    "test_data = test_df[\"comment_text\"]\n",
    "dev_data, dev_labels = train_df[~randIndexCut][\"comment_text\"], train_df[~randIndexCut][target_names]\n",
    "train_data, train_labels = train_df[randIndexCut][\"comment_text\"], train_df[randIndexCut][target_names]\n",
    "\n",
    "print 'total training observations:', train_df.shape[0]\n",
    "print 'training data shape:', train_data.shape\n",
    "print 'training label shape:', train_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape\n",
    "print 'labels names:', target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how imblanced the label set is in order to have a better understanding with the label quality of the given data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"63d43cdc-49d8-4f16-811e-4b4a3d5ac514\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"63d43cdc-49d8-4f16-811e-4b4a3d5ac514\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"63d43cdc-49d8-4f16-811e-4b4a3d5ac514\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '63d43cdc-49d8-4f16-811e-4b4a3d5ac514' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"63d43cdc-49d8-4f16-811e-4b4a3d5ac514\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"63d43cdc-49d8-4f16-811e-4b4a3d5ac514\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"63d43cdc-49d8-4f16-811e-4b4a3d5ac514\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '63d43cdc-49d8-4f16-811e-4b4a3d5ac514' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"63d43cdc-49d8-4f16-811e-4b4a3d5ac514\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"55217b68-83fb-4087-9122-4a80c1b79b22\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"3be2c5be-e391-40b2-8ebf-61d93d03d57d\":{\"roots\":{\"references\":[{\"attributes\":{\"overlay\":{\"id\":\"ed3ed6ea-e861-4266-a3a0-2e7aa99c9d93\",\"type\":\"BoxAnnotation\"}},\"id\":\"ba5efd85-1247-4c8a-b13e-5073b80f0dc7\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"data_source\":{\"id\":\"f51adc48-fc8f-40e4-9642-1ee360e4565b\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"73256f87-6311-4f09-b087-95ab45e14ae6\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"ebf8f156-468a-4d4d-b5d8-181884327700\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"628fb3fd-b676-49ca-8855-8017064babc7\",\"type\":\"CDSView\"}},\"id\":\"99ec0145-c03a-4214-a157-ebda30d8eb47\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"cd8f81c8-63e3-4812-b8f1-dc838287e781\",\"type\":\"HelpTool\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"22edb291-9ac9-4bc8-ba21-8e802acc1860\",\"type\":\"Title\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"ed3ed6ea-e861-4266-a3a0-2e7aa99c9d93\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"callback\":null,\"factors\":[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]},\"id\":\"4aa2e5d0-4b24-417a-bf90-f6e739a13213\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"239665d0-2731-44f3-8c03-c0dfa7a7079f\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"9e65a96c-89f4-4d35-9f46-77f119f7ba81\",\"type\":\"SaveTool\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"f11ae22d-7d72-4f07-abb3-f26ff1792e66\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"5225bbb0-f352-4395-8014-cf7a106d2268\",\"type\":\"BasicTicker\"}},\"id\":\"4c272e3b-b15a-47e7-b587-8973b979193b\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"d82898f7-0408-4c3a-9d18-8a82965a5f23\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"top\"],\"data\":{\"top\":[10688,1115,5882,323,5490,990],\"x\":[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]}},\"id\":\"f51adc48-fc8f-40e4-9642-1ee360e4565b\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"formatter\":{\"id\":\"469d5dab-75f0-4aad-8ef9-11ccc7a17167\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"f11ae22d-7d72-4f07-abb3-f26ff1792e66\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"5225bbb0-f352-4395-8014-cf7a106d2268\",\"type\":\"BasicTicker\"}},\"id\":\"fce05c7d-2357-4362-90a0-79afecd59c0d\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"ec8b2f96-42cd-4170-be6a-29bba2809c26\",\"type\":\"ResetTool\"},{\"attributes\":{\"below\":[{\"id\":\"e72e2de6-c612-4547-96d1-90561829fb0c\",\"type\":\"CategoricalAxis\"}],\"left\":[{\"id\":\"fce05c7d-2357-4362-90a0-79afecd59c0d\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"e72e2de6-c612-4547-96d1-90561829fb0c\",\"type\":\"CategoricalAxis\"},{\"id\":\"913ab4a5-5c45-44ea-8448-c1932269d3d7\",\"type\":\"Grid\"},{\"id\":\"fce05c7d-2357-4362-90a0-79afecd59c0d\",\"type\":\"LinearAxis\"},{\"id\":\"4c272e3b-b15a-47e7-b587-8973b979193b\",\"type\":\"Grid\"},{\"id\":\"ed3ed6ea-e861-4266-a3a0-2e7aa99c9d93\",\"type\":\"BoxAnnotation\"},{\"id\":\"99ec0145-c03a-4214-a157-ebda30d8eb47\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"22edb291-9ac9-4bc8-ba21-8e802acc1860\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"c3a71e1f-ad1f-4891-9b6c-5dbf8628278d\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"4aa2e5d0-4b24-417a-bf90-f6e739a13213\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"d82898f7-0408-4c3a-9d18-8a82965a5f23\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"af3e030c-2ec2-41ca-bd0b-f9ebf3c6d5e5\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"9700b525-2703-4833-8d9a-c8a6f1f7d046\",\"type\":\"LinearScale\"}},\"id\":\"f11ae22d-7d72-4f07-abb3-f26ff1792e66\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"formatter\":{\"id\":\"2dce0018-0aa5-42a2-a991-7708a7accddc\",\"type\":\"CategoricalTickFormatter\"},\"plot\":{\"id\":\"f11ae22d-7d72-4f07-abb3-f26ff1792e66\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"3b0547c3-3565-412e-ae1f-ef349416da5c\",\"type\":\"CategoricalTicker\"}},\"id\":\"e72e2de6-c612-4547-96d1-90561829fb0c\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"2dce0018-0aa5-42a2-a991-7708a7accddc\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"plot\":{\"id\":\"f11ae22d-7d72-4f07-abb3-f26ff1792e66\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"3b0547c3-3565-412e-ae1f-ef349416da5c\",\"type\":\"CategoricalTicker\"}},\"id\":\"913ab4a5-5c45-44ea-8448-c1932269d3d7\",\"type\":\"Grid\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"73256f87-6311-4f09-b087-95ab45e14ae6\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"5225bbb0-f352-4395-8014-cf7a106d2268\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"469d5dab-75f0-4aad-8ef9-11ccc7a17167\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"c2db4c4b-35fa-4f25-8a13-a34d63eb1938\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"9700b525-2703-4833-8d9a-c8a6f1f7d046\",\"type\":\"LinearScale\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"239665d0-2731-44f3-8c03-c0dfa7a7079f\",\"type\":\"PanTool\"},{\"id\":\"c2db4c4b-35fa-4f25-8a13-a34d63eb1938\",\"type\":\"WheelZoomTool\"},{\"id\":\"ba5efd85-1247-4c8a-b13e-5073b80f0dc7\",\"type\":\"BoxZoomTool\"},{\"id\":\"9e65a96c-89f4-4d35-9f46-77f119f7ba81\",\"type\":\"SaveTool\"},{\"id\":\"ec8b2f96-42cd-4170-be6a-29bba2809c26\",\"type\":\"ResetTool\"},{\"id\":\"cd8f81c8-63e3-4812-b8f1-dc838287e781\",\"type\":\"HelpTool\"}]},\"id\":\"c3a71e1f-ad1f-4891-9b6c-5dbf8628278d\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"3b0547c3-3565-412e-ae1f-ef349416da5c\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"af3e030c-2ec2-41ca-bd0b-f9ebf3c6d5e5\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"ebf8f156-468a-4d4d-b5d8-181884327700\",\"type\":\"VBar\"},{\"attributes\":{\"source\":{\"id\":\"f51adc48-fc8f-40e4-9642-1ee360e4565b\",\"type\":\"ColumnDataSource\"}},\"id\":\"628fb3fd-b676-49ca-8855-8017064babc7\",\"type\":\"CDSView\"}],\"root_ids\":[\"f11ae22d-7d72-4f07-abb3-f26ff1792e66\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.14\"}};\n",
       "  var render_items = [{\"docid\":\"3be2c5be-e391-40b2-8ebf-61d93d03d57d\",\"elementid\":\"55217b68-83fb-4087-9122-4a80c1b79b22\",\"modelid\":\"f11ae22d-7d72-4f07-abb3-f26ff1792e66\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "f11ae22d-7d72-4f07-abb3-f26ff1792e66"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0              0\n",
       "1      0             0        0       0       0              0\n",
       "2      0             0        0       0       0              0\n",
       "3      0             0        0       0       0              0\n",
       "6      1             1        1       0       1              0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.io import push_notebook\n",
    "from bokeh.plotting import figure, show, output_file, output_notebook\n",
    "\n",
    "target_counts = train_labels.apply(np.sum,0)\n",
    "target_counts\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "p = figure(x_range=target_names)\n",
    "p.vbar(x=target_names, top = target_counts, width=0.9)\n",
    "\n",
    "show(p)\n",
    "\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is fairly imbalanced when counting label occurrences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas to consider\n",
    "- Sampling methods\n",
    "- Custom Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering/Selection (WIP)\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/burgew/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Text preprocessor using NLTK tokenization and Lemmatization\n",
    "\n",
    "    This class is to be used in an sklean Pipeline, prior to other processers like PCA/LSA/classification\n",
    "    Attributes:\n",
    "        lower: A boolean indicating whether text should be lowercased by preprocessor\n",
    "                default: true\n",
    "        strip: A boolean indicating whether text should be stripped of surrounding whitespace, underscores and '*'\n",
    "                default: true\n",
    "        stopwords: A set of words to be used as stop words and thus ignored during tokenization\n",
    "                default: built-in English stop words\n",
    "        punct: A set of punctuation characters that should be ignored\n",
    "                default: None\n",
    "        lemmatizer: An object that should be used to lemmatize tokens\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stopwords=None, punct=None,\n",
    "                 lower=True, strip=True):\n",
    "        self.lower      = lower\n",
    "        self.strip      = strip\n",
    "        self.stopwords  = stopwords or set(sw.words('english'))\n",
    "        self.punct      = punct or set(string.punctuation)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return [\" \".join(doc) for doc in X]\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            list(self.tokenize(doc)) for doc in X\n",
    "        ]\n",
    "\n",
    "    def tokenize(self, document):\n",
    "\n",
    "        # Break the document into sentences\n",
    "        for sent in sent_tokenize(unicode(document,'utf-8')):\n",
    "\n",
    "            # Break the sentence into part of speech tagged tokens\n",
    "            for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "                # Apply preprocessing to the token\n",
    "                token = token.lower() if self.lower else token\n",
    "                token = token.strip() if self.strip else token\n",
    "                token = token.strip('_') if self.strip else token\n",
    "                token = token.strip('*') if self.strip else token\n",
    "\n",
    "                # If stopword, ignore token and continue\n",
    "                if token in self.stopwords:\n",
    "                    continue\n",
    "\n",
    "                # If punctuation, ignore token and continue\n",
    "                if all(char in self.punct for char in token):\n",
    "                    continue\n",
    "\n",
    "                # Lemmatize the token and yield\n",
    "                lemma = self.lemmatize(token, tag)\n",
    "                \n",
    "                # S\n",
    "                yield lemma\n",
    "\n",
    "    def lemmatize(self, token, tag):\n",
    "        tag = {\n",
    "            'N': wn.NOUN,\n",
    "            'V': wn.VERB,\n",
    "            'R': wn.ADV,\n",
    "            'J': wn.ADJ\n",
    "        }.get(tag[0], wn.NOUN)\n",
    "\n",
    "        return self.lemmatizer.lemmatize(token, tag)\n",
    "\n",
    "def identity(arg):\n",
    "    \"\"\"\n",
    "    Simple identity function works as a passthrough.\n",
    "    \"\"\"\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "This block uses the NLTKPreprocessor to tokenize the input data and then the TfidfVectorizer to vectorize it. The NLTKPreprocessor will ignore English stop words and will lemmatize where possible. The vectorizer ignores words occuring in fewer than 5 documents, which sufficed to reduce the size of the words vector significantly. Also, the vectorizer will limit the total features (words) to 15000, prioritizing the most valuable ones with highest TF-IDF score.\n",
    "\n",
    "Note that in this case the tokenization available by default in TfidfVectorizer is disabled, since that is handled by the NLTKPreprocessor. This made it clear that tokenization is by far more expensive (time) than vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, errno\n",
    "\n",
    "def remove_file(filename):\n",
    "\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these these statements to generate new Preprocessing/Vectorization results each time        \n",
    "# Leaving them commented will result in pickling of these results and reusing them for the next run\n",
    "# \n",
    "#remove_file('train_preproc_data.pickle')\n",
    "#remove_file('train_tfidf_counts.pickle')\n",
    "#remove_file('dev_preproc_data.pickle')\n",
    "#remove_file('dev_tfidf_counts.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing of training data...\n",
      "Completed tokenization/preprocessing of training data in 599.39 seconds\n",
      "Starting vectorization of training data...\n",
      "Completed vectorization of training data in 22.62 seconds\n",
      "Starting preprocessing of dev data...\n",
      "Completed tokenization/preprocessing of dev data in 253.83 seconds\n",
      "\n",
      "Starting vectorization of dev data...\n",
      "Completed vectorization of dev data in 3.51 seconds\n",
      "\n",
      "Vocabulary (tfidf) size is: 30000\n",
      "Sample vocabulary from TfidfVectorizer:\n",
      "          count\n",
      "\"\"—           0\n",
      "(“            1\n",
      "(→            2\n",
      "(𒁳)          3\n",
      ")‎            4\n",
      ",’            5\n",
      ",”            6\n",
      ".—            7\n",
      ".— dαlus      8\n",
      ".’            9\n",
      "None\n",
      "...\n",
      "       count\n",
      "✍      29990\n",
      "。      29991\n",
      "・      29992\n",
      "竜龙     29993\n",
      "見学     29994\n",
      "見学 迷惑  29995\n",
      "迷惑     29996\n",
      "連絡     29997\n",
      "連絡 見学  29998\n",
      "，      29999\n",
      "None\n",
      "Number of nonzero entries in matrix: 3713222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    counts\n",
       "6        4\n",
       "12       1\n",
       "16       1\n",
       "42       4\n",
       "43       3\n",
       "44       1\n",
       "51       2\n",
       "55       4\n",
       "56       3\n",
       "58       2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "np.random.seed(455)\n",
    "\n",
    "# This preprocessor will be used to process data prior to vectorization\n",
    "nltkPreprocessor = NLTKPreprocessor()\n",
    "    \n",
    "# Note that this vectorizer is created with a passthru tokenizer(identity), no preprocessor and no lowercasing\n",
    "# This is to account for the NLTKPreprocessor already taking care of these.\n",
    "tfidfVector = TfidfVectorizer(ngram_range=(1,2), min_df=5, max_features=30000,\n",
    "                              tokenizer=identity, preprocessor=None, lowercase=False)\n",
    "\n",
    "pickle_file_name = 'train_preproc_data.pickle'\n",
    "if (not os.path.exists(pickle_file_name)):\n",
    "    print \"Starting preprocessing of training data...\"\n",
    "    start_train_preproc = time.time()\n",
    "    nltkPreprocessor.fit(train_data)\n",
    "    train_preproc_data = nltkPreprocessor.transform(train_data)\n",
    "    finish_train_preproc = time.time()\n",
    "    print \"Completed tokenization/preprocessing of training data in {:.2f} seconds\".format(finish_train_preproc-start_train_preproc)\n",
    "    \n",
    "    with open(pickle_file_name,'w') as pickle_file:\n",
    "        pickle.dump(train_preproc_data,pickle_file)\n",
    "else:\n",
    "    with open(pickle_file_name,'r') as pickle_file:\n",
    "        train_preproc_data = pickle.load(pickle_file)\n",
    "\n",
    "pickle_file_name = 'train_tfidf_counts.pickle'\n",
    "if (not os.path.exists(pickle_file_name)):\n",
    "    \n",
    "    # Generating new TF-IDF train counts means we need to then re-apply LSA to the results, so remove the LSA results\n",
    "    remove_file('lsa_train_counts.pickle')\n",
    "    \n",
    "    print \"Starting vectorization of training data...\"\n",
    "    start_train_vectors = time.time()\n",
    "    train_tfidf_counts = tfidfVector.fit_transform(train_preproc_data)\n",
    "    finish_train_vectors = time.time()\n",
    "    print \"Completed vectorization of training data in {:.2f} seconds\".format(finish_train_vectors-start_train_vectors)\n",
    "    \n",
    "    with open(pickle_file_name,'w') as pickle_file:\n",
    "        pickle.dump(train_tfidf_counts,pickle_file)\n",
    "else:\n",
    "    with open(pickle_file_name,'r') as pickle_file:\n",
    "        train_tfidf_counts = pickle.load(pickle_file)\n",
    "    \n",
    "pickle_file_name = 'dev_preproc_data.pickle'\n",
    "if (not os.path.exists(pickle_file_name)):\n",
    "    print \"\\nStarting preprocessing of dev data...\"\n",
    "    start_dev_preproc = time.time()\n",
    "    nltkPreprocessor.fit(dev_data)\n",
    "    dev_preproc_data = nltkPreprocessor.transform(dev_data)\n",
    "    finish_dev_preproc = time.time()\n",
    "    print \"Completed tokenization/preprocessing of dev data in {:.2f} seconds\".format(finish_dev_preproc-start_dev_preproc)\n",
    "\n",
    "    with open(pickle_file_name,'w') as pickle_file:\n",
    "        pickle.dump(dev_preproc_data,pickle_file)\n",
    "else:\n",
    "    with open(pickle_file_name,'r') as pickle_file:\n",
    "        dev_preproc_data = pickle.load(pickle_file)\n",
    "    \n",
    "pickle_file_name = 'dev_tfidf_counts.pickle'\n",
    "if (not os.path.exists(pickle_file_name)):\n",
    "    \n",
    "    \n",
    "    # Generating new TF-IDF dev counts means we need to then re-apply LSA to the results, so remove the LSA results\n",
    "    remove_file('lsa_dev_counts.pickle')\n",
    "    \n",
    "    print \"Starting vectorization of dev data...\"\n",
    "    start_dev_vectors = time.time()\n",
    "    dev_tfidf_counts = tfidfVector.transform(dev_preproc_data)\n",
    "    finish_dev_vectors = time.time()\n",
    "    print \"Completed vectorization of dev data in {:.2f} seconds\".format(finish_dev_vectors-start_dev_vectors)\n",
    "\n",
    "    with open(pickle_file_name,'w') as pickle_file:\n",
    "        pickle.dump(dev_tfidf_counts,pickle_file)\n",
    "else:\n",
    "    with open(pickle_file_name,'r') as pickle_file:\n",
    "        dev_tfidf_counts = pickle.load(pickle_file)\n",
    "\n",
    "print(\"\\nVocabulary (tfidf) size is: {}\").format(len(tfidfVector.vocabulary_))\n",
    "vocab_entries = {k: tfidfVector.vocabulary_[k] for k in tfidfVector.vocabulary_.keys()}\n",
    "vocab_entries = pd.Series(vocab_entries).to_frame()\n",
    "vocab_entries.columns = ['count']\n",
    "vocab_entries = vocab_entries.sort_values(by='count')\n",
    "\n",
    "print(\"Sample vocabulary from TfidfVectorizer:\")\n",
    "print(pp.pprint(vocab_entries.head(10)))\n",
    "print(\"...\")\n",
    "print(pp.pprint(vocab_entries.tail(10)))\n",
    "print(\"Number of nonzero entries in matrix: {}\").format(train_tfidf_counts.nnz)\n",
    "\n",
    "# sample column wise sum, we can see that an observation can have multiple classes.\n",
    "count_df = pd.DataFrame(train_labels.apply(np.sum,1), columns = [\"counts\"])\n",
    "count_df = count_df[((count_df[\"counts\"] >= 1))]\n",
    "count_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA/LSA\n",
    "    Principal Component Analysis (PCA) and Latent Semantic Analysis (LSA) are both operations that use Singular Value Decomposition to reduce the dimensionality of a dataset. PCA is applied to a term-covariance matrix, whereas LSA is applied to a term-document matrix. As such, LSA is appropriate for machine learning algorithms using scikit-learn TfidfVectorizer. Additionally PCA, as implemented in scikit-learn, cannot handle the sparse matrices that are produced by such vectorization tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these these statements to generate new LSA Feature Reduction results each time        \n",
    "# Leaving them commented will result in pickling of these results and reusing them for the next run\n",
    "# \n",
    "#remove_file('lsa_train_counts.pickle')\n",
    "#remove_file('lsa_dev_counts.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LSA on train counts with 3000 components...\n",
      "Train counts transform took 43.80 minutes.\n",
      "Starting LSA on dev counts with 3000 components...\n",
      "Dev counts transform took 40.77 minutes.\n"
     ]
    }
   ],
   "source": [
    "target_components = len(tfidfVector.vocabulary_)/10\n",
    "\n",
    "pickle_file_name = 'lsa_train_counts.pickle'\n",
    "if (not os.path.exists(pickle_file_name)):\n",
    "    svd = TruncatedSVD(n_components=target_components, algorithm='arpack')\n",
    "    print \"Starting LSA on train counts with {} components...\".format(target_components)\n",
    "    train_start=time.time()\n",
    "    lsa_train_counts = svd.fit_transform(train_tfidf_counts)\n",
    "    train_stop=time.time()\n",
    "    print \"Train counts transform took {:.2f} minutes.\".format((train_stop-train_start)/60)\n",
    "    \n",
    "    with open(pickle_file_name,'w') as pickle_file:\n",
    "        pickle.dump(dev_preproc_data,pickle_file)\n",
    "else:\n",
    "    with open(pickle_file_name,'r') as pickle_file:\n",
    "        dev_preproc_data = pickle.load(pickle_file)\n",
    "    \n",
    "pickle_file_name = 'lsa_dev_counts.pickle'\n",
    "if (not os.path.exists(pickle_file_name)):\n",
    "    print \"Starting LSA on dev counts with {} components...\".format(target_components)\n",
    "    dev_start=time.time()\n",
    "    lsa_dev_counts = svd.fit_transform(dev_tfidf_counts)\n",
    "    dev_stop=time.time()\n",
    "    print \"Dev counts transform took {:.2f} minutes.\".format((dev_stop-dev_start)/60)\n",
    "    \n",
    "    with open(pickle_file_name,'w') as pickle_file:\n",
    "        pickle.dump(dev_preproc_data,pickle_file)\n",
    "else:\n",
    "    with open(pickle_file_name,'r') as pickle_file:\n",
    "        dev_preproc_data = pickle.load(pickle_file)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier (Neural Net) - shallow - both Train and Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification with Neural Net (sklearn.MLPClassifier)\n",
    "In choosing a neural net model for text classification, the output layer should have the same number of nodes as the number of classification labels. In this case, there are 6 labels and as such not only will the output layer have 6 nodes, but the final hidden layer as well. The input layer will have the same number of nodes as features, normally, and ideally the initial hidden layer will be between that and the number of classes.\n",
    "\n",
    "In this case, we're limiting our feature set to 15,000 features (words), and it was not possible to use a number of initial hidden layer nodes at all close to that, running this process on a Macbook. So, setting the initial hidden layer to 12 gave at least some benefit of being less than the number of features and greater than the number of output classes. This (12,6) model is the one that ended up producing best (most accurate) results.\n",
    "\n",
    "Note that, nod toward deeper learning, a (10,8,6) model was also tested, but this ended up demonstrating overfitting, with a signficantly higher accuracy score on test data than on dev data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling with MLPClassifier (shallow/wide Net)\n",
      "Train data CV score for class toxic is 0.93, after 16.98 minutes.\n",
      "Train data CV score for class severe_toxic is 0.87, after 9.16 minutes.\n",
      "Train data CV score for class obscene is 0.93, after 11.79 minutes.\n",
      "Train data CV score for class threat is 0.93, after 4.06 minutes.\n",
      "Train data CV score for class insult is 0.91, after 13.57 minutes.\n",
      "Train data CV score for class identity_hate is 0.91, after 7.62 minutes.\n",
      "Full shallow/wide Train Neural Net cross-val across all labels with train data took 63.17 minutes.\n",
      "Mean shallow/wide Train ROC_AUC for MLPClassifier: 0.91\n",
      "DEV data CV score for class toxic is 0.90, after 6.35 minutes.\n",
      "DEV data CV score for class severe_toxic is 0.91, after 3.20 minutes.\n",
      "DEV data CV score for class obscene is 0.94, after 3.37 minutes.\n",
      "DEV data CV score for class threat is 0.92, after 1.45 minutes.\n",
      "DEV data CV score for class insult is 0.89, after 3.93 minutes.\n",
      "DEV data CV score for class identity_hate is 0.91, after 2.28 minutes.\n",
      "Full shallow/wide Neural Net cross-val across all labels with dev data took 20.58 minutes.\n",
      "Mean shallow/wide DEV ROC_AUC for MLPClassifier: 0.91\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "#from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n",
    "\n",
    "\n",
    "\n",
    "print(\"Modelling with MLPClassifier (shallow/wide Net)\")\n",
    "\n",
    "# Testing testing/cross-val with shallow/wide Neural Net for both train and dev dataprediction_output = []\n",
    "scores_output = []\n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    label_CV_start = time.time()\n",
    "\n",
    "    # This Multi-Layer Perceptron classifier will be setup with hidden layers of 6 and 6 each, with tanh activation\n",
    "    # Running a 3-way cross-validation for a single label takes between 10 and 20 minutes, dependenging on the machine.\n",
    "    # The mean AUC for train and dev was 93%.\n",
    "    \n",
    "    # Changing the Net to (12,6) hidden layers gave an AUC of 94%. This was likely aided by the LSA that wasn't in place\n",
    "    # for the earlier 93% test.\n",
    "    \n",
    "    # Changing to try (18,6) hidden layers resulted in 93% again, for both Train and Dev\n",
    "    \n",
    "    # Changed back to (12,6) for both\n",
    "    \n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(24,12), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(lsa_train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, lsa_train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    label_CV_finish = time.time()\n",
    "    print('Train data CV score for class {} is {:.2f}, after {:.2f} minutes.'.format(name, cv_score, \n",
    "                                                                                (label_CV_finish-label_CV_start)/60))\n",
    "full_CV_finish = time.time()\n",
    "print(\"Full shallow/wide Train Neural Net cross-val across all labels with train data took {:.2f} minutes.\".format((full_CV_finish-full_CV_start)/60))\n",
    "\n",
    "print(\"Mean shallow/wide Train ROC_AUC for MLPClassifier: {:.2f}\".format(np.mean(scores_output)))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    label_CV_start = time.time()\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(24,12), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(lsa_dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, lsa_dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    label_CV_finish = time.time()\n",
    "    print('DEV data CV score for class {} is {:.2f}, after {:.2f} minutes.'.format(name, cv_score, \n",
    "                                                                                (label_CV_finish-label_CV_start)/60))\n",
    "full_CV_finish = time.time()\n",
    "print(\"Full shallow/wide Neural Net cross-val across all labels with dev data took {:.2f} minutes.\".format((full_CV_finish-full_CV_start)/60))\n",
    "print(\"Mean shallow/wide DEV ROC_AUC for MLPClassifier: {:.2f}\".format(np.mean(scores_output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier (Neural Net) - shallow - just Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "#from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n",
    "\n",
    "\n",
    "\n",
    "print(\"Training with MLPClassifier (shallow/wide Net)\")\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(12,6), activation='tanh', learning_rate='adaptive')\n",
    "\n",
    "# Training with shallow/wide Neural Net \n",
    "for name in target_names:\n",
    "    label_CV_start = time.time()\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(12,6), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(lsa_train_counts, train_labels[name])\n",
    "    label_CV_finish = time.time()\n",
    "    print('Train data for class {} completed, after {:.2f} minutes.'.format(name, cv_score,\n",
    "                                                                            (label_CV_finish-label_CV_start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier (Neural Net) - deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "#from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n",
    "\n",
    "\n",
    "\n",
    "print(\"Modelling with MLPClassifier (deep/thinner)\")\n",
    "\n",
    "# Testing testing/cross-val with deep/thinner Neural Net for both train and dev data\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    label_CV_start = time.time()\n",
    "    \n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(10,8,6), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(lsa_train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, lsa_train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    label_CV_finish = time.time()\n",
    "    print('Train data CV score for class {} is {:.2f}, after {:.2f} minutes.'.format(name, cv_score, \n",
    "                                                                                (label_CV_finish-label_CV_start)/60))\n",
    "full_CV_finish = time.time()\n",
    "print(\"Full deep/thin Neural Net Train cross-val across all labels took {:.2f} minutes.\".format((full_CV_finish-full_CV_start)/60))\n",
    "\n",
    "print(\"Mean deep/thin Train ROC_AUC for MLPClassifier: {:.2f}\".format(np.mean(scores_output)))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "full_CV_start = time.time()\n",
    "for name in target_names:\n",
    "    label_CV_start = time.time()\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(10,8,6), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(lsa_dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, lsa_dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    label_CV_finish = time.time()\n",
    "    print('DEV data CV score for class {} is {:.2f}, after {:.2f} minutes.'.format(name, cv_score, \n",
    "                                                                                (label_CV_finish-label_CV_start)/60))\n",
    "full_CV_finish = time.time()\n",
    "print(\"Full deep/thin Neural Net DEV cross-val across all labels took {:.2f} minutes.\".format((full_CV_finish-full_CV_start)/60))\n",
    "print(\"Mean neep/thin DEV ROC_AUC for MLPClassifier: {:.2f}\".format(np.mean(scores_output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### First Pass Logistic Regression with sag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'sag'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver)\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver) \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### First Pass Logistic Regression with saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver)\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver) \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Here's the same using tfidf and saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver)\n",
    "    classifier.fit(train_tfidf_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_tfidf_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver) \n",
    "    classifier.fit(dev_tfidf_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_tfidf_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Original counts with saga and L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1')\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1') \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf with saga and L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "solver = 'saga'\n",
    "\n",
    "print(\"Modelling with {} solver\".format(solver))\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1')\n",
    "    classifier.fit(train_tfidf_counts, train_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_tfidf_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Training data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "    \n",
    "print(\"Mean Training ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver=solver,penalty='l1') \n",
    "    classifier.fit(dev_tfidf_counts, dev_labels[name])\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, dev_tfidf_counts, dev_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('Dev data CV score for class {} is {}'.format(name, cv_score))\n",
    "\n",
    "        \n",
    "print(\"Mean Dev ROC_AUC for {} solver: {}\").format(solver, np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "dev_Vector = CountVectorizer(ngram_range=(1,1))\n",
    "dev_counts = countVector.fit_transform(dev_data)\n",
    "\n",
    "pred_dt = pd.DataFrame()\n",
    "scores_dev = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    scores_dev.append(cv_score)\n",
    "    output = classifier.predict(dev_counts)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels[name], output)\n",
    "    print('Dev score for class {} is {}'.format(name, metrics.auc(fpr,tpr)))\n",
    "    pred_dt[name] = classifier.predict_proba(dev_counts)[:, 1]\n",
    "    \n",
    "    \n",
    "print(\"Mean(dev) ROC_AUC: {}\").format(np.mean(scores_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on dev set is worse than training set, thus evidence of overfitting and a need for performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is multi-label since each observation can be classified as multiple fields.  This is an important distinction from multi-class where each prediction can only be one label.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df\n",
    "train_labels[\"toxic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Text Preprocessing - training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "np.random.seed(455)\n",
    "\n",
    "# This preprocessor will be used to process data prior to vectorization\n",
    "nltkPreprocessor = NLTKPreprocessor()\n",
    "    \n",
    "# Note that this vectorizer is created with a passthru tokenizer(identity), no preprocessor and no lowercasing\n",
    "# This is to account for the NLTKPreprocessor already taking care of these.\n",
    "tfidfVector = TfidfVectorizer(ngram_range=(1,1), min_df=5, max_features=15000,\n",
    "                              tokenizer=identity, preprocessor=None, lowercase=False)\n",
    "\n",
    "print \"Starting final preprocessing of training data...\"\n",
    "start_train_preproc = time.time()\n",
    "trainPreprocData = nltkPreprocessor.fit_transform(train_df[\"comment_text\"])\n",
    "finish_train_preproc = time.time()\n",
    "print \"Completed tokenization/preprocessing of training data in {:.2f} seconds\".format((finish_train_preproc-start_train_preproc))\n",
    "\n",
    "print \"Starting final preprocessing of test data...\"\n",
    "start_test_preproc = time.time()\n",
    "testPreprocData = nltkPreprocessor.transform(test_df[\"comment_text\"])\n",
    "finish_test_preproc = time.time()\n",
    "print \"Completed tokenization/preprocessing of test data in {:.2f} seconds\".format((finish_test_preproc-start_test_preproc))\n",
    "\n",
    "print \"Starting vectorization of training data...\"\n",
    "start_train_vectors = time.time()\n",
    "finalTrainCounts = tfidfVector.fit_transform(trainPreprocData)\n",
    "finish_train_vectors = time.time()\n",
    "print \"Completed vectorization of training data in {:.2f} seconds\".format((finish_train_vectors-start_train_vectors))\n",
    "\n",
    "print \"Starting vectorization of test data...\"\n",
    "start_test_vectors = time.time()\n",
    "finalTestCounts = tfidfVector.transform(testPreprocData)\n",
    "finish_test_vectors = time.time()\n",
    "print \"Completed vectorization of test data in {:.2f} seconds\".format((finish_test_vectors-start_test_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final LSA Feature Selection - training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_components = len(tfidfVector.vocabulary_)/10\n",
    "svd = TruncatedSVD(n_components=target_components, algorithm='arpack')\n",
    "print \"Starting LSA on train counts with {} components...\".format(target_components)\n",
    "train_start=time.time()\n",
    "lsaTrainCounts = svd.fit_transform(finalTraincounts)\n",
    "train_stop=time.time()\n",
    "print \"Train counts transform took {:.2f} seconds.\".format(train_stop-train_start)\n",
    "\n",
    "target_components = len(tfidfVector.vocabulary_)/10\n",
    "svd = TruncatedSVD(n_components=target_components, algorithm='arpack')\n",
    "print \"Starting LSA on test counts with {} components...\".format(target_components)\n",
    "train_start=time.time()\n",
    "lsaTestCounts = svd.fit_transform(finalTestCounts)\n",
    "train_stop=time.time()\n",
    "print \"Test counts transform took {:.2f} seconds.\".format(train_stop-train_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final MLPClassifier Training and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "#from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n",
    "\n",
    "prediction_submission = pd.DataFrame()\n",
    "prediction_submission[\"id\"] = test_df[\"id\"]\n",
    "\n",
    "print(\"Training with MLPClassifier (shallow/wide Net)\")\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(12,6), activation='tanh', learning_rate='adaptive')\n",
    "\n",
    "# Training with shallow/wide Neural Net \n",
    "for name in target_names:\n",
    "    \n",
    "    label_train_start = time.time()\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(12,6), activation='tanh', learning_rate='adaptive')\n",
    "    classifier.fit(lsaTrainCounts, train_df[name])\n",
    "    label_train_finish = time.time()\n",
    "    print('Training for class {} completed, after {:.2f} minutes.'.format(name, \n",
    "                                                                          (label_train_finish-label_train_start)/60))\n",
    "    label_predict_start = time.time()\n",
    "    prediction_submission[name] = classifier.predict_proba(lsaTestCounts)[:, 1]\n",
    "    label_predict_finish = time.time()\n",
    "    print('Prediction for class {} completed, after {:.2f} minutes.'.format(name,\n",
    "                                                                    (label_predict_finish-label_predict_start)/60))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "print(prediction_submission.head(10)) # print frame output \n",
    "prediction_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submission - based on test preprocessing, LSA feature selection and MLPClassifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_submission = pd.DataFrame()\n",
    "prediction_submission[\"id\"] = test_df[\"id\"]\n",
    "\n",
    "# new vector object for all train data for submission\n",
    "finalTrainVector = CountVectorizer()\n",
    "finalTrainCount = finalTrainVector.fit_transform(train_df[\"comment_text\"])\n",
    "\n",
    "# TODO: Using pipelines can clean up repetitive processes\n",
    "# test set up\n",
    "#testVector = CountVectorizer()\n",
    "testCount = finalTrainVector.transform(test_df[\"comment_text\"])\n",
    "\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') #sag is one kind of solver optimize for multi-label\n",
    "    clf = classifier.fit(finalTrainCount, train_df[name])\n",
    "    prediction_submission[name] = clf.predict_proba(testCount)[:, 1]\n",
    "    #print(prediction_submission)\n",
    "\n",
    "    \n",
    "print(prediction_submission.head(10)) # print frame output \n",
    "prediction_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "prediction_submission = pd.DataFrame()\n",
    "prediction_submission[\"id\"] = test_df[\"id\"]\n",
    "\n",
    "# new vector object for all train data for submission\n",
    "finalTrainVector = CountVectorizer()\n",
    "finalTrainCount = finalTrainVector.fit_transform(train_df[\"comment_text\"])\n",
    "\n",
    "# TODO: Using pipelines can clean up repetitive processes\n",
    "# test set up\n",
    "#testVector = CountVectorizer()\n",
    "testCount = finalTrainVector.transform(test_df[\"comment_text\"])\n",
    "\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') #sag is one kind of solver optimize for multi-label\n",
    "    clf = classifier.fit(finalTrainCount, train_df[name])\n",
    "    prediction_submission[name] = clf.predict_proba(testCount)[:, 1]\n",
    "    #print(prediction_submission)\n",
    "\n",
    "    \n",
    "print(prediction_submission.head(10)) # print frame output \n",
    "prediction_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame contains the output for each class and is saved in a pandas data frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
