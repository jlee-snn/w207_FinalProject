{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#scipy imports\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import bokeh\n",
    "#! pip install bokeh\n",
    "\n",
    "# target classes\n",
    "target_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training observations: 159571\n",
      "training data shape: (112268,)\n",
      "training label shape: (112268, 6)\n",
      "dev label shape: (47303, 6)\n",
      "labels names: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "# read frames localy through csv\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# Random index generator for splitting training data\n",
    "# Note: Each rerun of cell will create new splits.\n",
    "randIndexCut = np.random.rand(len(train_df)) < 0.7\n",
    "\n",
    "#S plit up data\n",
    "test_data = test_df[\"comment_text\"]\n",
    "dev_data, dev_labels = train_df[~randIndexCut][\"comment_text\"], train_df[~randIndexCut][target_names]\n",
    "train_data, train_labels = train_df[randIndexCut][\"comment_text\"], train_df[randIndexCut][target_names]\n",
    "tiny_data,small_data = train_df[:200][\"comment_text\"],train_df[:1000][\"comment_text\"]\n",
    "tiny_labels,small_labels = train_df[:200][target_names],train_df[:1000][target_names]\n",
    "\n",
    "\n",
    "print('total training observations:', train_df.shape[0])\n",
    "print('training data shape:', train_data.shape)\n",
    "print('training label shape:', train_labels.shape)\n",
    "print('dev label shape:', dev_labels.shape)\n",
    "print ('labels names:', target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of corpus 462986\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "word_corpus = '../data/words.txt'\n",
    "word_file = open(word_corpus, 'rt')\n",
    "large_word_corpus = word_file.read()\n",
    "word_file.close\n",
    "large_word_corpus = large_word_corpus.split()\n",
    "large_word_corpus = [ word.lower() for word in large_word_corpus]\n",
    "large_word_corpus = set(large_word_corpus)\n",
    "\n",
    "good_words_list = brown.words()\n",
    "good_word_set = set([word.lower() for word in good_words_list])\n",
    "#punctuation = re.sub(\"[\\'\\-]\",'',string.punctuation)\n",
    "punctuation = \"[\\!\\?\\\"\\#\\$\\%\\&\\(\\)\\*\\+\\,\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\]\\^\\_\\`\\{\\|\\}\\~\\']\"\n",
    "print('Size of corpus ' + str(len(large_word_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from http://norvig.com/spell-correct.html\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('../data/big.txt').read()))\n",
    "\n",
    "def norvig_P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def norvig_correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(norvig_candidates(word), key=norvig_P)\n",
    "\n",
    "def norvig_candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to support finding and correcting spellings\n",
    "# using pyenchant for spell checking\n",
    "from enchant import DictWithPWL\n",
    "from enchant.checker import SpellChecker\n",
    "import difflib\n",
    "# import splitter # not useful, does a worse job than my implementation\n",
    "\n",
    "# mywords.txt currently contains:\n",
    "# - list of firstnames and surnames gathered from internet searches\n",
    "# http://www.birkenhoerdt.net/surnames-all.php?tree=1\n",
    "my_dict=DictWithPWL('en_US', \"../data/mywords.txt\")\n",
    "my_checker = SpellChecker(my_dict)\n",
    "\n",
    "# list of swear words correctly spelt courtesy of https://www.noswearing.com/\n",
    "\n",
    "def my_preprocessor(textblock):\n",
    "    # u -> you\n",
    "    # c -> see\n",
    "    # k -> okay\n",
    "    return_words = textblock\n",
    "\n",
    "#     return_words = re.sub(r\"[^A-Za-z0-9,!?*.;’´'\\/]\", \" \", return_words)\n",
    "    return_words = re.sub(r\"[^A-Za-z0-9]\", \" \", return_words)\n",
    "    return_words = re.sub(r\",\",\" \",return_words)\n",
    "    return_words = re.sub(r\"\\.\\.+\",\" \",return_words)\n",
    "    return_words = re.sub(r\"\\.\",\" \",return_words)\n",
    "    return_words = re.sub(r\"\\(\",\" \", return_words)\n",
    "    return_words = re.sub(r\"\\)\",\" \", return_words)\n",
    "    return_works = re.sub(r\"\\;\", \" \", return_words)\n",
    "    return_words = re.sub(r\":\",\" \", return_words)\n",
    "    return_words = re.sub(r\"´\", \"'\", return_words)\n",
    "    return_words = re.sub(r\"`\", \"'\", return_words)\n",
    "    return_words = re.sub(r\"''+\", \"'\", return_words)\n",
    "    return_words = re.sub(r\" '\", \" \", return_words)\n",
    "    return_words = re.sub(r\"' \", \" \", return_words)\n",
    "    return_words = re.sub(r\"\\\"\", \" \", return_words)\n",
    "    return_words = re.sub(r\"\\/\", \" \", return_words)\n",
    "    return_words = re.sub(r\"\\!\\!+\", \"!!\", return_words)\n",
    "    return_words = re.sub(r\"\\?\\?+\", \"?!\", return_words)\n",
    "    return_words = re.sub(r\"\\!\", \" !\", return_words)\n",
    "    return_words = re.sub(r\"\\?\", \" ?\", return_words)\n",
    "    return_words = re.sub(r\"\\b\\d+\\b\", \"999\", return_words)\n",
    "    # slang and abbreviations, need to be aware of capitolization and spaces\n",
    "    return_words = re.sub(r\"[Ww]on't\", \"will not\", return_words)\n",
    "    return_words = re.sub(r\"n't\", \" not\", return_words)\n",
    "    return_words = re.sub(r\"'s\\b\", \" is\", return_words)\n",
    "    return_words = re.sub(r\"\\b[Aa]bt\\b\", \"about\", return_words)\n",
    "    return return_words\n",
    "\n",
    "def trysplit(word, verbose=False):\n",
    "    split_candidates = []\n",
    "    max_proba = 0.0\n",
    "    for i in range(1,len(word)):\n",
    "        # I will only allow single letters of 'a' and 'i', all others ignored.  Pyenchant allows for\n",
    "        # any single letter to be a legitimate word, and so too does norvig.  The dictionary defines\n",
    "        # them as nouns that represent the letter, however even though several can be used in slang\n",
    "        # (e.g. k->okay, c->see, u->you) using them in conjoined words would make the splitting far\n",
    "        # too difficult and also human understanding much more difficult #howucthisk, u c?\n",
    "        if (len(word[:i]) != 1 or (word[:i].lower() == 'a' or word[:i].lower() == 'i')) and (\n",
    "            len(word[i:]) != 1 or (word[i:].lower() == 'a' or word[i:].lower() == 'i')):\n",
    "            if my_checker.check(word[:i]) and my_checker.check(word[i:]):\n",
    "                norvig_score = norvig_P(word[:i]) + norvig_P(word[i:])\n",
    "                if norvig_score > max_proba:\n",
    "                    max_proba = norvig_score\n",
    "                    split_candidates = [word[:i],word[i:]]\n",
    "    for i in range(1,len(word)):\n",
    "        for j in range(i+1,len(word)):        \n",
    "            if (len(word[:i]) != 1 or (word[:i].lower() == 'a' or word[:i].lower() == 'i')) and (\n",
    "                len(word[i:j]) != 1 or (word[i:j].lower() == 'a' or word[i:j].lower() == 'i')) and (\n",
    "                len(word[i:]) != 1 or (word[i:].lower() == 'a' or word[i:].lower() == 'i')):\n",
    "                \n",
    "                if my_checker.check(word[:i]) and my_checker.check(word[i:j]) and my_checker.check(word[j:]):\n",
    "                    norvig_score = norvig_P(word[:i]) + norvig_P(word[i:j]) + norvig_P(word[j:])\n",
    "                    if norvig_score > max_proba:\n",
    "                        max_proba = norvig_score\n",
    "                        split_candidates = [word[:i],word[i:j],word[j:]]\n",
    "    for i in range(1,len(word)):\n",
    "        for j in range(i+1,len(word)):\n",
    "            for k in range(j+1,len(word)):\n",
    "                if (len(word[:i]) != 1 or (word[:i].lower() == 'a' or word[:i].lower() == 'i')) and (\n",
    "                    len(word[i:j]) != 1 or (word[i:j].lower() == 'a' or word[i:j].lower() == 'i')) and (\n",
    "                    len(word[j:k]) != 1 or (word[j:k].lower() == 'a' or word[j:k].lower() == 'i')) and (\n",
    "                    len(word[k:]) != 1 or (word[k:].lower() == 'a' or word[k:].lower() == 'i')):\n",
    "                    verbose and print(\"making it here with i=%s j=%s k=%s %s  max_proba=%d\" %(word[:i],word[i:j],word[j:k],word[k:], max_proba))\n",
    "                    verbose and print(\"lengths are %d %d %d %d\" % (len(word[:i]), len(word[i:j]),len(word[j:k]),len(word[k:])))\n",
    "                    if my_checker.check(word[:i]) and my_checker.check(word[i:j]) and my_checker.check(word[j:k]) and my_checker.check(word[k:]):\n",
    "                        verbose and print('found words ' + word[i:] + ' ' + word[k:])\n",
    "                        norvig_score = norvig_P(word[:i]) + norvig_P(word[i:j]) + norvig_P(word[j:k]) + norvig_P(word[k:])\n",
    "                        if norvig_score > max_proba:\n",
    "                            verbose and print(\"found higher probability %d with %s %s %s %s\" % (norvig_score, word[:i], word[i:j], word[j:k], word[k:]))\n",
    "                            max_proba = norvig_score\n",
    "                            split_candidates = [word[:i],word[i:j],word[j:k],word[k:]]\n",
    "    return split_candidates\n",
    "\n",
    "def get_best_candidates(word):\n",
    "    best_words = []\n",
    "    best_ratio = 0\n",
    "    a = set(my_checker.suggest(word))\n",
    "    for b in a:\n",
    "        if not '-' in b:\n",
    "            tmp = difflib.SequenceMatcher(None, word, b).ratio()\n",
    "            if tmp > best_ratio:\n",
    "                best_words=[b]\n",
    "                best_ratio=tmp\n",
    "            elif tmp == best_ratio:\n",
    "                best_words.append(b)\n",
    "    return best_words\n",
    "    \n",
    "def fix_spellings(textinput, verbose=False):\n",
    "    words = textinput.split()\n",
    "    return_list = []\n",
    "    for word in words:\n",
    "        if my_checker.check(word) or my_checker.check(word.lower()) or word in punctuation or\\\n",
    "            any(i.isdigit() for i in word) or (word[-1].lower() == 's' and my_checker.check(word[:-1].lower())):\n",
    "            return_list.append(word)\n",
    "            # continue\n",
    "        else:            \n",
    "            candidates = get_best_candidates(word)\n",
    "            if len(candidates) == 1:\n",
    "                return_list.append(candidates.pop())\n",
    "            elif len(candidates) > 1:\n",
    "                # try another spell checker\n",
    "                nv_candidates = norvig_candidates(word)\n",
    "                tmp_set = set(nv_candidates).intersection(set(candidates))\n",
    "                if len(tmp_set) == 1:\n",
    "                    # only 1 overlap, should be correct\n",
    "                    return_list.append(tmp_set.pop())\n",
    "                elif len(nv_candidates) == 1 and next(iter(nv_candidates)) == word:\n",
    "                        # this is suspicious, pyenchants' \"suggest\" method always returns something, however if\n",
    "                        # norvigs method cannot find a suitable match within a short distance then it simply\n",
    "                        # returns the orignal word.  This section is for potentially conjoined words\n",
    "                        tmp_list=trysplit(word)\n",
    "\n",
    "                        # If we get back a list of split words then use these\n",
    "                        if len(tmp_list) != 0:\n",
    "                            return_list.extend(tmp_list)\n",
    "                            continue\n",
    "                else:\n",
    "                    # arbitrary now, just going to use the first one found from pyenchant, even though\n",
    "                    # I have seen norvig get the correct word sometimes when pyenchant gets it wrong\n",
    "                    return_list.append(candidates[0])\n",
    "    return return_list\n",
    "\n",
    "# myword='In a long discussion about thisismessedup what should I do askd'\n",
    "# print(fix_spellings(myword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my love']\n",
      "False\n",
      "['my love', 'my-love', 'ladylove', 'Mylo', 'lovely', 'Lovejoy', 'Melville', 'Malvin', 'mylo', 'malone', 'milone', 'love']\n",
      "{'move', 'glove', 'love'}\n",
      "['my love']\n"
     ]
    }
   ],
   "source": [
    "myword2='mylove'\n",
    "# trysplit(myword)\n",
    "#norvig_P('is')\n",
    "#fix_spellings('alit')\n",
    "# help(enchant)\n",
    "#myword2=\"I'm\"\n",
    "print(get_best_candidates(myword2))\n",
    "print(my_checker.check(myword2))\n",
    "print(my_checker.suggest(myword2))\n",
    "print(norvig_candidates(myword2))\n",
    "print(fix_spellings(myword2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Sorry \n",
      "\n",
      "I'm sorry I screwed around with someones talk page.  It was very bad to do.  I know how having the templates on their talk page helps you assert your dominance over them.  I know I should bow down to the almighty administrators.  But then again, I'm going to go play outside....with your mom.   76.122.79.82\n",
      "[\"I'm\", 'Sorry', \"I'm\", 'sorry', 'I', 'screwed', 'around', 'with', 'someones', 'talk', 'page', 'It', 'was', 'very', 'bad', 'to', 'do', 'I', 'know', 'how', 'having', 'the', 'templates', 'on', 'their', 'talk', 'page', 'helps', 'you', 'assert', 'your', 'dominance', 'over', 'them', 'I', 'know', 'I', 'should', 'bow', 'down', 'to', 'the', 'almighty', 'administrators', 'But', 'then', 'again', \"I'm\", 'going', 'to', 'go', 'play', 'outside', 'with', 'your', 'mom', '999', '999', '999', '999']\n"
     ]
    }
   ],
   "source": [
    "index=44\n",
    "print(train_data[index])\n",
    "print(fix_spellings(my_preprocessor(train_data[index]), verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a flag for any level of toxix or a unique number for each combination\n",
    "def bernoulli_toxic_labels (label_vector):\n",
    "    return [1 if (label_vector['toxic'][x] + label_vector['severe_toxic'][x] +\n",
    "                label_vector['obscene'][x] + label_vector['threat'][x] +\n",
    "                label_vector['insult'][x] + label_vector['identity_hate'][x]) > 0 else 0 \n",
    "            for x in label_vector.index.values]\n",
    "\n",
    "def binarize_toxic_labels (label_vector):\n",
    "    return [(label_vector['toxic'][x]*32 + label_vector['severe_toxic'][x]*16 +\n",
    "                label_vector['obscene'][x]*8 + label_vector['threat'][x]*4 +\n",
    "                label_vector['insult'][x]*2 + label_vector['identity_hate'][x]) \n",
    "            for x in label_vector.index.values]\n",
    "\n",
    "binary_train_labels = binarize_toxic_labels(train_labels)\n",
    "binary_dev_labels = binarize_toxic_labels(dev_labels)\n",
    "\n",
    "bernoulli_train_labels = bernoulli_toxic_labels(train_labels)\n",
    "bernoulli_dev_labels = bernoulli_toxic_labels(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "count_vect_plain = CountVectorizer(preprocessor=my_preprocessor)\n",
    "X_train_counts_plain = count_vect_plain.fit_transform(train_data)\n",
    "X_dev_counts_plain = count_vect_plain.transform(dev_data)\n",
    "\n",
    "tfidf_vect_plain = TfidfVectorizer(preprocessor=my_preprocessor)\n",
    "X_train_tfidf_plain = tfidf_vect_plain.fit_transform(train_data)\n",
    "X_dev_tfidf_plain = tfidf_vect_plain.transform(dev_data)\n",
    "\n",
    "count_vect_stop_words = CountVectorizer(stop_words='english',preprocessor=my_preprocessor)\n",
    "X_train_counts_stop_words = count_vect_stop_words.fit_transform(train_data)\n",
    "X_dev_counts_stop_words = count_vect_stop_words.transform(dev_data)\n",
    "\n",
    "tfidf_vect_stop_words = TfidfVectorizer(stop_words='english',preprocessor=my_preprocessor)\n",
    "X_train_tfidf_stop_words = tfidf_vect_stop_words.fit_transform(train_data)\n",
    "X_dev_tfidf_stop_words = tfidf_vect_stop_words.transform(dev_data)\n",
    "\n",
    "count_vect_stop_words_max10k = CountVectorizer(stop_words='english', max_features=10000,preprocessor=my_preprocessor)\n",
    "X_train_counts_stop_words_max10k = count_vect_stop_words_max10k.fit_transform(train_data)\n",
    "X_dev_counts_stop_words_max10k = count_vect_stop_words_max10k.transform(dev_data)\n",
    "\n",
    "tfidf_vect_stop_words_max10k = TfidfVectorizer(stop_words='english', max_features=10000,preprocessor=my_preprocessor)\n",
    "X_train_tfidf_stop_words_max10k = tfidf_vect_stop_words_max10k.fit_transform(train_data)\n",
    "X_dev_tfidf_stop_words_max10k = tfidf_vect_stop_words_max10k.transform(dev_data)\n",
    "\n",
    "count_vect_stop_words_max5k = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_counts_stop_words_max5k = count_vect_stop_words_max5k.fit_transform(train_data)\n",
    "X_dev_counts_stop_words_max5k = count_vect_stop_words_max5k.transform(dev_data)\n",
    "\n",
    "tfidf_vect_stop_words_max5k = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf_stop_words_max5k = tfidf_vect_stop_words_max5k.fit_transform(train_data)\n",
    "X_dev_tfidf_stop_words_max5k = tfidf_vect_stop_words_max5k.transform(dev_data)\n",
    "\n",
    "count_vect_max5k = CountVectorizer(max_features=5000)\n",
    "X_train_counts_max5k = count_vect_max5k.fit_transform(train_data)\n",
    "X_dev_counts_max5k = count_vect_max5k.transform(dev_data)\n",
    "\n",
    "tfidf_vect_max5k = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf_max5k = tfidf_vect_max5k.fit_transform(train_data)\n",
    "X_dev_tfidf_max5k = tfidf_vect_max5k.transform(dev_data)\n",
    "\n",
    "count_vect_max4k = CountVectorizer(max_features=4000)\n",
    "X_train_counts_max4k = count_vect_max4k.fit_transform(train_data)\n",
    "X_dev_counts_max4k = count_vect_max4k.transform(dev_data)\n",
    "\n",
    "tfidf_vect_max4k = TfidfVectorizer(max_features=4000)\n",
    "X_train_tfidf_max4k = tfidf_vect_max4k.fit_transform(train_data)\n",
    "X_dev_tfidf_max4k = tfidf_vect_max4k.transform(dev_data)\n",
    "\n",
    "count_vect_max6k = CountVectorizer(max_features=6000)\n",
    "X_train_counts_max6k = count_vect_max6k.fit_transform(train_data)\n",
    "X_dev_counts_max6k = count_vect_max6k.transform(dev_data)\n",
    "\n",
    "tfidf_vect_max6k = TfidfVectorizer(max_features=6000)\n",
    "X_train_tfidf_max6k = tfidf_vect_max6k.fit_transform(train_data)\n",
    "X_dev_tfidf_max6k = tfidf_vect_max6k.transform(dev_data)\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_f1_auc_on_train_dev(dev_vector, train_vector, name):\n",
    "    multinomial_nb_class = MultinomialNB().fit(train_vector, train_labels[name])\n",
    "    predicted_labels_dev = multinomial_nb_class.predict(dev_vector)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels[name], predicted_labels_dev)\n",
    "    predicted_labels_train = multinomial_nb_class.predict(train_vector)\n",
    "    fpr1, tpr1, thresholds1 = metrics.roc_curve(train_labels[name], predicted_labels_train)\n",
    "    f1scoredev = metrics.f1_score(dev_labels[name],predicted_labels_dev,average='micro')\n",
    "    f1scoretrain = metrics.f1_score(train_labels[name],predicted_labels_train,average='micro')\n",
    "    aucdev = metrics.auc(fpr,tpr)\n",
    "    auctrain = metrics.auc(fpr1,tpr1)\n",
    "    return f1scoredev,aucdev,f1scoretrain,auctrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  set          label     f1dev    aucdev   f1train  auctrain\n",
      "0          CountPlain          toxic  0.942498  0.773851  0.947786  0.818918\n",
      "1          TfidfPlain          toxic  0.921717  0.599574  0.923317  0.616814\n",
      "2      CountStopWords          toxic  0.943746  0.776646  0.951295  0.827418\n",
      "3      TfidfStopWords          toxic  0.924466  0.611925  0.927531  0.635766\n",
      "4   CountStopWords10k          toxic  0.946748  0.812008  0.948961  0.822992\n",
      "5   TfidfStopWords10k          toxic  0.946621  0.760780  0.947991  0.770859\n",
      "6    CountStopWords5k          toxic  0.947805  0.823325  0.948730  0.828803\n",
      "7    TfidfStopWords5k          toxic  0.949559  0.747556  0.949246  0.750520\n",
      "8             Count5k          toxic  0.938714  0.839973  0.941132  0.848808\n",
      "9            TfidfS5k          toxic  0.949559  0.747556  0.949246  0.750520\n",
      "10            Count4k          toxic  0.939052  0.833640  0.940838  0.841222\n",
      "11           TfidfS5k          toxic  0.947868  0.738899  0.947973  0.743093\n",
      "12            Count6k          toxic  0.938757  0.842705  0.941586  0.853184\n",
      "13           TfidfS6k          toxic  0.949475  0.748713  0.949353  0.751652\n",
      "14         CountPlain   severe_toxic  0.980847  0.704307  0.978827  0.755346\n",
      "15         TfidfPlain   severe_toxic  0.990339  0.500000  0.989828  0.501721\n",
      "16     CountStopWords   severe_toxic  0.981692  0.720986  0.980297  0.785660\n",
      "17     TfidfStopWords   severe_toxic  0.990339  0.500000  0.989864  0.501305\n",
      "18  CountStopWords10k   severe_toxic  0.977930  0.813343  0.978427  0.841683\n",
      "19  TfidfStopWords10k   severe_toxic  0.988563  0.596611  0.988394  0.615802\n",
      "20   CountStopWords5k   severe_toxic  0.984060  0.845691  0.984261  0.851153\n",
      "21   TfidfStopWords5k   severe_toxic  0.990994  0.589171  0.990719  0.593059\n",
      "22            Count5k   severe_toxic  0.981819  0.871645  0.981553  0.865005\n",
      "23           TfidfS5k   severe_toxic  0.990994  0.589171  0.990719  0.593059\n",
      "24            Count4k   severe_toxic  0.982242  0.869692  0.981829  0.861666\n",
      "25           TfidfS5k   severe_toxic  0.991142  0.600080  0.990630  0.607364\n",
      "26            Count6k   severe_toxic  0.981904  0.874938  0.981562  0.869793\n",
      "27           TfidfS6k   severe_toxic  0.990994  0.578337  0.990594  0.579515\n",
      "28         CountPlain        obscene  0.960362  0.766805  0.960202  0.809068\n",
      "29         TfidfPlain        obscene  0.953470  0.563253  0.954555  0.583406\n",
      "..                ...            ...       ...       ...       ...       ...\n",
      "54            Count6k         threat  0.985688  0.762753  0.987040  0.865527\n",
      "55           TfidfS6k         threat  0.996977  0.500000  0.996989  0.499987\n",
      "56         CountPlain         insult  0.958311  0.740321  0.958528  0.789896\n",
      "57         TfidfPlain         insult  0.953682  0.535318  0.954956  0.553488\n",
      "58     CountStopWords         insult  0.959432  0.749046  0.960853  0.801033\n",
      "59     TfidfStopWords         insult  0.953724  0.532086  0.955170  0.550352\n",
      "60  CountStopWords10k         insult  0.960003  0.819513  0.961396  0.833028\n",
      "61  TfidfStopWords10k         insult  0.963110  0.720677  0.963400  0.733142\n",
      "62   CountStopWords5k         insult  0.965372  0.833930  0.965618  0.836959\n",
      "63   TfidfStopWords5k         insult  0.968607  0.719296  0.968629  0.725380\n",
      "64            Count5k         insult  0.958523  0.856971  0.958002  0.858337\n",
      "65           TfidfS5k         insult  0.968607  0.719296  0.968629  0.725380\n",
      "66            Count4k         insult  0.958692  0.853399  0.957869  0.851686\n",
      "67           TfidfS5k         insult  0.967972  0.713878  0.968646  0.724791\n",
      "68            Count6k         insult  0.958480  0.858982  0.958314  0.862604\n",
      "69           TfidfS6k         insult  0.968353  0.715502  0.968673  0.724036\n",
      "70         CountPlain  identity_hate  0.982454  0.594858  0.980431  0.633983\n",
      "71         TfidfPlain  identity_hate  0.990804  0.500000  0.991333  0.501008\n",
      "72     CountStopWords  identity_hate  0.986512  0.587796  0.984867  0.655126\n",
      "73     TfidfStopWords  identity_hate  0.990804  0.500000  0.991342  0.500502\n",
      "74  CountStopWords10k  identity_hate  0.973828  0.724879  0.975478  0.786310\n",
      "75  TfidfStopWords10k  identity_hate  0.990614  0.524957  0.991084  0.535629\n",
      "76   CountStopWords5k  identity_hate  0.981164  0.752494  0.982791  0.803794\n",
      "77   TfidfStopWords5k  identity_hate  0.991269  0.530981  0.991859  0.544195\n",
      "78            Count5k  identity_hate  0.977147  0.759577  0.977705  0.805317\n",
      "79           TfidfS5k  identity_hate  0.991269  0.530981  0.991859  0.544195\n",
      "80            Count4k  identity_hate  0.977803  0.747382  0.978213  0.793820\n",
      "81           TfidfS5k  identity_hate  0.991100  0.536590  0.991788  0.547736\n",
      "82            Count6k  identity_hate  0.976999  0.758364  0.977580  0.807809\n",
      "83           TfidfS6k  identity_hate  0.991206  0.525255  0.991832  0.537028\n",
      "\n",
      "[84 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "scores_all=pd.DataFrame(columns=['set','label','f1dev','aucdev','f1train','auctrain'])\n",
    "\n",
    "for name in target_names:\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_plain,\n",
    "                                                   dev_vector=X_dev_counts_plain,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountPlain',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_plain,\n",
    "                                                   dev_vector=X_dev_tfidf_plain,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfPlain',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_stop_words,\n",
    "                                                   dev_vector=X_dev_counts_stop_words,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountStopWords',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_stop_words,\n",
    "                                                   dev_vector=X_dev_tfidf_stop_words,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfStopWords',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_stop_words_max10k,\n",
    "                                                   dev_vector=X_dev_counts_stop_words_max10k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountStopWords10k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_stop_words_max10k,\n",
    "                                                   dev_vector=X_dev_tfidf_stop_words_max10k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfStopWords10k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_stop_words_max5k,\n",
    "                                                   dev_vector=X_dev_counts_stop_words_max5k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountStopWords5k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_stop_words_max5k,\n",
    "                                                   dev_vector=X_dev_tfidf_stop_words_max5k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfStopWords5k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_max5k,\n",
    "                                                   dev_vector=X_dev_counts_max5k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['Count5k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_max5k,\n",
    "                                                   dev_vector=X_dev_tfidf_max5k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfS5k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_max4k,\n",
    "                                                   dev_vector=X_dev_counts_max4k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['Count4k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_max4k,\n",
    "                                                   dev_vector=X_dev_tfidf_max4k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfS5k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_max6k,\n",
    "                                                   dev_vector=X_dev_counts_max6k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['Count6k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_max6k,\n",
    "                                                   dev_vector=X_dev_tfidf_max6k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfS6k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    \n",
    "\n",
    "    # not measuring here for each name\n",
    "print(scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:57:20.780986\n",
      "22:57:20.854956\n",
      "22:57:20.857472\n",
      "04:58:13.734259\n",
      "07:37:37.114353\n"
     ]
    }
   ],
   "source": [
    "count_vect_plain_pre = CountVectorizer(preprocessor=my_preprocessor)\n",
    "print(str(datetime.datetime.now().time()))\n",
    "X_train_counts_plain_pre = count_vect_plain_pre.fit_transform(tiny_data)\n",
    "print(str(datetime.datetime.now().time()))\n",
    "count_vect_plain_pre_token = CountVectorizer(preprocessor=my_preprocessor, tokenizer=fix_spellings)\n",
    "print(str(datetime.datetime.now().time()))\n",
    "X_train_counts_plain_pre_token = count_vect_plain_pre_token.fit_transform(train_data)\n",
    "print(str(datetime.datetime.now().time()))\n",
    "X_dev_counts_plain_pre_token = count_vect_plain_pre_token.transform(dev_data)\n",
    "print(str(datetime.datetime.now().time()))\n",
    "#X_dev_counts_plain_pre = count_vect_plain_pre.transform(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  set          label     f1dev    aucdev   f1train  auctrain\n",
      "0          CountPlain          toxic  0.942498  0.773851  0.947786  0.818918\n",
      "1          TfidfPlain          toxic  0.921717  0.599574  0.923317  0.616814\n",
      "2      CountStopWords          toxic  0.943746  0.776646  0.951295  0.827418\n",
      "3      TfidfStopWords          toxic  0.924466  0.611925  0.927531  0.635766\n",
      "4   CountStopWords10k          toxic  0.946748  0.812008  0.948961  0.822992\n",
      "5   TfidfStopWords10k          toxic  0.946621  0.760780  0.947991  0.770859\n",
      "6    CountStopWords5k          toxic  0.945521  0.794479  0.946378  0.801147\n",
      "7    TfidfStopWords5k          toxic  0.945669  0.753434  0.945675  0.759185\n",
      "8          CountPlain   severe_toxic  0.980847  0.704307  0.978827  0.755346\n",
      "9          TfidfPlain   severe_toxic  0.990339  0.500000  0.989828  0.501721\n",
      "10     CountStopWords   severe_toxic  0.981692  0.720986  0.980297  0.785660\n",
      "11     TfidfStopWords   severe_toxic  0.990339  0.500000  0.989864  0.501305\n",
      "12  CountStopWords10k   severe_toxic  0.977930  0.813343  0.978427  0.841683\n",
      "13  TfidfStopWords10k   severe_toxic  0.988563  0.596611  0.988394  0.615802\n",
      "14   CountStopWords5k   severe_toxic  0.978352  0.802723  0.978908  0.829314\n",
      "15   TfidfStopWords5k   severe_toxic  0.987316  0.646902  0.987450  0.650115\n",
      "16         CountPlain        obscene  0.960362  0.766805  0.960202  0.809068\n",
      "17         TfidfPlain        obscene  0.953470  0.563253  0.954555  0.583406\n",
      "18     CountStopWords        obscene  0.962518  0.780306  0.963658  0.826634\n",
      "19     TfidfStopWords        obscene  0.954443  0.567761  0.956221  0.592512\n",
      "20  CountStopWords10k        obscene  0.962983  0.841610  0.964629  0.855783\n",
      "21  TfidfStopWords10k        obscene  0.966937  0.766089  0.967123  0.774594\n",
      "22   CountStopWords5k        obscene  0.964315  0.827477  0.964745  0.836463\n",
      "23   TfidfStopWords5k        obscene  0.967465  0.772455  0.967203  0.777088\n",
      "24         CountPlain         threat  0.992601  0.557066  0.990327  0.581465\n",
      "25         TfidfPlain         threat  0.996977  0.500000  0.996998  0.499991\n",
      "26     CountStopWords         threat  0.996152  0.544903  0.994691  0.598535\n",
      "27     TfidfStopWords         threat  0.996977  0.500000  0.996998  0.499991\n",
      "28  CountStopWords10k         threat  0.983468  0.677978  0.984555  0.794341\n",
      "29  TfidfStopWords10k         threat  0.996977  0.503486  0.996998  0.505943\n",
      "30   CountStopWords5k         threat  0.982940  0.705600  0.983762  0.796920\n",
      "31   TfidfStopWords5k         threat  0.996956  0.510447  0.996963  0.507414\n",
      "32         CountPlain         insult  0.958311  0.740321  0.958528  0.789896\n",
      "33         TfidfPlain         insult  0.953682  0.535318  0.954956  0.553488\n",
      "34     CountStopWords         insult  0.959432  0.749046  0.960853  0.801033\n",
      "35     TfidfStopWords         insult  0.953724  0.532086  0.955170  0.550352\n",
      "36  CountStopWords10k         insult  0.960003  0.819513  0.961396  0.833028\n",
      "37  TfidfStopWords10k         insult  0.963110  0.720677  0.963400  0.733142\n",
      "38   CountStopWords5k         insult  0.960320  0.801172  0.960790  0.807753\n",
      "39   TfidfStopWords5k         insult  0.963850  0.733879  0.963240  0.736733\n",
      "40         CountPlain  identity_hate  0.982454  0.594858  0.980431  0.633983\n",
      "41         TfidfPlain  identity_hate  0.990804  0.500000  0.991333  0.501008\n",
      "42     CountStopWords  identity_hate  0.986512  0.587796  0.984867  0.655126\n",
      "43     TfidfStopWords  identity_hate  0.990804  0.500000  0.991342  0.500502\n",
      "44  CountStopWords10k  identity_hate  0.973828  0.724879  0.975478  0.786310\n",
      "45  TfidfStopWords10k  identity_hate  0.990614  0.524957  0.991084  0.535629\n",
      "46   CountStopWords5k  identity_hate  0.974441  0.717217  0.975915  0.758426\n",
      "47   TfidfStopWords5k  identity_hate  0.990254  0.549828  0.990558  0.564489\n",
      "48   CountPlainPreTok          toxic  0.942160  0.790216  0.947884  0.828995\n",
      "49   CountPlainPreTok   severe_toxic  0.980044  0.723403  0.978462  0.763859\n",
      "50   CountPlainPreTok        obscene  0.959664  0.790403  0.960300  0.826048\n",
      "51   CountPlainPreTok         threat  0.991100  0.563285  0.989774  0.581188\n",
      "52   CountPlainPreTok         insult  0.957254  0.761527  0.958724  0.806495\n",
      "53   CountPlainPreTok  identity_hate  0.980509  0.600709  0.979513  0.636586\n",
      "54   CountPlainPreTok          toxic  0.942160  0.790216  0.947884  0.828995\n",
      "55   CountPlainPreTok   severe_toxic  0.980044  0.723403  0.978462  0.763859\n",
      "56   CountPlainPreTok        obscene  0.959664  0.790403  0.960300  0.826048\n",
      "57   CountPlainPreTok         threat  0.991100  0.563285  0.989774  0.581188\n",
      "58   CountPlainPreTok         insult  0.957254  0.761527  0.958724  0.806495\n",
      "59   CountPlainPreTok  identity_hate  0.980509  0.600709  0.979513  0.636586\n"
     ]
    }
   ],
   "source": [
    "for name in target_names:\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_plain_pre_token,\n",
    "                                                   dev_vector=X_dev_counts_plain_pre_token,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountPlainPreTok',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "\n",
    "print(scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model counts_plain_pre_token_toxic to saved/counts_plain_pre_token_toxic.sav\n",
      "Finished saving saved/counts_plain_pre_token_toxic.sav\n",
      "Saving to saved/counts_plain_pre_token_toxic_predict_dev.csv\n",
      "Finished saving saved/counts_plain_pre_token_toxic_predict_dev.csv\n",
      "Saving to saved/counts_plain_pre_token_toxic_predict_dev_proba.csv\n",
      "Finished saving saved/counts_plain_pre_token_toxic_predict_dev_proba.csv\n",
      "Saving to saved/counts_plain_pre_token_toxic_predict_dev_proba_log.csv\n",
      "Finished saving saved/counts_plain_pre_token_toxic_predict_dev_proba_log.csv\n",
      "Saving model counts_plain_pre_token_severe_toxic to saved/counts_plain_pre_token_severe_toxic.sav\n",
      "Finished saving saved/counts_plain_pre_token_severe_toxic.sav\n",
      "Saving to saved/counts_plain_pre_token_severe_toxic_predict_dev.csv\n",
      "Finished saving saved/counts_plain_pre_token_severe_toxic_predict_dev.csv\n",
      "Saving to saved/counts_plain_pre_token_severe_toxic_predict_dev_proba.csv\n",
      "Finished saving saved/counts_plain_pre_token_severe_toxic_predict_dev_proba.csv\n",
      "Saving to saved/counts_plain_pre_token_severe_toxic_predict_dev_proba_log.csv\n",
      "Finished saving saved/counts_plain_pre_token_severe_toxic_predict_dev_proba_log.csv\n",
      "Saving model counts_plain_pre_token_obscene to saved/counts_plain_pre_token_obscene.sav\n",
      "Finished saving saved/counts_plain_pre_token_obscene.sav\n",
      "Saving to saved/counts_plain_pre_token_obscene_predict_dev.csv\n",
      "Finished saving saved/counts_plain_pre_token_obscene_predict_dev.csv\n",
      "Saving to saved/counts_plain_pre_token_obscene_predict_dev_proba.csv\n",
      "Finished saving saved/counts_plain_pre_token_obscene_predict_dev_proba.csv\n",
      "Saving to saved/counts_plain_pre_token_obscene_predict_dev_proba_log.csv\n",
      "Finished saving saved/counts_plain_pre_token_obscene_predict_dev_proba_log.csv\n",
      "Saving model counts_plain_pre_token_threat to saved/counts_plain_pre_token_threat.sav\n",
      "Finished saving saved/counts_plain_pre_token_threat.sav\n",
      "Saving to saved/counts_plain_pre_token_threat_predict_dev.csv\n",
      "Finished saving saved/counts_plain_pre_token_threat_predict_dev.csv\n",
      "Saving to saved/counts_plain_pre_token_threat_predict_dev_proba.csv\n",
      "Finished saving saved/counts_plain_pre_token_threat_predict_dev_proba.csv\n",
      "Saving to saved/counts_plain_pre_token_threat_predict_dev_proba_log.csv\n",
      "Finished saving saved/counts_plain_pre_token_threat_predict_dev_proba_log.csv\n",
      "Saving model counts_plain_pre_token_insult to saved/counts_plain_pre_token_insult.sav\n",
      "Finished saving saved/counts_plain_pre_token_insult.sav\n",
      "Saving to saved/counts_plain_pre_token_insult_predict_dev.csv\n",
      "Finished saving saved/counts_plain_pre_token_insult_predict_dev.csv\n",
      "Saving to saved/counts_plain_pre_token_insult_predict_dev_proba.csv\n",
      "Finished saving saved/counts_plain_pre_token_insult_predict_dev_proba.csv\n",
      "Saving to saved/counts_plain_pre_token_insult_predict_dev_proba_log.csv\n",
      "Finished saving saved/counts_plain_pre_token_insult_predict_dev_proba_log.csv\n",
      "Saving model counts_plain_pre_token_identity_hate to saved/counts_plain_pre_token_identity_hate.sav\n",
      "Finished saving saved/counts_plain_pre_token_identity_hate.sav\n",
      "Saving to saved/counts_plain_pre_token_identity_hate_predict_dev.csv\n",
      "Finished saving saved/counts_plain_pre_token_identity_hate_predict_dev.csv\n",
      "Saving to saved/counts_plain_pre_token_identity_hate_predict_dev_proba.csv\n",
      "Finished saving saved/counts_plain_pre_token_identity_hate_predict_dev_proba.csv\n",
      "Saving to saved/counts_plain_pre_token_identity_hate_predict_dev_proba_log.csv\n",
      "Finished saving saved/counts_plain_pre_token_identity_hate_predict_dev_proba_log.csv\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model_name, model):\n",
    "    filename='saved/' + model_name + '.sav'\n",
    "    print('Saving model %s to %s' % (model_name, filename))\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    print('Finished saving %s' % (filename))\n",
    "\n",
    "def save_csv_results(name, data):\n",
    "    filename='saved/' + name + '.csv'\n",
    "    print('Saving to %s' % (filename))\n",
    "    pd.DataFrame(data).to_csv(filename)\n",
    "    print('Finished saving %s' % (filename))\n",
    "\n",
    "for name in target_names:\n",
    "    multinomial_nb_class = MultinomialNB().fit(X_train_counts_plain_pre_token, train_labels[name])\n",
    "    predicted_labels_dev = multinomial_nb_class.predict(X_dev_counts_plain_pre_token)\n",
    "    predicted_labels_proba_dev = multinomial_nb_class.predict_proba(X_dev_counts_plain_pre_token)\n",
    "    predicted_labels_log_proba_dev = multinomial_nb_class.predict_log_proba(X_dev_counts_plain_pre_token)\n",
    "    model_name = 'counts_plain_pre_token_' + name\n",
    "    model_name_predict = model_name + '_predict_dev'\n",
    "    model_name_predict_proba = model_name_predict + '_proba'\n",
    "    model_name_predict_log_proba = model_name_predict_proba + '_log'\n",
    "    save_model(model_name=model_name, model=multinomial_nb_class)\n",
    "    save_csv_results(name=model_name_predict, data=predicted_labels_dev)\n",
    "    save_csv_results(name=model_name_predict_proba, data=predicted_labels_proba_dev)\n",
    "    save_csv_results(name=model_name_predict_log_proba, data=predicted_labels_log_proba_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
