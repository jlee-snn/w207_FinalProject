{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of things were tested for this model\n",
    "\n",
    "* A variety of different parameters and vectorizers\n",
    "  * Count and Tfidf vectors\n",
    "  * Variety of feature sizes\n",
    "  * Data preprocessed or not\n",
    "  * Removing stop words and accents\n",
    "* Calculation of three types of scoring, precision, recall and auc\n",
    "\n",
    "Lessons learned\n",
    "* Experience is key: being novice has made this process take much longer\n",
    "\n",
    "* Interpreters (I'm sure everyone knows this) are slow, and for the moment this is single threaded so even slower.  A side requiment of this is that hardware matters, particularly faster cores and plenty of memory.\n",
    "\n",
    "* While we can in some cases brute force the best parameters there are situations where unless we have time and a cluster for processing power, we must instead rely on educated guesswork and compromises.  The educated guesswork can obviously be helped by research and experience.\n",
    "\n",
    "* Gaussian Naive Bayes is not suitable for the very sparse inputs we are using so not testing these out.\n",
    "\n",
    "\n",
    "Results:  \n",
    "\n",
    "<TABLE>\n",
    "<TR><TH> label</TH><TH> model</TH><TH> alpha</TH><TH> type</TH><TH> preprocessor</TH><TH> tokenizer</TH><TH> max_features</TH><TH> stop_words</TH><TH> lowercase</TH><TH> strip_accents</TH><TH> score_type</TH><TH> score </TH></TR>\n",
    "<TR><TD> toxic</TD><TD> multi</TD><TD> 10</TD><TD> tfidf</TD><TD> 0</TD><TD> 0</TD><TD> None</TD><TD> None</TD><TD> TRUE</TD><TD> None</TD><TD> precision</TD><TD> 1 </TD></TR>\n",
    "<TR><TD> severe_toxic</TD><TD> multi</TD><TD> 10</TD><TD> tfidf</TD><TD> 0</TD><TD> 0</TD><TD> 6000</TD><TD> english</TD><TD> FALSE</TD><TD> None</TD><TD> precision</TD><TD> 0.8 </TD></TR>\n",
    "<TR><TD> obscene</TD><TD> multi</TD><TD> 2</TD><TD> tfidf</TD><TD> 0</TD><TD> 0</TD><TD> None</TD><TD> None</TD><TD> TRUE</TD><TD> None</TD><TD> precision</TD><TD> 1 </TD></TR>\n",
    "<TR><TD> threat</TD><TD> multi</TD><TD> 0.5</TD><TD> tfidf</TD><TD> 0</TD><TD> 0</TD><TD> None</TD><TD> None</TD><TD> FALSE</TD><TD> None</TD><TD> precision</TD><TD> 1 </TD></TR>\n",
    "<TR><TD> insult</TD><TD> multi</TD><TD> 2</TD><TD> tfidf</TD><TD> 0</TD><TD> 0</TD><TD> None</TD><TD> None</TD><TD> FALSE</TD><TD> None</TD><TD> precision</TD><TD> 1 </TD></TR>\n",
    "<TR><TD> identity_hate</TD><TD> multi</TD><TD> 2</TD><TD> tfidf</TD><TD> 1</TD><TD> 0</TD><TD> 3000</TD><TD> english</TD><TD> FALSE</TD><TD> None</TD><TD> precision</TD><TD> 0.884615 </TD></TR>\n",
    "<TR><TH> Average</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> 0.947435833 </TH></TR>\n",
    "</TABLE>\n",
    "\n",
    "<TABLE>\n",
    "<TR><TH> label</TH><TH> model</TH><TH> alpha</TH><TH> type</TH><TH> preprocessor</TH><TH> tokenizer</TH><TH> max_features</TH><TH> stop_words</TH><TH> lowercase</TH><TH> strip_accents</TH><TH> score_type</TH><TH> score </TH></TR>\n",
    "<TR><TD> toxic</TD><TD> bern</TD><TD> 1</TD><TD> tfidf</TD><TD> 0</TD><TD> 0</TD><TD> 10000</TD><TD> english</TD><TD> TRUE</TD><TD> unicode</TD><TD> recall</TD><TD> 0.886398 </TD></TR>\n",
    "<TR><TD> severe_toxic</TD><TD> bern</TD><TD> 0.5</TD><TD> tfidf</TD><TD> 0</TD><TD> 0</TD><TD> 10000</TD><TD> english</TD><TD> TRUE</TD><TD> None</TD><TD> recall</TD><TD> 0.953782 </TD></TR>\n",
    "<TR><TD> obscene</TD><TD> bern</TD><TD> 1</TD><TD> tfidf</TD><TD> 1</TD><TD> 0</TD><TD> 10000</TD><TD> english</TD><TD> FALSE</TD><TD> None</TD><TD> recall</TD><TD> 0.897975 </TD></TR>\n",
    "<TR><TD> threat</TD><TD> bern</TD><TD> 0.5</TD><TD> tfidf</TD><TD> 0</TD><TD> 0</TD><TD> 3000</TD><TD> None</TD><TD> TRUE</TD><TD> None</TD><TD> recall</TD><TD> 0.868421 </TD></TR>\n",
    "<TR><TD> insult</TD><TD> bern</TD><TD> 1</TD><TD> tfidf</TD><TD> 0</TD><TD> 0</TD><TD> 10000</TD><TD> english</TD><TD> TRUE</TD><TD> unicode</TD><TD>recall</TD><TD> 0.885738 </TD></TR>\n",
    "<TR><TD> identity_hate</TD><TD> bern</TD><TD> 0.5</TD><TD> tfidf</TD><TD> 1</TD><TD> 0</TD><TD> 4000</TD><TD> None</TD><TD> FALSE</TD><TD> None</TD><TD> recall</TD><TD> 0.88785 </TD></TR>\n",
    "<TR><TH> Average</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> 0.896694 </TH></TR>\n",
    "</TABLE>\n",
    "\n",
    "<TABLE>\n",
    "<TR><TH> label</TH><TH> model</TH><TH> alpha</TH><TH> type</TH><TH> preprocessor</TH><TH> tokenizer</TH><TH> max_features</TH><TH> stop_words</TH><TH> lowercase</TH><TH> strip_accents</TH><TH> score_type</TH><TH> score </TH></TR>\n",
    "<TR><TD> toxic</TD><TD> bern</TD><TD> 15</TD><TD> tfidf</TD><TD> 1</TD><TD> 0</TD><TD> 4000</TD><TD> english</TD><TD> FALSE</TD><TD> None</TD><TD> roc_auc</TD><TD> 0.858937 </TD></TR>\n",
    "<TR><TD> severe_toxic</TD><TD> bern</TD><TD> 2</TD><TD> tfidf</TD><TD> 1</TD><TD> 0</TD><TD> 4000</TD><TD> english</TD><TD> FALSE</TD><TD> None</TD><TD> roc_auc</TD><TD> 0.93949 </TD></TR>\n",
    "<TR><TD> obscene</TD><TD> bern</TD><TD> 10</TD><TD> tfidf</TD><TD> 1</TD><TD> 0</TD><TD> 4000</TD><TD> english</TD><TD> FALSE</TD><TD> None</TD><TD> roc_auc</TD><TD> 0.888569 </TD></TR>\n",
    "<TR><TD> threat</TD><TD> bern</TD><TD> 0.5</TD><TD> tfidf</TD><TD> 1</TD><TD> 0</TD><TD> 4000</TD><TD> None</TD><TD> FALSE</TD><TD> None</TD><TD> roc_auc</TD><TD> 0.899946 </TD></TR>\n",
    "<TR><TD> insult</TD><TD> bern</TD><TD> 10</TD><TD> tfidf</TD><TD> 1</TD><TD> 0</TD><TD> 3000</TD><TD> english</TD><TD> FALSE</TD><TD> None</TD><TD> roc_auc</TD><TD> 0.872004 </TD></TR>\n",
    "<TR><TD> identity_hate</TD><TD> bern</TD><TD> 1</TD><TD> tfidf</TD><TD> 1</TD><TD> 0</TD><TD> 4000</TD><TD> english</TD><TD> FALSE</TD><TD> None</TD><TD> roc_auc</TD><TD> 0.886601 </TD></TR>\n",
    "<TR><TH> Average</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> &nbsp;</TH><TH> 0.8909245 </TH></TR>\n",
    "</TABLE>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#scipy imports\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import bokeh\n",
    "#! pip install bokeh\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import string\n",
    "from sklearn import metrics\n",
    "\n",
    "# target classes\n",
    "target_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total training observations:', 111828)\n",
      "('training data shape:', (111828,))\n",
      "('training label shape:', (111828, 6))\n",
      "('dev label shape:', (47743, 6))\n",
      "('labels names:', ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n"
     ]
    }
   ],
   "source": [
    "# read frames localy through csv\n",
    "train_df = pd.read_csv(\"../data/new_train.csv\")\n",
    "test_df = pd.read_csv(\"../data/new_test.csv\")\n",
    "\n",
    "# # Random index generator for splitting training data\n",
    "# # Note: Each rerun of cell will create new splits.\n",
    "# randIndexCut = np.random.rand(len(train_df)) < 0.7\n",
    "\n",
    "# #S plit up data\n",
    "# test_data = test_df[\"comment_text\"]\n",
    "# dev_data, dev_labels = train_df[~randIndexCut][\"comment_text\"], train_df[~randIndexCut][target_names]\n",
    "# train_data, train_labels = train_df[randIndexCut][\"comment_text\"], train_df[randIndexCut][target_names]\n",
    "\n",
    "dev_data, dev_labels = test_df[\"comment_text\"], test_df[target_names]\n",
    "train_data, train_labels = train_df[\"comment_text\"], train_df[target_names]\n",
    "\n",
    "print('total training observations:', train_df.shape[0])\n",
    "print('training data shape:', train_data.shape)\n",
    "print('training label shape:', train_labels.shape)\n",
    "print('dev label shape:', dev_labels.shape)\n",
    "print('labels names:', target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Courtesy of Walt\n",
    "\n",
    "import nltk\n",
    "# These imports enable the use of NLTKPreprocessor in an sklearn Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import punkt as punkt\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "\n",
    "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Text preprocessor using NLTK tokenization and Lemmatization\n",
    "\n",
    "    This class is to be used in an sklean Pipeline, prior to other processers like PCA/LSA/classification\n",
    "    Attributes:\n",
    "        lower: A boolean indicating whether text should be lowercased by preprocessor\n",
    "                default: True\n",
    "        strip: A boolean indicating whether text should be stripped of surrounding whitespace, underscores and '*'\n",
    "                default: True\n",
    "        stopwords: A set of words to be used as stop words and thus ignored during tokenization\n",
    "                default: built-in English stop words\n",
    "        punct: A set of punctuation characters that should be ignored\n",
    "                default: None\n",
    "        lemmatizer: An object that should be used to lemmatize tokens\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stopwords=None, punct=None,\n",
    "                 lower=True, strip=True):\n",
    "        self.lower      = lower\n",
    "        self.strip      = strip\n",
    "        self.stopwords  = stopwords or set(sw.words('english'))\n",
    "        self.punct      = punct or set(string.punctuation)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return [\" \".join(doc) for doc in X]\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            list(self.tokenize(doc)) for doc in X\n",
    "        ]\n",
    "\n",
    "    def tokenize(self, document):\n",
    "\n",
    "        # Break the document into sentences\n",
    "        for sent in sent_tokenize(unicode(document, 'utf8')):\n",
    "\n",
    "            # Break the sentence into part of speech tagged tokens\n",
    "            for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "                # Apply preprocessing to the token\n",
    "                token = token.lower() if self.lower else token\n",
    "                token = token.strip() if self.strip else token\n",
    "                token = token.strip('_') if self.strip else token\n",
    "                token = token.strip('*') if self.strip else token\n",
    "\n",
    "                # If stopword, ignore token and continue\n",
    "                if token in self.stopwords:\n",
    "                    continue\n",
    "\n",
    "                # If punctuation, ignore token and continue\n",
    "                if all(char in self.punct for char in token):\n",
    "                    continue\n",
    "\n",
    "                # Lemmatize the token and yield\n",
    "                lemma = self.lemmatize(token, tag)\n",
    "                \n",
    "                # S\n",
    "                yield lemma\n",
    "\n",
    "    def lemmatize(self, token, tag):\n",
    "        tag = {\n",
    "            'N': wn.NOUN,\n",
    "            'V': wn.VERB,\n",
    "            'R': wn.ADV,\n",
    "            'J': wn.ADJ\n",
    "        }.get(tag[0], wn.NOUN)\n",
    "\n",
    "        return self.lemmatizer.lemmatize(token, tag)\n",
    "\n",
    "def identity(arg):\n",
    "    \"\"\"\n",
    "    Simple identity function works as a passthrough.\n",
    "    \"\"\"\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of scores on dev set and training set\n",
    "def score_classifier_train_on_dev(dev_vector, train_vector, dev_labels, train_labels, label, ctype, pscoring):\n",
    "    \"\"\"This function takes two vectors, one for training and one for dev, trains them\n",
    "    on the selected Naive Bayes model, then depending on the scoring required it\n",
    "    finds the optimal alpha for the particular scoring and calculates that score from\n",
    "    predictions on the dev set.\n",
    "    \n",
    "    Args:\n",
    "        dev_vector: the processed vector of dev data\n",
    "        train_vector: the processed vector of training data\n",
    "        dev_labels: the vector of each of the 6 lables for the dev set\n",
    "        train_labels: the vector of labels for the training set\n",
    "        label (string) : the label name to test\n",
    "        ctype: multi, gaus or bern, choses between multinomial, gaussian or bernoulli Naive Bayes\n",
    "        scoring: should be one of roc_auc, precision, or recall\n",
    "        \n",
    "    Returns:\n",
    "        alpha: the best alpha value for this classifier\n",
    "        score: the score when using this classifier to predict dev\n",
    "    \"\"\"\n",
    "    alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0, 15.0, 20.0, 50.0, 100.0]}\n",
    "\n",
    "    if pscoring != 'precision' and pscoring != 'recall' and pscoring != 'roc_auc' and pscoring != 'f1':\n",
    "        print('score_classifier_train_on_dev: Invalid input parameter %s' %(pscoring))\n",
    "        return\n",
    "    \n",
    "    if ctype == 'multi':\n",
    "        nb_class = MultinomialNB().fit(train_vector, train_labels[label])\n",
    "    elif ctype == 'bern':\n",
    "        nb_class = BernoulliNB().fit(train_vector, train_labels[label])\n",
    "    elif ctype == 'gaus':\n",
    "        nb_class = GaussianNB().fit(train_vector, train_labels[label])\n",
    "    else:\n",
    "        print('ctype = %s, error' % (ctype))\n",
    "        return\n",
    "    \n",
    "    # use this to generate the best fitting model for AUC scoring\n",
    "    clf = GridSearchCV(nb_class, param_grid = alphas, scoring=pscoring)\n",
    "    clf.fit(train_vector, train_labels[label])\n",
    "    \n",
    "    # Predict the dev vector\n",
    "    predicted_labels_dev = clf.predict(dev_vector)\n",
    "    \n",
    "    rscore = 0 # return score\n",
    "    # now calculate the score of interested based on the function parameter pscoring\n",
    "    if pscoring == 'precision':\n",
    "        rscore = metrics.precision_score(dev_labels[label], predicted_labels_dev)\n",
    "    elif pscoring == 'recall':\n",
    "        rscore = metrics.recall_score(dev_labels[label], predicted_labels_dev)\n",
    "    elif pscoring == 'f1':\n",
    "        rscore = metrics.f1_score(dev_labels[label], predicted_labels_dev)\n",
    "    else:\n",
    "        rscore = metrics.roc_auc_score(dev_labels[label], predicted_labels_dev)\n",
    "\n",
    "    return clf.best_params_, rscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_all_vectors(my_feature_sizes = [None, 3000, 4000, 5000, 6000, 10000],\n",
    "                       my_stop_words = [None, 'english'],\n",
    "                       my_strip_accents = [None, 'ascii', 'unicode'],\n",
    "                       my_lowercase = [True, False],\n",
    "                       basetrain_data=[],\n",
    "                       basedev_data=[],\n",
    "                       preprocessedtrain_data=[],\n",
    "                       preprocesseddev_data=[],\n",
    "                       verbose=False):\n",
    "    \"\"\"This loops through the lists in the parameters creating 2 vector sets for each combination, \n",
    "    one CountVectorizer and one for TfidfVectorizer.  It allows for both preprocessed and unprocessed\n",
    "    input data, and in the case of pre-processed it does not use the options to strip_accents or\n",
    "    lowercase the data, those options are assumed to have occurred when the data was preprocessed.\n",
    "    \n",
    "    Args:\n",
    "        my_feature_size (list of sizes): Non-empty list of feature sizes to use in vectors\n",
    "        my_stop_words (list of stop_words): Provided to the vectorizers\n",
    "        my_strip_accents (list of options): Provided to the vectorizers\n",
    "        my_lowercase (bool): Provided to the vectorizer\n",
    "        basetrain_data (Opt: list of input data): this is the base training data, no preprocessing\n",
    "        basedev_data (Opt: list of input data): this is the base dev data, no preprocessing\n",
    "        preprocessedtrain_data (Opt: list of input data): this is the base training data that received preprocessing\n",
    "        preprocesseddev_data= (Opt: list of input data): this is the base dev data that received preprocessing\n",
    "        verbose (bool): to write progress outputs\n",
    "        \n",
    "    Returns: \n",
    "        vectors_all (Pandas Datafram) : a dataframe where each line contains the unique count or tfidf vector\n",
    "            along with the set of parameters that were used to create it.\n",
    "    \"\"\"\n",
    "    \n",
    "    vectors_all=pd.DataFrame(columns=['vectortrain', 'vectordata','type','preprocessor', 'tokenizer',\n",
    "                                      'max_features', 'stop_words', 'lowercase', 'strip_accents' ])\n",
    "\n",
    "    index=1\n",
    "    if len(basetrain_data) != 0 and len(basedev_data) != 0:\n",
    "        # we have unprocessed data so create vectors for it\n",
    "        for i in my_feature_sizes:\n",
    "            for x in my_stop_words:\n",
    "                for y in my_strip_accents:\n",
    "                    for z in my_lowercase:\n",
    "                        if (verbose == True):\n",
    "                            print(\"%s: Processing the next two vectors from base data, index %d\" % (str(datetime.datetime.now().time()),index))\n",
    "                            index +=1\n",
    "\n",
    "                        # Create a count vectorizer with the provided parameters\n",
    "                        vect = CountVectorizer(max_features=i, stop_words=x, strip_accents=y, lowercase=z)\n",
    "                        # Train the unpreprocessed training set\n",
    "                        vect_train = vect.fit_transform(train_data)\n",
    "                        # Transform the dev set for fuuture predictions\n",
    "                        vect_dev = vect.transform(dev_data)\n",
    "                        # add into the output data frame with the list of vectors chosen\n",
    "                        vectors_all.loc[vectors_all.shape[0]] = [vect_train, vect_dev, 'count', 0, 0, i, x, z, y]\n",
    "\n",
    "                        # Now create tfidf vectorizer for the set of parameters\n",
    "                        vect = TfidfVectorizer(max_features=i, stop_words=x, strip_accents=y, analyzer='word',lowercase=z)\n",
    "                        vect_train = vect.fit_transform(train_data)\n",
    "                        vect_dev = vect.transform(dev_data)\n",
    "                        vectors_all.loc[vectors_all.shape[0]] = [vect_train, vect_dev, 'tfidf', 0, 0, i, x, z, y]\n",
    "\n",
    "    index=1\n",
    "    if len(preprocessedtrain_data) != 0 and len(preprocesseddev_data) != 0:\n",
    "        # Separate loop for the preprocessed data as we cannot set the lowercase or strip accents parameters on these\n",
    "        for i in my_feature_sizes:\n",
    "            for x in my_stop_words:\n",
    "                print(\"%s: Processing the next two vectors from preprocessed data, index %d\" % (str(datetime.datetime.now().time()),index))\n",
    "                index +=1\n",
    "\n",
    "                # Same but with the preprocessed data\n",
    "                vect = CountVectorizer(tokenizer=identity, max_features=i, stop_words=x,strip_accents=None, lowercase=False)\n",
    "                vect_train= vect.fit_transform(train_preproc_data)\n",
    "                vect_dev= vect.transform(dev_preproc_data)\n",
    "                vectors_all.loc[vectors_all.shape[0]] = [vect_train, vect_dev, 'count', 1, 0, i, x, False, None]\n",
    "\n",
    "                # Create a tfidf but fit with the preprocessed data\n",
    "                vect = TfidfVectorizer(tokenizer=identity,max_features=i, stop_words=x,strip_accents=None, lowercase=False)\n",
    "                vect_train = vect.fit_transform(train_preproc_data)\n",
    "                vect_dev = vect.transform(dev_preproc_data)\n",
    "                vectors_all.loc[vectors_all.shape[0]] = [vect_train, vect_dev, 'tfidf', 1, 0, i, x, False, None]\n",
    "\n",
    "    if verbose == True:\n",
    "        print('%s: Completed create_all_vectors' % (str(datetime.datetime.now().time())))\n",
    "        \n",
    "    return vectors_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1auc_all_models (vectors_all, score_types = ['precision', 'recall', 'roc_auc'], \n",
    "                                model_types = ['multi', 'bern'], verbose=False):\n",
    "    \"\"\"This function takes a vector of type vectors_all (defined above) acts as a wrapper\n",
    "    to send each vector to the score_classifier_train_on_dev function selecting first multinomialNB\n",
    "    and after that Bernoulli.  It collects the resulting scores and the best alpha and stores\n",
    "    the results in a dataframe which is returned once all the results are calculated\n",
    "    \n",
    "    Args:\n",
    "        vectors_all (dataframe) : a dataframe defined above that stores the vector data in each row\n",
    "        score_types (list) : a list of scoring types to be passed to the scoring\n",
    "        model_types (list) : a list of the Naive Bayes model types to create when scoring these vectors\n",
    "        verbose (bool): print out progress when true\n",
    "    Returns\n",
    "        dataframe: A dataframe of all the resulting scores and the details for each model\n",
    "    \"\"\"\n",
    "    data_all=pd.DataFrame(columns=['vectorno', 'label', 'model','alpha', 'type', 'preprocessor', 'tokenizer', \n",
    "                                   'max_features', 'stop_words', 'lowercase', 'strip_accents',\n",
    "                                   'score_type', 'score'])\n",
    "    score_types = ['precision', 'recall', 'roc_auc']\n",
    "    model_types = ['multi', 'bern']\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('%s: Starting calculate_f1auc_all_models' % (str(datetime.datetime.now().time())))        \n",
    "    for index,row in vectors_all.iterrows():\n",
    "        if verbose == True:\n",
    "            print('%s: checking row %d' % (str(datetime.datetime.now().time()),index))\n",
    "        for name in target_names:\n",
    "            for score_type in score_types:\n",
    "                for model_type in model_types:\n",
    "                    # Calculate the score for this pair of vectors with a variety of scoring\n",
    "                    # parameters and types of NB classifier\n",
    "                    alpha, score = score_classifier_train_on_dev(train_vector=row['vectortrain'], \n",
    "                                        dev_vector=row['vectordata'], dev_labels=dev_labels,\n",
    "                                        train_labels=train_labels, label=name, ctype=model_type, pscoring=score_type )\n",
    "                    \n",
    "                    # Store all the results in the dataframe\n",
    "                    data_all.loc[data_all.shape[0]] = [index,name,model_type,alpha,row['type'], \n",
    "                                        row['preprocessor'], row['tokenizer'], row['max_features'], \n",
    "                                        row['stop_words'], row['lowercase'], row['strip_accents'],\n",
    "                                        score_type, score]\n",
    "    if verbose == True:\n",
    "        print('%s: finished calculate_f1auc_all_models' % (str(datetime.datetime.now().time())))               \n",
    "    return data_all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:06:25.010907: starting\n",
      "16:06:25.011172: transforming training data with NLTK preprocessor\n",
      "16:19:05.932769: transforming dev data with NLTK preprocessor\n",
      "16:24:35.561962: completed NLTK preprocessor\n",
      "16:24:35.779542: Processing the next two vectors from base data, index 1\n",
      "16:25:06.946774: Processing the next two vectors from base data, index 2\n",
      "16:25:36.074516: Processing the next two vectors from base data, index 3\n",
      "16:26:06.103916: Processing the next two vectors from base data, index 4\n",
      "16:26:34.372225: Processing the next two vectors from base data, index 5\n",
      "16:27:04.014832: Processing the next two vectors from base data, index 6\n",
      "16:27:33.917852: Processing the next two vectors from base data, index 7\n",
      "16:27:59.620404: Processing the next two vectors from base data, index 8\n",
      "16:28:25.403724: Processing the next two vectors from base data, index 9\n",
      "16:28:53.191286: Processing the next two vectors from base data, index 10\n",
      "16:29:21.158506: Processing the next two vectors from base data, index 11\n",
      "16:29:50.626637: Processing the next two vectors from base data, index 12\n",
      "16:30:19.991120: Processing the next two vectors from base data, index 13\n",
      "16:30:46.290836: Processing the next two vectors from base data, index 14\n",
      "16:31:12.551653: Processing the next two vectors from base data, index 15\n",
      "16:31:40.663624: Processing the next two vectors from base data, index 16\n",
      "16:32:10.023408: Processing the next two vectors from base data, index 17\n",
      "16:32:39.952192: Processing the next two vectors from base data, index 18\n",
      "16:36:17.331880: Processing the next two vectors from base data, index 19\n",
      "16:36:42.687831: Processing the next two vectors from base data, index 20\n",
      "16:37:07.596122: Processing the next two vectors from base data, index 21\n",
      "16:37:34.285324: Processing the next two vectors from base data, index 22\n",
      "16:38:01.055025: Processing the next two vectors from base data, index 23\n",
      "16:38:29.204133: Processing the next two vectors from base data, index 24\n",
      "16:38:57.312993: Processing the next two vectors from base data, index 25\n",
      "16:39:22.881492: Processing the next two vectors from base data, index 26\n",
      "16:39:48.462967: Processing the next two vectors from base data, index 27\n",
      "16:40:16.088590: Processing the next two vectors from base data, index 28\n",
      "16:40:43.456655: Processing the next two vectors from base data, index 29\n",
      "16:41:12.239115: Processing the next two vectors from base data, index 30\n",
      "16:41:41.308878: Processing the next two vectors from base data, index 31\n",
      "16:42:06.150342: Processing the next two vectors from base data, index 32\n",
      "16:42:31.584134: Processing the next two vectors from base data, index 33\n",
      "16:42:59.069749: Processing the next two vectors from base data, index 34\n",
      "16:43:26.053842: Processing the next two vectors from base data, index 35\n",
      "16:43:54.250889: Processing the next two vectors from base data, index 36\n",
      "16:44:22.690294: Processing the next two vectors from base data, index 37\n",
      "16:44:48.084004: Processing the next two vectors from base data, index 38\n",
      "16:45:13.635132: Processing the next two vectors from base data, index 39\n",
      "16:45:41.322758: Processing the next two vectors from base data, index 40\n",
      "16:46:08.906170: Processing the next two vectors from base data, index 41\n",
      "16:46:37.906172: Processing the next two vectors from base data, index 42\n",
      "16:47:06.560089: Processing the next two vectors from base data, index 43\n",
      "16:47:31.354097: Processing the next two vectors from base data, index 44\n",
      "16:47:56.568066: Processing the next two vectors from base data, index 45\n",
      "16:48:23.441441: Processing the next two vectors from base data, index 46\n",
      "16:48:50.516958: Processing the next two vectors from base data, index 47\n",
      "16:49:18.626582: Processing the next two vectors from base data, index 48\n",
      "16:49:46.852251: Processing the next two vectors from base data, index 49\n",
      "16:50:14.714880: Processing the next two vectors from base data, index 50\n",
      "16:50:42.407157: Processing the next two vectors from base data, index 51\n",
      "16:51:10.346223: Processing the next two vectors from base data, index 52\n",
      "16:51:38.490703: Processing the next two vectors from base data, index 53\n",
      "16:52:07.784789: Processing the next two vectors from base data, index 54\n",
      "16:52:37.422009: Processing the next two vectors from base data, index 55\n",
      "16:53:02.378412: Processing the next two vectors from base data, index 56\n",
      "16:53:27.571825: Processing the next two vectors from base data, index 57\n",
      "16:53:54.408737: Processing the next two vectors from base data, index 58\n",
      "16:54:21.687013: Processing the next two vectors from base data, index 59\n",
      "16:54:49.702644: Processing the next two vectors from base data, index 60\n",
      "16:55:18.044354: Processing the next two vectors from base data, index 61\n",
      "16:55:43.825092: Processing the next two vectors from base data, index 62\n",
      "16:56:09.567358: Processing the next two vectors from base data, index 63\n",
      "16:56:37.451663: Processing the next two vectors from base data, index 64\n",
      "16:57:05.098791: Processing the next two vectors from base data, index 65\n",
      "16:57:34.496896: Processing the next two vectors from base data, index 66\n",
      "16:58:03.283505: Processing the next two vectors from base data, index 67\n",
      "16:58:28.276958: Processing the next two vectors from base data, index 68\n",
      "16:58:53.434881: Processing the next two vectors from base data, index 69\n",
      "16:59:20.307797: Processing the next two vectors from base data, index 70\n",
      "16:59:47.665618: Processing the next two vectors from base data, index 71\n",
      "17:00:16.016746: Processing the next two vectors from base data, index 72\n",
      "17:00:44.475105: Processing the next two vectors from preprocessed data, index 1\n",
      "17:01:09.831632: Processing the next two vectors from preprocessed data, index 2\n",
      "17:01:20.550963: Processing the next two vectors from preprocessed data, index 3\n",
      "17:01:30.132545: Processing the next two vectors from preprocessed data, index 4\n",
      "17:01:40.441718: Processing the next two vectors from preprocessed data, index 5\n",
      "17:01:50.223657: Processing the next two vectors from preprocessed data, index 6\n",
      "17:02:00.587682: Processing the next two vectors from preprocessed data, index 7\n",
      "17:02:11.373075: Processing the next two vectors from preprocessed data, index 8\n",
      "17:02:22.201928: Processing the next two vectors from preprocessed data, index 9\n",
      "17:02:32.774025: Processing the next two vectors from preprocessed data, index 10\n",
      "17:02:46.525120: Processing the next two vectors from preprocessed data, index 11\n",
      "17:02:59.078926: Processing the next two vectors from preprocessed data, index 12\n",
      "17:03:09.533624: Completed create_all_vectors\n",
      "17:03:09.872616: Starting calculate_f1auc_all_models\n",
      "17:03:09.874016: checking row 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "score_classifier_train_on_dev() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-400845c7126b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# calculate the f1 and auc for all the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_f1auc_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# for label in target_names:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7563160cac08>\u001b[0m in \u001b[0;36mcalculate_f1auc_all_models\u001b[0;34m(vectors_all, score_types, model_types, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m                     alpha, score = score_classifier_train_on_dev(train_vector=row['vectortrain'], \n\u001b[1;32m     33\u001b[0m                                         \u001b[0mdev_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectordata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                                         train_labels=train_labels, name=name, ctype=model_type, pscoring=score_type )\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0;31m# Store all the results in the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: score_classifier_train_on_dev() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "verbose=True\n",
    "top_score_results = pd.DataFrame(columns=['vectorno', 'label', 'model','alpha', 'type', 'preprocessor', 'tokenizer', \n",
    "                                   'max_features', 'stop_words', 'lowercase', 'strip_accents',\n",
    "                                   'score_type', 'score'])\n",
    "score_types = ['precision', 'recall', 'roc_auc']\n",
    "\n",
    "print('%s: starting' %(str(datetime.datetime.now().time())))\n",
    "\n",
    "# # Set up all the NLTK Preprocessing\n",
    "# print('%s: Creating new NLTK Preprocessor' %(str(datetime.datetime.now().time())))\n",
    "# nltkPreprocessor = NLTKPreprocessor()\n",
    "# print('%s: Converting training data with NLTK Preprocessor' %(str(datetime.datetime.now().time())))\n",
    "# nltkPreprocessor.fit(train_data)\n",
    "# train_preproc_data = nltkPreprocessor.transform(train_data)\n",
    "# print('%s: Converting dev data with NLTK Preprocessor' %(str(datetime.datetime.now().time())))\n",
    "# nltkPreprocessor.fit(dev_data)\n",
    "# dev_preproc_data = nltkPreprocessor.transform(dev_data)\n",
    "# print('%s: done' %(str(datetime.datetime.now().time())))\n",
    "\n",
    "if verbose == True:\n",
    "    print('%s: transforming training data with NLTK preprocessor' %(str(datetime.datetime.now().time())))\n",
    "train_preproc_data = NLTKPreprocessor().fit(train_data).transform(train_data)\n",
    "if verbose == True:\n",
    "    print('%s: transforming dev data with NLTK preprocessor' %(str(datetime.datetime.now().time())))\n",
    "dev_preproc_data = NLTKPreprocessor().fit(dev_data).transform(dev_data)\n",
    "if verbose == True:\n",
    "    print('%s: completed NLTK preprocessor' %(str(datetime.datetime.now().time())))\n",
    "\n",
    "# Create the set of vectors:\n",
    "vectors_all = create_all_vectors(basetrain_data=train_data, basedev_data=dev_data,\n",
    "                        preprocessedtrain_data=train_preproc_data, preprocesseddev_data=dev_preproc_data,\n",
    "                        verbose=verbose)\n",
    "\n",
    "# calculate the f1 and auc for all the models\n",
    "result_df = calculate_f1auc_all_models(vectors_all,verbose=verbose)\n",
    "\n",
    "# for label in target_names:\n",
    "#     df_tmp = result_df.loc[result_df['label'] == label]\n",
    "#     for score_type in score_types:\n",
    "#         df_tmp2 = df_tmp[df_tmp.score_type == score_type]\n",
    "#         top_score_results.loc[top_score_results.shape[0]] = df_tmp2.loc[df_tmp2['score'].idxmax()]\n",
    "    \n",
    "# print(top_score_results)\n",
    "# print('%s: ending' %(str(datetime.datetime.now().time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Best scores:\n",
    "\n",
    "top_score_results = pd.DataFrame(columns=['vectorno', 'label', 'model','alpha', 'type', 'preprocessor', 'tokenizer', \n",
    "                                   'max_features', 'stop_words', 'lowercase', 'strip_accents',\n",
    "                                   'score_type', 'score'])\n",
    "for score_type in score_types:\n",
    "    for label in target_names:\n",
    "        df_tmp = result_df[(result_df['label'] == label) & (result_df['score_type'] == score_type)]\n",
    "        top_score_results.loc[top_score_results.shape[0]] = df_tmp.loc[df_tmp['score'].idxmax()]\n",
    "    \n",
    "print(top_score_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best TFIDF scores.  These are identical to the top scores as it seems the TFIDF vs Count \n",
    "# does not impact\n",
    "\n",
    "top_score_results_tfidf = pd.DataFrame(columns=['vectorno', 'label', 'model','alpha', 'type', 'preprocessor', 'tokenizer', \n",
    "                                   'max_features', 'stop_words', 'lowercase', 'strip_accents',\n",
    "                                   'score_type', 'score'])\n",
    "for score_type in score_types:\n",
    "    for label in target_names:\n",
    "        df_tmp = result_df[(result_df['label'] == label) & (result_df['score_type'] == score_type)\n",
    "                          & (result_df['type'] == 'tfidf')]\n",
    "        top_score_results_tfidf.loc[top_score_results_tfidf.shape[0]] = df_tmp.loc[df_tmp['score'].idxmax()]\n",
    "    \n",
    "print(top_score_results_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best TFIDF scores with preprocessed data\n",
    "\n",
    "top_score_results_tfidf = pd.DataFrame(columns=['vectorno', 'label', 'model','alpha', 'type', 'preprocessor', 'tokenizer', \n",
    "                                   'max_features', 'stop_words', 'lowercase', 'strip_accents',\n",
    "                                   'score_type', 'score'])\n",
    "for score_type in score_types:\n",
    "    for label in target_names:\n",
    "        df_tmp = result_df[(result_df['label'] == label) & (result_df['score_type'] == score_type)\n",
    "                          & (result_df['type'] == 'tfidf') & (result_df['preprocessor'] == 1)]\n",
    "        top_score_results_tfidf.loc[top_score_results_tfidf.shape[0]] = df_tmp.loc[df_tmp['score'].idxmax()]\n",
    "    \n",
    "print(top_score_results_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for overfitting\n",
    "# Do a new dev split create the best models as defined by the previous step, train them on the new train\n",
    "# Graph the data for presentation\n",
    "\n",
    "print('%s: starting' %(str(datetime.datetime.now().time())))\n",
    "vect = CountVectorizer(tokenizer=identity, max_features=4000, stop_words='english',strip_accents=None, lowercase=False)\n",
    "vect_train = vect.fit_transform(train_preproc_data)\n",
    "vect_dev = vect.transform(dev_preproc_data)\n",
    "print('%s: Vectors created' %(str(datetime.datetime.now().time())))\n",
    "nb_class_toxic = BernoulliNB(alpha=15).fit(vect_train, train_labels['toxic'])\n",
    "nb_class_severe_toxic = BernoulliNB(alpha=2).fit(vect_train, train_labels['severe_toxic'])\n",
    "nb_class_threat = BernoulliNB(alpha=1).fit(vect_train, train_labels['threat'])\n",
    "nb_class_obscene = BernoulliNB(alpha=0.5).fit(vect_train, train_labels['obscene'])\n",
    "nb_class_insult = BernoulliNB(alpha=10).fit(vect_train, train_labels['insult'])\n",
    "nb_class_identity_hate = BernoulliNB(alpha=1).fit(vect_train, train_labels['identity_hate'])\n",
    "print('%s: BernoulliNB classifiers created' %(str(datetime.datetime.now().time())))\n",
    "predicted_labels_dev = nb_class_toxic.predict(vect_dev)\n",
    "print(metrics.roc_auc_score(dev_labels['toxic'], predicted_labels_dev))\n",
    "predicted_labels_dev = nb_class_severe_toxic.predict(vect_dev)\n",
    "print(metrics.roc_auc_score(dev_labels['severe_toxic'], predicted_labels_dev))\n",
    "predicted_labels_dev = nb_class_threat.predict(vect_dev)\n",
    "print(metrics.roc_auc_score(dev_labels['threat'], predicted_labels_dev))\n",
    "predicted_labels_dev = nb_class_obscene.predict(vect_dev)\n",
    "print(metrics.roc_auc_score(dev_labels['obscene'], predicted_labels_dev))\n",
    "predicted_labels_dev = nb_class_insult.predict(vect_dev)\n",
    "print(metrics.roc_auc_score(dev_labels['insult'], predicted_labels_dev))\n",
    "predicted_labels_dev = nb_class_identity_hate.predict(vect_dev)\n",
    "print(metrics.roc_auc_score(dev_labels['identity_hate'], predicted_labels_dev))\n",
    "print('%s: predictions completed' %(str(datetime.datetime.now().time())))\n",
    "print('all classifiers created and %d predicted' %(dev_labels.shape[0]))\n",
    "\n",
    "rscore = metrics.roc_auc_score(dev_labels[label], predicted_labels_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_score_results = pd.DataFrame(columns=['vectorno', 'label', 'model','alpha', 'type', 'preprocessor', 'tokenizer', \n",
    "                                   'max_features', 'stop_words', 'lowercase', 'strip_accents',\n",
    "                                   'score_type', 'score'])\n",
    "for label in target_names:\n",
    "    df_tmp = result_df.loc[result_df['label'] == label]\n",
    "    for score_type in score_types:\n",
    "        df_tmp2 = df_tmp[df_tmp.score_type == score_type]\n",
    "        top_score_results.loc[top_score_results.shape[0]] = df_tmp2.loc[df_tmp2['score'].idxmax()]\n",
    "    \n",
    "print(top_score_results)\n",
    "result_df.to_csv('all_scores.csv')\n",
    "top_score_results.to_csv('top_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_score_results_tfidf = pd.DataFrame(columns=['vectorno', 'label', 'model','alpha', 'type', 'preprocessor', 'tokenizer', \n",
    "                                   'max_features', 'stop_words', 'lowercase', 'strip_accents',\n",
    "                                   'score_type', 'score'])\n",
    "\n",
    "sizes=[3000, 4000, 5000, 6000]\n",
    "for size in sizes:\n",
    "    for label in target_names:\n",
    "        for score_type in score_types:\n",
    "            df_tmp = result_df[(result_df['label'] == label) & (result_df['type'] == 'tfidf')\n",
    "                          & (result_df['max_features'] == size)]\n",
    "            top_score_results_tfidf.loc[top_score_results_tfidf.shape[0]] = df_tmp.loc[df_tmp['score'].idxmax()]\n",
    "    \n",
    "print(top_score_results_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_score_results_tfidf.to_csv('top_scores_by_size_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[(result_df['label'] == 'toxic') & (result_df['type']=='tfidf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
