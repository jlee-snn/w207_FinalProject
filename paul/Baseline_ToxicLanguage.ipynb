{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Submission: Toxic Language Classification \n",
    "**w207 Spring 2018 - Final Project Baseline**\n",
    "\n",
    "**Team: Paul, Walt, Yisang, Joe**\n",
    "\n",
    "\n",
    "\n",
    "### Project Description \n",
    "\n",
    "Our challenge is to build a multi-headed model thatâ€™s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate.  The toxic language data set is sourced from Wikipedia and available as a public kaggle data set. \n",
    "\n",
    "Our goal is to use various machine learning techniques used in class to develop high quality ML models and pipelines.  \n",
    "\n",
    "1. Exercise and build upon concepts covered in class and test out at least 3 kinds of supervised models:\n",
    "    a. Regression (LASSO, Logistic)\n",
    "    b. Trees (RF, XGBoost)\n",
    "    c. DeepLearning (Tensorflow)\n",
    "2. Using stacking/ensembling methods for improving prediction metrics (K-Means, anomaly detection)\n",
    "3. Using unsupervised methods for feature engineering/selection\n",
    "\n",
    "For the baseline proposal, this file contains a first pass run through from data preprocessing to model evaluation using a regression model pipeline. \n",
    "\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#scipy imports\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import bokeh\n",
    "#! pip install bokeh\n",
    "\n",
    "# target classes\n",
    "target_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training observations: 159571\n",
      "training data shape: (111744,)\n",
      "training label shape: (111744, 6)\n",
      "dev label shape: (47827, 6)\n",
      "labels names: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "# read frames localy through csv\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# Random index generator for splitting training data\n",
    "# Note: Each rerun of cell will create new splits.\n",
    "randIndexCut = np.random.rand(len(train_df)) < 0.7\n",
    "\n",
    "#S plit up data\n",
    "test_data = test_df[\"comment_text\"]\n",
    "dev_data, dev_labels = train_df[~randIndexCut][\"comment_text\"], train_df[~randIndexCut][target_names]\n",
    "train_data, train_labels = train_df[randIndexCut][\"comment_text\"], train_df[randIndexCut][target_names]\n",
    "\n",
    "\n",
    "print('total training observations:', train_df.shape[0])\n",
    "print('training data shape:', train_data.shape)\n",
    "print('training label shape:', train_labels.shape)\n",
    "print('dev label shape:', dev_labels.shape)\n",
    "print ('labels names:', target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how imblanced the label set is in order to have a better understanding with the label quality of the given data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"2b5eac18-c03c-4f56-8616-b0fbc3ea272c\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"2b5eac18-c03c-4f56-8616-b0fbc3ea272c\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"2b5eac18-c03c-4f56-8616-b0fbc3ea272c\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '2b5eac18-c03c-4f56-8616-b0fbc3ea272c' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"2b5eac18-c03c-4f56-8616-b0fbc3ea272c\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"2b5eac18-c03c-4f56-8616-b0fbc3ea272c\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"2b5eac18-c03c-4f56-8616-b0fbc3ea272c\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '2b5eac18-c03c-4f56-8616-b0fbc3ea272c' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"2b5eac18-c03c-4f56-8616-b0fbc3ea272c\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"3ac4b9f5-8ce2-43a1-a729-92b9737fed0d\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"5ee41a15-8f52-4326-9833-9aa10ff382de\":{\"roots\":{\"references\":[{\"attributes\":{\"source\":{\"id\":\"92170f0f-7d4e-4a53-8b73-9394ea02d338\",\"type\":\"ColumnDataSource\"}},\"id\":\"b3951a10-5ac9-4625-a1dd-8b477ec625ab\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"37ab77f9-44bd-43b5-b8ab-547e4067a01f\",\"type\":\"ResetTool\"},{\"attributes\":{\"plot\":{\"id\":\"ccee1e9c-0463-491f-bad5-852d7562f42e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"6fb3f862-5f1f-4750-8eea-3deb72736aed\",\"type\":\"CategoricalTicker\"}},\"id\":\"36af94f8-cc34-4f2f-9e91-36cbbbcd3ac9\",\"type\":\"Grid\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"7d7c949c-3d62-4529-ad4a-aa4e7253780a\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"28eca65a-7c30-41f8-9cfe-0a256955c738\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"3b4380b0-1957-4fb0-aeff-52adf0c723f1\",\"type\":\"VBar\"},{\"attributes\":{\"formatter\":{\"id\":\"f862d512-3ce2-49f5-a7dd-a77a4f3e3ff3\",\"type\":\"CategoricalTickFormatter\"},\"plot\":{\"id\":\"ccee1e9c-0463-491f-bad5-852d7562f42e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"6fb3f862-5f1f-4750-8eea-3deb72736aed\",\"type\":\"CategoricalTicker\"}},\"id\":\"7c857cce-8c54-44f5-94a8-930a1a265ed1\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"6fb3f862-5f1f-4750-8eea-3deb72736aed\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"c65a865b-cd73-4257-b343-c4f02561e52b\",\"type\":\"DataRange1d\"},{\"attributes\":{\"overlay\":{\"id\":\"656da984-b73b-49fe-93d7-ba92576e197c\",\"type\":\"BoxAnnotation\"}},\"id\":\"7f33a4bb-d3c8-46fd-9ea3-4fcc9a45683d\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"data_source\":{\"id\":\"92170f0f-7d4e-4a53-8b73-9394ea02d338\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"7d7c949c-3d62-4529-ad4a-aa4e7253780a\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"3b4380b0-1957-4fb0-aeff-52adf0c723f1\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"b3951a10-5ac9-4625-a1dd-8b477ec625ab\",\"type\":\"CDSView\"}},\"id\":\"7712d1ed-db38-4af0-9699-7cb0fe051bfa\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"factors\":[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]},\"id\":\"9c18aa10-6bb2-4025-b5d0-221a63a150d7\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"7e270a44-3c8a-4e66-8bd6-82b0d65ed103\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"b941f9f0-412f-488b-9c3d-ada5a5806378\",\"type\":\"BasicTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"656da984-b73b-49fe-93d7-ba92576e197c\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"03e8e54f-f013-44a6-8e3c-7a2e26f5ca98\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"35051ecd-a3f1-461a-a359-c70e623f70a7\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"48498faa-e535-4380-89a8-4319ba9cd370\",\"type\":\"PanTool\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"302856ba-88c8-48bc-85ca-263dffb94cdf\",\"type\":\"Title\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"48498faa-e535-4380-89a8-4319ba9cd370\",\"type\":\"PanTool\"},{\"id\":\"7e270a44-3c8a-4e66-8bd6-82b0d65ed103\",\"type\":\"WheelZoomTool\"},{\"id\":\"7f33a4bb-d3c8-46fd-9ea3-4fcc9a45683d\",\"type\":\"BoxZoomTool\"},{\"id\":\"35051ecd-a3f1-461a-a359-c70e623f70a7\",\"type\":\"SaveTool\"},{\"id\":\"37ab77f9-44bd-43b5-b8ab-547e4067a01f\",\"type\":\"ResetTool\"},{\"id\":\"03e8e54f-f013-44a6-8e3c-7a2e26f5ca98\",\"type\":\"HelpTool\"}]},\"id\":\"66610608-7ecc-4f12-bef3-9b555b666a77\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"top\"],\"data\":{\"top\":[10720,1118,5955,343,5561,1025],\"x\":[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]}},\"id\":\"92170f0f-7d4e-4a53-8b73-9394ea02d338\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"ec7a1125-1149-4338-989a-b02693749b5d\",\"type\":\"LinearScale\"},{\"attributes\":{\"below\":[{\"id\":\"7c857cce-8c54-44f5-94a8-930a1a265ed1\",\"type\":\"CategoricalAxis\"}],\"left\":[{\"id\":\"34311924-507f-4a3e-b645-284ad4b41d35\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"7c857cce-8c54-44f5-94a8-930a1a265ed1\",\"type\":\"CategoricalAxis\"},{\"id\":\"36af94f8-cc34-4f2f-9e91-36cbbbcd3ac9\",\"type\":\"Grid\"},{\"id\":\"34311924-507f-4a3e-b645-284ad4b41d35\",\"type\":\"LinearAxis\"},{\"id\":\"3f28d6e4-c5cf-4d95-ba2c-fca66bca9d58\",\"type\":\"Grid\"},{\"id\":\"656da984-b73b-49fe-93d7-ba92576e197c\",\"type\":\"BoxAnnotation\"},{\"id\":\"7712d1ed-db38-4af0-9699-7cb0fe051bfa\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"302856ba-88c8-48bc-85ca-263dffb94cdf\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"66610608-7ecc-4f12-bef3-9b555b666a77\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"9c18aa10-6bb2-4025-b5d0-221a63a150d7\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"b8e20918-1176-4ac5-b897-676ada9c85df\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"c65a865b-cd73-4257-b343-c4f02561e52b\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"ec7a1125-1149-4338-989a-b02693749b5d\",\"type\":\"LinearScale\"}},\"id\":\"ccee1e9c-0463-491f-bad5-852d7562f42e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"b8e20918-1176-4ac5-b897-676ada9c85df\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"f862d512-3ce2-49f5-a7dd-a77a4f3e3ff3\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"28eca65a-7c30-41f8-9cfe-0a256955c738\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"ccee1e9c-0463-491f-bad5-852d7562f42e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b941f9f0-412f-488b-9c3d-ada5a5806378\",\"type\":\"BasicTicker\"}},\"id\":\"34311924-507f-4a3e-b645-284ad4b41d35\",\"type\":\"LinearAxis\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"ccee1e9c-0463-491f-bad5-852d7562f42e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b941f9f0-412f-488b-9c3d-ada5a5806378\",\"type\":\"BasicTicker\"}},\"id\":\"3f28d6e4-c5cf-4d95-ba2c-fca66bca9d58\",\"type\":\"Grid\"}],\"root_ids\":[\"ccee1e9c-0463-491f-bad5-852d7562f42e\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.14\"}};\n",
       "  var render_items = [{\"docid\":\"5ee41a15-8f52-4326-9833-9aa10ff382de\",\"elementid\":\"3ac4b9f5-8ce2-43a1-a729-92b9737fed0d\",\"modelid\":\"ccee1e9c-0463-491f-bad5-852d7562f42e\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "ccee1e9c-0463-491f-bad5-852d7562f42e"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "2      0             0        0       0       0              0\n",
       "3      0             0        0       0       0              0\n",
       "4      0             0        0       0       0              0\n",
       "5      0             0        0       0       0              0\n",
       "6      1             1        1       0       1              0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.io import push_notebook\n",
    "from bokeh.plotting import figure, show, output_file, output_notebook\n",
    "\n",
    "target_counts = train_labels.apply(np.sum,0)\n",
    "target_counts\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "p = figure(x_range=target_names)\n",
    "p.vbar(x=target_names, top = target_counts, width=0.9)\n",
    "\n",
    "show(p)\n",
    "\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10720\n",
      "Total normal = 100373, total with issues = 11371\n",
      "toxic            10720\n",
      "severe_toxic      1118\n",
      "obscene           5955\n",
      "threat             343\n",
      "insult            5561\n",
      "identity_hate     1025\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_size = len(train_labels.toxic)\n",
    "\n",
    "print(sum(train_labels.toxic))\n",
    "total_normal=len(np.where((train_labels.toxic==0) & (train_labels.severe_toxic==0) & (train_labels.obscene==0) & \n",
    "             (train_labels.threat ==0 ) & (train_labels.insult==0) & (train_labels.identity_hate==0))[0])\n",
    "print(\"Total normal = %d, total with issues = %d\" % (total_normal, total_size-total_normal))\n",
    "print(target_counts)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is fairly imbalanced when counting label occurrences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas to consider\n",
    "- Sampling methods\n",
    "- Custom Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering/Selection (WIP)\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is: 153456\n",
      "Number of nonzero entries in matrix: 4867196\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6  </th>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 </th>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16 </th>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42 </th>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43 </th>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44 </th>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51 </th>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55 </th>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56 </th>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58 </th>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59 </th>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65 </th>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86 </th>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td> 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td> 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     counts\n",
       "6         4\n",
       "12        1\n",
       "16        1\n",
       "42        4\n",
       "43        3\n",
       "44        1\n",
       "51        2\n",
       "55        4\n",
       "56        3\n",
       "58        2\n",
       "59        1\n",
       "65        3\n",
       "86        2\n",
       "105       4\n",
       "176       5\n",
       "181       4\n",
       "201       2\n",
       "206       1\n",
       "211       3\n",
       "218       4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Count Vectorizer\n",
    "countVector = CountVectorizer(ngram_range=(1,1))\n",
    "train_counts = countVector.fit_transform(train_data)\n",
    "\n",
    "print(\"Vocabulary size is: {}\".format(len(countVector.vocabulary_)))\n",
    "\n",
    "print(\"Number of nonzero entries in matrix: {}\".format(train_counts.nnz))\n",
    "\n",
    "#sample column wise sum, we can see that an observation can have multiple classes. \n",
    "count_df = pd.DataFrame(train_labels.apply(np.sum,1), columns = [\"counts\"])\n",
    "count_df = count_df[((count_df[\"counts\"] >= 1))]\n",
    "count_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Pass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.798116317574296\n",
      "CV score for class severe_toxic is 0.7765996914864169\n",
      "CV score for class obscene is 0.7761163880394683\n",
      "CV score for class threat is 0.617148792692224\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3cc56a6a3c6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     cv_score = np.mean(cross_val_score(\n\u001b[0;32m---> 11\u001b[0;31m         classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mscores_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CV score for class {} is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1581\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1289\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1291\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                 is_saga=(solver == 'saga'))\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/linear_model/sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    321\u001b[0m                             \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                             \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                             verbose)\n\u001b[0m\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "prediction_output = []\n",
    "scores_output = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') \n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_counts, train_labels[name], cv=3, scoring='roc_auc'))\n",
    "    scores_output.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(name, cv_score))\n",
    "    classifier.fit(train_counts, train_labels[name])\n",
    "    \n",
    "    \n",
    "print(\"Mean ROC_AUC: {}\").format(np.mean(scores_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev score for class toxic is 0.675413012295\n",
      "Dev score for class severe_toxic is 0.581701390358\n",
      "Dev score for class obscene is 0.631987934387\n",
      "Dev score for class threat is 0.503865476473\n",
      "Dev score for class insult is 0.60758283931\n",
      "Dev score for class identity_hate is 0.521895703782\n",
      "Mean(dev) ROC_AUC: 0.676147422434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "dev_Vector = CountVectorizer(ngram_range=(1,1))\n",
    "dev_counts = countVector.fit_transform(dev_data)\n",
    "\n",
    "pred_dt = pd.DataFrame()\n",
    "scores_dev = []\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') \n",
    "    classifier.fit(dev_counts, dev_labels[name])\n",
    "    scores_dev.append(cv_score)\n",
    "    output = classifier.predict(dev_counts)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels[name], output)\n",
    "    print('Dev score for class {} is {}'.format(name, metrics.auc(fpr,tpr)))\n",
    "    pred_dt[name] = classifier.predict_proba(dev_counts)[:, 1]\n",
    "    \n",
    "    \n",
    "print(\"Mean(dev) ROC_AUC: {}\").format(np.mean(scores_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on dev set is worse than training set, thus evidence of overfitting and a need for performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is multi-label since each observation can be classified as multiple fields.  This is an important distinction from multi-class where each prediction can only be one label.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "5         0\n",
       "6         1\n",
       "9         0\n",
       "10        0\n",
       "11        0\n",
       "13        0\n",
       "14        0\n",
       "17        0\n",
       "18        0\n",
       "21        0\n",
       "22        0\n",
       "24        0\n",
       "25        0\n",
       "26        0\n",
       "27        0\n",
       "29        0\n",
       "30        0\n",
       "31        0\n",
       "32        0\n",
       "35        0\n",
       "36        0\n",
       "38        0\n",
       "39        0\n",
       "41        0\n",
       "43        1\n",
       "44        1\n",
       "46        0\n",
       "         ..\n",
       "159535    0\n",
       "159536    0\n",
       "159537    0\n",
       "159538    0\n",
       "159539    0\n",
       "159540    0\n",
       "159541    1\n",
       "159542    0\n",
       "159544    0\n",
       "159545    0\n",
       "159546    1\n",
       "159547    0\n",
       "159549    0\n",
       "159550    0\n",
       "159551    0\n",
       "159554    1\n",
       "159555    0\n",
       "159557    0\n",
       "159558    0\n",
       "159559    0\n",
       "159560    0\n",
       "159561    0\n",
       "159562    0\n",
       "159563    0\n",
       "159564    0\n",
       "159565    0\n",
       "159566    0\n",
       "159567    0\n",
       "159569    0\n",
       "159570    0\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df\n",
    "train_labels[\"toxic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.889472      0.889208  0.889490  0.889300  0.889859   \n",
      "1  0000247867823ef7  0.250917      0.250663  0.250762  0.250821  0.250742   \n",
      "2  00013b17ad220c46  0.432613      0.432735  0.432661  0.432668  0.432595   \n",
      "3  00017563c3f7919a  0.068362      0.068237  0.068175  0.068064  0.068163   \n",
      "4  00017695ad8997eb  0.424004      0.424707  0.424460  0.424676  0.424557   \n",
      "5  0001ea8717f6de06  0.340763      0.340854  0.340989  0.340558  0.340962   \n",
      "6  00024115d4cbde0f  0.124536      0.124778  0.124653  0.124630  0.124505   \n",
      "7  000247e83dcc1211  0.452367      0.452056  0.452069  0.452164  0.452073   \n",
      "8  00025358d4737918  0.006227      0.006221  0.006210  0.006212  0.006193   \n",
      "9  00026d1092fe71cc  0.044093      0.044136  0.044161  0.044094  0.044203   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.888301  \n",
      "1       0.250729  \n",
      "2       0.432661  \n",
      "3       0.068241  \n",
      "4       0.424652  \n",
      "5       0.340869  \n",
      "6       0.124839  \n",
      "7       0.452120  \n",
      "8       0.006195  \n",
      "9       0.044119  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "# SK-learn libraries for cross validation\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# Basic Logistic Regression Model/MultiLabel Edition\n",
    "\n",
    "prediction_submission = pd.DataFrame()\n",
    "prediction_submission[\"id\"] = test_df[\"id\"]\n",
    "\n",
    "# new vector object for all train data for submission\n",
    "finalTrainVector = CountVectorizer()\n",
    "finalTrainCount = finalTrainVector.fit_transform(train_df[\"comment_text\"])\n",
    "\n",
    "# TODO: Using pipelines can clean up repeitive processes\n",
    "# test set up\n",
    "#testVector = CountVectorizer()\n",
    "testCount = finalTrainVector.transform(test_df[\"comment_text\"])\n",
    "\n",
    "for name in target_names:\n",
    "    classifier = LogisticRegression(solver='sag') #sag is one kind of solver optimize for multi-label\n",
    "    clf = classifier.fit(finalTrainCount, train_df[\"toxic\"])\n",
    "    prediction_submission[name] = clf.predict_proba(testCount)[:, 1]\n",
    "    #print(prediction_submission)\n",
    "\n",
    "    \n",
    "print(prediction_submission.head(10)) # print frame output \n",
    "#prediction_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame contains the output for each class and is saved in a pandas data frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell for preprocessing functions\n",
    "from autocorrect import spell\n",
    "\n",
    "def find_spelling_errors(textdoc):\n",
    "    words = textdoc.split()\n",
    "    words = [ word.lower() for word in words]\n",
    "    misspelled_words = []\n",
    "    misspelled_words.append([re.sub(punctuation,'',word) for word in words if re.sub(punctuation,'',word) not in all_words])\n",
    "    return misspelled_words\n",
    "\n",
    "def trysplit(word):\n",
    "    lentmp = len(word)\n",
    "    return_words=[]\n",
    "    for i in range(lentmp):\n",
    "        if all_words.intersection(set([word[:lentmp-i].lower()])):\n",
    "            return_words.append(word[:lentmp-i])\n",
    "            if len(word[lentmp-i:]) > 0:\n",
    "                return_words.extend(trysplit(word[lentmp-i:]))\n",
    "            else:\n",
    "                return [word[:lentmp-i]]\n",
    "            break\n",
    "    return return_words \n",
    "\n",
    "def fix_spelling_errors(textdoc):\n",
    "    words = textdoc.split()\n",
    "    return_list = []\n",
    "    for word in words:\n",
    "        if all_words.intersection(set([re.sub(punctuation,'',word.lower())])):\n",
    "            return_list.append(word)\n",
    "        else:\n",
    "            # word is not found in the dictionary, try to correct the spelling\n",
    "            if word == spell(word): # no changes made by the spell checker\n",
    "                return_list.extend(trysplit(word))\n",
    "            else:\n",
    "                return_list.append(spell(word))\n",
    "    return return_list\n",
    "    #return [ spell(word.lower()) if re.sub(punctuation,'',word.lower()) not in all_words else word for word in words]\n",
    "    #return [spell(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a flag for any level of toxix or a unique number for each combination\n",
    "def bernoulli_toxic_labels (label_vector):\n",
    "    return [1 if (label_vector['toxic'][x] + label_vector['severe_toxic'][x] +\n",
    "                label_vector['obscene'][x] + label_vector['threat'][x] +\n",
    "                label_vector['insult'][x] + label_vector['identity_hate'][x]) > 0 else 0 \n",
    "            for x in label_vector.index.values]\n",
    "\n",
    "def binarize_toxic_labels (label_vector):\n",
    "    return [(label_vector['toxic'][x]*32 + label_vector['severe_toxic'][x]*16 +\n",
    "                label_vector['obscene'][x]*8 + label_vector['threat'][x]*4 +\n",
    "                label_vector['insult'][x]*2 + label_vector['identity_hate'][x]) \n",
    "            for x in label_vector.index.values]\n",
    "\n",
    "binary_train_labels = binarize_toxic_labels(train_labels)\n",
    "binary_dev_labels = binarize_toxic_labels(dev_labels)\n",
    "\n",
    "bernoulli_train_labels = bernoulli_toxic_labels(train_labels)\n",
    "bernoulli_dev_labels = bernoulli_toxic_labels(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_plain = CountVectorizer()\n",
    "X_train_counts_plain = count_vect_plain.fit_transform(train_data)\n",
    "X_dev_counts_plain = count_vect_plain.transform(dev_data)\n",
    "\n",
    "tfidf_vect_plain = TfidfVectorizer()\n",
    "X_train_tfidf_plain = tfidf_vect_plain.fit_transform(train_data)\n",
    "X_dev_tfidf_plain = tfidf_vect_plain.transform(dev_data)\n",
    "\n",
    "count_vect_stop_words = CountVectorizer(stop_words='english')\n",
    "X_train_counts_stop_words = count_vect_stop_words.fit_transform(train_data)\n",
    "X_dev_counts_stop_words = count_vect_stop_words.transform(dev_data)\n",
    "\n",
    "tfidf_vect_stop_words = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf_stop_words = tfidf_vect_stop_words.fit_transform(train_data)\n",
    "X_dev_tfidf_stop_words = tfidf_vect_stop_words.transform(dev_data)\n",
    "\n",
    "count_vect_stop_words_max10k = CountVectorizer(stop_words='english', max_features=10000)\n",
    "X_train_counts_stop_words_max10k = count_vect_stop_words_max1k.fit_transform(train_data)\n",
    "X_dev_counts_stop_words_max10k = count_vect_stop_words_max1k.transform(dev_data)\n",
    "\n",
    "tfidf_vect_stop_words_max10k = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "X_train_tfidf_stop_words_max10k = tfidf_vect_stop_words_max1k.fit_transform(train_data)\n",
    "X_dev_tfidf_stop_words_max10k = tfidf_vect_stop_words_max1k.transform(dev_data)\n",
    "\n",
    "count_vect_stop_words_max5k = CountVectorizer(stop_words='english', max_features=5000,lowercase=False)\n",
    "X_train_counts_stop_words_max5k = count_vect_stop_words_max5k.fit_transform(train_data)\n",
    "X_dev_counts_stop_words_max5k = count_vect_stop_words_max5k.transform(dev_data)\n",
    "\n",
    "tfidf_vect_stop_words_max5k = TfidfVectorizer(stop_words='english', max_features=5000,lowercase=False)\n",
    "X_train_tfidf_stop_words_max5k = tfidf_vect_stop_words_max5k.fit_transform(train_data)\n",
    "X_dev_tfidf_stop_words_max5k = tfidf_vect_stop_words_max5k.transform(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_f1_auc_on_train_dev(dev_vector, train_vector, name):\n",
    "    multinomial_nb_class = MultinomialNB().fit(train_vector, train_labels[name])\n",
    "    predicted_labels_dev = multinomial_nb_class.predict(dev_vector)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels[name], predicted_labels_dev)\n",
    "    predicted_labels_train = multinomial_nb_class.predict(train_vector)\n",
    "    fpr1, tpr1, thresholds1 = metrics.roc_curve(train_labels[name], predicted_labels_train)\n",
    "    f1scoredev = metrics.f1_score(dev_labels[name],predicted_labels_dev,average='micro')\n",
    "    f1scoretrain = metrics.f1_score(train_labels[name],predicted_labels_train,average='micro')\n",
    "    aucdev = metrics.auc(fpr,tpr)\n",
    "    auctrain = metrics.auc(fpr1,tpr1)\n",
    "    return f1scoredev,aucdev,f1scoretrain,auctrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  set          label     f1dev    aucdev   f1train  auctrain\n",
      "0          CountPlain          toxic  0.947289  0.801548  0.951962  0.845478\n",
      "1          TfidfPlain          toxic  0.917243  0.567728  0.921266  0.590688\n",
      "2      CountStopWords          toxic  0.948606  0.788689  0.956096  0.843303\n",
      "3      TfidfStopWords          toxic  0.920777  0.586300  0.925374  0.612055\n",
      "4   CountStopWords10k          toxic  0.942334  0.768309  0.945339  0.776567\n",
      "5   TfidfStopWords10k          toxic  0.944216  0.719495  0.945438  0.725590\n",
      "6    CountStopWords5k          toxic  0.943944  0.793540  0.946986  0.808163\n",
      "7    TfidfStopWords5k          toxic  0.943693  0.746089  0.946583  0.761787\n",
      "8          CountPlain   severe_toxic  0.988500  0.705723  0.987096  0.754863\n",
      "9          TfidfPlain   severe_toxic  0.990027  0.500000  0.989897  0.499950\n",
      "10     CountStopWords   severe_toxic  0.989295  0.715463  0.987946  0.765475\n",
      "11     TfidfStopWords   severe_toxic  0.990027  0.500000  0.989932  0.499968\n",
      "12  CountStopWords10k   severe_toxic  0.985218  0.804718  0.984697  0.828027\n",
      "13  TfidfStopWords10k   severe_toxic  0.990027  0.621406  0.990362  0.647607\n",
      "14   CountStopWords5k   severe_toxic  0.978715  0.781719  0.978862  0.832163\n",
      "15   TfidfStopWords5k   severe_toxic  0.987058  0.623020  0.987686  0.658209\n",
      "16         CountPlain        obscene  0.968762  0.802596  0.967622  0.834807\n",
      "17         TfidfPlain        obscene  0.952056  0.541055  0.952561  0.556259\n",
      "18     CountStopWords        obscene  0.970916  0.799564  0.971998  0.846230\n",
      "19     TfidfStopWords        obscene  0.953625  0.556091  0.954619  0.575570\n",
      "20  CountStopWords10k        obscene  0.973718  0.836659  0.974021  0.837948\n",
      "21  TfidfStopWords10k        obscene  0.973341  0.768068  0.973278  0.771631\n",
      "22   CountStopWords5k        obscene  0.963577  0.827520  0.964624  0.837977\n",
      "23   TfidfStopWords5k        obscene  0.966525  0.764093  0.967748  0.781071\n",
      "24         CountPlain         threat  0.996341  0.518047  0.995740  0.524108\n",
      "25         TfidfPlain         threat  0.997177  0.500000  0.996913  0.502897\n",
      "26     CountStopWords         threat  0.996801  0.533050  0.995955  0.548921\n",
      "27     TfidfStopWords         threat  0.997177  0.500000  0.996913  0.502897\n",
      "28  CountStopWords10k         threat  0.990905  0.736914  0.989995  0.772637\n",
      "29  TfidfStopWords10k         threat  0.997282  0.518519  0.996957  0.508733\n",
      "30   CountStopWords5k         threat  0.983001  0.740338  0.981798  0.813576\n",
      "31   TfidfStopWords5k         threat  0.997177  0.503693  0.996859  0.502871\n",
      "32         CountPlain         insult  0.964581  0.766856  0.965510  0.813491\n",
      "33         TfidfPlain         insult  0.952893  0.514626  0.952660  0.526326\n",
      "34     CountStopWords         insult  0.965877  0.756472  0.968240  0.815609\n",
      "35     TfidfStopWords         insult  0.953583  0.521545  0.953447  0.534579\n",
      "36  CountStopWords10k         insult  0.965250  0.785239  0.966871  0.794866\n",
      "37  TfidfStopWords10k         insult  0.967320  0.712561  0.967873  0.723822\n",
      "38   CountStopWords5k         insult  0.958894  0.798291  0.960535  0.813173\n",
      "39   TfidfStopWords5k         insult  0.962302  0.721194  0.963864  0.741480\n",
      "40         CountPlain  identity_hate  0.989629  0.557514  0.987937  0.600515\n",
      "41         TfidfPlain  identity_hate  0.992055  0.500000  0.990738  0.499955\n",
      "42     CountStopWords  identity_hate  0.990319  0.552641  0.989082  0.633474\n",
      "43     TfidfStopWords  identity_hate  0.992055  0.500000  0.990765  0.499968\n",
      "44  CountStopWords10k  identity_hate  0.985301  0.702826  0.984393  0.724865\n",
      "45  TfidfStopWords10k  identity_hate  0.992138  0.565305  0.991337  0.579517\n",
      "46   CountStopWords5k  identity_hate  0.976164  0.732157  0.975471  0.782707\n",
      "47   TfidfStopWords5k  identity_hate  0.990633  0.546272  0.989995  0.572073\n"
     ]
    }
   ],
   "source": [
    "scores_all=pd.DataFrame(columns=['set','label','f1dev','aucdev','f1train','auctrain'])\n",
    "\n",
    "for name in target_names:\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_plain,\n",
    "                                                   dev_vector=X_dev_counts_plain,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountPlain',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_plain,\n",
    "                                                   dev_vector=X_dev_tfidf_plain,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfPlain',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_stop_words,\n",
    "                                                   dev_vector=X_dev_counts_stop_words,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountStopWords',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_stop_words,\n",
    "                                                   dev_vector=X_dev_tfidf_stop_words,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfStopWords',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_stop_words_max10k,\n",
    "                                                   dev_vector=X_dev_counts_stop_words_max10k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountStopWords10k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_stop_words_max10k,\n",
    "                                                   dev_vector=X_dev_tfidf_stop_words_max10k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfStopWords10k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_stop_words_max5k,\n",
    "                                                   dev_vector=X_dev_counts_stop_words_max5k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountStopWords5k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_stop_words_max5k,\n",
    "                                                   dev_vector=X_dev_tfidf_stop_words_max5k,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfStopWords5k',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "\n",
    "    # not measuring here for each name\n",
    "print(scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_ngram5 = CountVectorizer(ngram_range=(1,10),lowercase=True)\n",
    "X_train_counts_ngram5 = count_vect_plain.fit_transform(train_data)\n",
    "X_dev_counts_ngram5 = count_vect_plain.transform(dev_data)\n",
    "\n",
    "tfidf_vect_ngram5 = TfidfVectorizer(ngram_range=(1,10),lowercase=True)\n",
    "X_train_tfidf_ngram5 = tfidf_vect_plain.fit_transform(train_data)\n",
    "X_dev_tfidf_ngram5 = tfidf_vect_plain.transform(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   set          label     f1dev    aucdev   f1train  auctrain\n",
      "0           CountPlain          toxic  0.947289  0.801548  0.951962  0.845478\n",
      "1           TfidfPlain          toxic  0.917243  0.567728  0.921266  0.590688\n",
      "2       CountStopWords          toxic  0.948606  0.788689  0.956096  0.843303\n",
      "3       TfidfStopWords          toxic  0.920777  0.586300  0.925374  0.612055\n",
      "4    CountStopWords10k          toxic  0.942334  0.768309  0.945339  0.776567\n",
      "5    TfidfStopWords10k          toxic  0.944216  0.719495  0.945438  0.725590\n",
      "6     CountStopWords5k          toxic  0.946160  0.819693  0.950029  0.833777\n",
      "7     TfidfStopWords5k          toxic  0.948397  0.747712  0.951362  0.763387\n",
      "8           CountPlain   severe_toxic  0.988500  0.705723  0.987096  0.754863\n",
      "9           TfidfPlain   severe_toxic  0.990027  0.500000  0.989897  0.499950\n",
      "10      CountStopWords   severe_toxic  0.989295  0.715463  0.987946  0.765475\n",
      "11      TfidfStopWords   severe_toxic  0.990027  0.500000  0.989932  0.499968\n",
      "12   CountStopWords10k   severe_toxic  0.985218  0.804718  0.984697  0.828027\n",
      "13   TfidfStopWords10k   severe_toxic  0.990027  0.621406  0.990362  0.647607\n",
      "14    CountStopWords5k   severe_toxic  0.983858  0.812333  0.984124  0.865368\n",
      "15    TfidfStopWords5k   severe_toxic  0.990382  0.561401  0.990854  0.600486\n",
      "16          CountPlain        obscene  0.968762  0.802596  0.967622  0.834807\n",
      "17          TfidfPlain        obscene  0.952056  0.541055  0.952561  0.556259\n",
      "18      CountStopWords        obscene  0.970916  0.799564  0.971998  0.846230\n",
      "19      TfidfStopWords        obscene  0.953625  0.556091  0.954619  0.575570\n",
      "20   CountStopWords10k        obscene  0.973718  0.836659  0.974021  0.837948\n",
      "21   TfidfStopWords10k        obscene  0.973341  0.768068  0.973278  0.771631\n",
      "22    CountStopWords5k        obscene  0.969871  0.856984  0.972285  0.874827\n",
      "23    TfidfStopWords5k        obscene  0.972798  0.768918  0.974459  0.787072\n",
      "24          CountPlain         threat  0.996341  0.518047  0.995740  0.524108\n",
      "25          TfidfPlain         threat  0.997177  0.500000  0.996913  0.502897\n",
      "26      CountStopWords         threat  0.996801  0.533050  0.995955  0.548921\n",
      "27      TfidfStopWords         threat  0.997177  0.500000  0.996913  0.502897\n",
      "28   CountStopWords10k         threat  0.990905  0.736914  0.989995  0.772637\n",
      "29   TfidfStopWords10k         threat  0.997282  0.518519  0.996957  0.508733\n",
      "..                 ...            ...       ...       ...       ...       ...\n",
      "114        CountNgram5         threat  0.996341  0.518047  0.995740  0.524108\n",
      "115        TfidfNgram5         threat  0.997177  0.500000  0.996913  0.502897\n",
      "116        CountNgram5         insult  0.964581  0.766856  0.965510  0.813491\n",
      "117        TfidfNgram5         insult  0.952893  0.514626  0.952660  0.526326\n",
      "118        CountNgram5  identity_hate  0.989629  0.557514  0.987937  0.600515\n",
      "119        TfidfNgram5  identity_hate  0.992055  0.500000  0.990738  0.499955\n",
      "120        CountNgram5          toxic  0.947289  0.801548  0.951962  0.845478\n",
      "121        TfidfNgram5          toxic  0.917243  0.567728  0.921266  0.590688\n",
      "122        CountNgram5   severe_toxic  0.988500  0.705723  0.987096  0.754863\n",
      "123        TfidfNgram5   severe_toxic  0.990027  0.500000  0.989897  0.499950\n",
      "124        CountNgram5        obscene  0.968762  0.802596  0.967622  0.834807\n",
      "125        TfidfNgram5        obscene  0.952056  0.541055  0.952561  0.556259\n",
      "126        CountNgram5         threat  0.996341  0.518047  0.995740  0.524108\n",
      "127        TfidfNgram5         threat  0.997177  0.500000  0.996913  0.502897\n",
      "128        CountNgram5         insult  0.964581  0.766856  0.965510  0.813491\n",
      "129        TfidfNgram5         insult  0.952893  0.514626  0.952660  0.526326\n",
      "130        CountNgram5  identity_hate  0.989629  0.557514  0.987937  0.600515\n",
      "131        TfidfNgram5  identity_hate  0.992055  0.500000  0.990738  0.499955\n",
      "132        CountNgram5          toxic  0.947289  0.801548  0.951962  0.845478\n",
      "133        TfidfNgram5          toxic  0.917243  0.567728  0.921266  0.590688\n",
      "134        CountNgram5   severe_toxic  0.988500  0.705723  0.987096  0.754863\n",
      "135        TfidfNgram5   severe_toxic  0.990027  0.500000  0.989897  0.499950\n",
      "136        CountNgram5        obscene  0.968762  0.802596  0.967622  0.834807\n",
      "137        TfidfNgram5        obscene  0.952056  0.541055  0.952561  0.556259\n",
      "138        CountNgram5         threat  0.996341  0.518047  0.995740  0.524108\n",
      "139        TfidfNgram5         threat  0.997177  0.500000  0.996913  0.502897\n",
      "140        CountNgram5         insult  0.964581  0.766856  0.965510  0.813491\n",
      "141        TfidfNgram5         insult  0.952893  0.514626  0.952660  0.526326\n",
      "142        CountNgram5  identity_hate  0.989629  0.557514  0.987937  0.600515\n",
      "143        TfidfNgram5  identity_hate  0.992055  0.500000  0.990738  0.499955\n",
      "\n",
      "[144 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "for name in target_names:\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_counts_ngram5,\n",
    "                                                   dev_vector=X_dev_counts_ngram5,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['CountNgram5',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "    tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain = score_f1_auc_on_train_dev(train_vector=X_train_tfidf_ngram5,\n",
    "                                                   dev_vector=X_dev_tfidf_ngram5,name=name)\n",
    "    scores_all.loc[scores_all.shape[0]] = ['TfidfNgram5',name,tmpf1dev,tmpaucdev,tmpf1train,tmpauctrain]\n",
    "print(scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1dev</th>\n",
       "      <th>aucdev</th>\n",
       "      <th>f1train</th>\n",
       "      <th>auctrain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">identity_hate</th>\n",
       "      <th>CountNgram5</th>\n",
       "      <td> 0.989629</td>\n",
       "      <td> 0.557514</td>\n",
       "      <td> 0.987937</td>\n",
       "      <td> 0.600515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountPlain</th>\n",
       "      <td> 0.989629</td>\n",
       "      <td> 0.557514</td>\n",
       "      <td> 0.987937</td>\n",
       "      <td> 0.600515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords</th>\n",
       "      <td> 0.990319</td>\n",
       "      <td> 0.552641</td>\n",
       "      <td> 0.989082</td>\n",
       "      <td> 0.633474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords10k</th>\n",
       "      <td> 0.985301</td>\n",
       "      <td> 0.702826</td>\n",
       "      <td> 0.984393</td>\n",
       "      <td> 0.724865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords5k</th>\n",
       "      <td> 0.989629</td>\n",
       "      <td> 0.755866</td>\n",
       "      <td> 0.987937</td>\n",
       "      <td> 0.813041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfNgram5</th>\n",
       "      <td> 0.992055</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.990738</td>\n",
       "      <td> 0.499955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfPlain</th>\n",
       "      <td> 0.992055</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.990738</td>\n",
       "      <td> 0.499955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords</th>\n",
       "      <td> 0.992055</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.990765</td>\n",
       "      <td> 0.499968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords10k</th>\n",
       "      <td> 0.992138</td>\n",
       "      <td> 0.565305</td>\n",
       "      <td> 0.991337</td>\n",
       "      <td> 0.579517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords5k</th>\n",
       "      <td> 0.992264</td>\n",
       "      <td> 0.523600</td>\n",
       "      <td> 0.991597</td>\n",
       "      <td> 0.556450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">insult</th>\n",
       "      <th>CountNgram5</th>\n",
       "      <td> 0.964581</td>\n",
       "      <td> 0.766856</td>\n",
       "      <td> 0.965510</td>\n",
       "      <td> 0.813491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountPlain</th>\n",
       "      <td> 0.964581</td>\n",
       "      <td> 0.766856</td>\n",
       "      <td> 0.965510</td>\n",
       "      <td> 0.813491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords</th>\n",
       "      <td> 0.965877</td>\n",
       "      <td> 0.756472</td>\n",
       "      <td> 0.968240</td>\n",
       "      <td> 0.815609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords10k</th>\n",
       "      <td> 0.965250</td>\n",
       "      <td> 0.785239</td>\n",
       "      <td> 0.966871</td>\n",
       "      <td> 0.794866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords5k</th>\n",
       "      <td> 0.964581</td>\n",
       "      <td> 0.828546</td>\n",
       "      <td> 0.966414</td>\n",
       "      <td> 0.845151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfNgram5</th>\n",
       "      <td> 0.952893</td>\n",
       "      <td> 0.514626</td>\n",
       "      <td> 0.952660</td>\n",
       "      <td> 0.526326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfPlain</th>\n",
       "      <td> 0.952893</td>\n",
       "      <td> 0.514626</td>\n",
       "      <td> 0.952660</td>\n",
       "      <td> 0.526326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords</th>\n",
       "      <td> 0.953583</td>\n",
       "      <td> 0.521545</td>\n",
       "      <td> 0.953447</td>\n",
       "      <td> 0.534579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords10k</th>\n",
       "      <td> 0.967320</td>\n",
       "      <td> 0.712561</td>\n",
       "      <td> 0.967873</td>\n",
       "      <td> 0.723822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords5k</th>\n",
       "      <td> 0.967842</td>\n",
       "      <td> 0.720007</td>\n",
       "      <td> 0.969851</td>\n",
       "      <td> 0.742841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">obscene</th>\n",
       "      <th>CountNgram5</th>\n",
       "      <td> 0.968762</td>\n",
       "      <td> 0.802596</td>\n",
       "      <td> 0.967622</td>\n",
       "      <td> 0.834807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountPlain</th>\n",
       "      <td> 0.968762</td>\n",
       "      <td> 0.802596</td>\n",
       "      <td> 0.967622</td>\n",
       "      <td> 0.834807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords</th>\n",
       "      <td> 0.970916</td>\n",
       "      <td> 0.799564</td>\n",
       "      <td> 0.971998</td>\n",
       "      <td> 0.846230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords10k</th>\n",
       "      <td> 0.973718</td>\n",
       "      <td> 0.836659</td>\n",
       "      <td> 0.974021</td>\n",
       "      <td> 0.837948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords5k</th>\n",
       "      <td> 0.969871</td>\n",
       "      <td> 0.856984</td>\n",
       "      <td> 0.972285</td>\n",
       "      <td> 0.874827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfNgram5</th>\n",
       "      <td> 0.952056</td>\n",
       "      <td> 0.541055</td>\n",
       "      <td> 0.952561</td>\n",
       "      <td> 0.556259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfPlain</th>\n",
       "      <td> 0.952056</td>\n",
       "      <td> 0.541055</td>\n",
       "      <td> 0.952561</td>\n",
       "      <td> 0.556259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords</th>\n",
       "      <td> 0.953625</td>\n",
       "      <td> 0.556091</td>\n",
       "      <td> 0.954619</td>\n",
       "      <td> 0.575570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords10k</th>\n",
       "      <td> 0.973341</td>\n",
       "      <td> 0.768068</td>\n",
       "      <td> 0.973278</td>\n",
       "      <td> 0.771631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords5k</th>\n",
       "      <td> 0.972798</td>\n",
       "      <td> 0.768918</td>\n",
       "      <td> 0.974459</td>\n",
       "      <td> 0.787072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">severe_toxic</th>\n",
       "      <th>CountNgram5</th>\n",
       "      <td> 0.988500</td>\n",
       "      <td> 0.705723</td>\n",
       "      <td> 0.987096</td>\n",
       "      <td> 0.754863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountPlain</th>\n",
       "      <td> 0.988500</td>\n",
       "      <td> 0.705723</td>\n",
       "      <td> 0.987096</td>\n",
       "      <td> 0.754863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords</th>\n",
       "      <td> 0.989295</td>\n",
       "      <td> 0.715463</td>\n",
       "      <td> 0.987946</td>\n",
       "      <td> 0.765475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords10k</th>\n",
       "      <td> 0.985218</td>\n",
       "      <td> 0.804718</td>\n",
       "      <td> 0.984697</td>\n",
       "      <td> 0.828027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords5k</th>\n",
       "      <td> 0.988500</td>\n",
       "      <td> 0.812333</td>\n",
       "      <td> 0.987096</td>\n",
       "      <td> 0.865368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfNgram5</th>\n",
       "      <td> 0.990027</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.989897</td>\n",
       "      <td> 0.499950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfPlain</th>\n",
       "      <td> 0.990027</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.989897</td>\n",
       "      <td> 0.499950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords</th>\n",
       "      <td> 0.990027</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.989932</td>\n",
       "      <td> 0.499968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords10k</th>\n",
       "      <td> 0.990027</td>\n",
       "      <td> 0.621406</td>\n",
       "      <td> 0.990362</td>\n",
       "      <td> 0.647607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords5k</th>\n",
       "      <td> 0.990382</td>\n",
       "      <td> 0.561401</td>\n",
       "      <td> 0.990854</td>\n",
       "      <td> 0.600486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">threat</th>\n",
       "      <th>CountNgram5</th>\n",
       "      <td> 0.996341</td>\n",
       "      <td> 0.518047</td>\n",
       "      <td> 0.995740</td>\n",
       "      <td> 0.524108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountPlain</th>\n",
       "      <td> 0.996341</td>\n",
       "      <td> 0.518047</td>\n",
       "      <td> 0.995740</td>\n",
       "      <td> 0.524108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords</th>\n",
       "      <td> 0.996801</td>\n",
       "      <td> 0.533050</td>\n",
       "      <td> 0.995955</td>\n",
       "      <td> 0.548921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords10k</th>\n",
       "      <td> 0.990905</td>\n",
       "      <td> 0.736914</td>\n",
       "      <td> 0.989995</td>\n",
       "      <td> 0.772637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords5k</th>\n",
       "      <td> 0.996341</td>\n",
       "      <td> 0.769115</td>\n",
       "      <td> 0.995740</td>\n",
       "      <td> 0.835632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfNgram5</th>\n",
       "      <td> 0.997177</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.996913</td>\n",
       "      <td> 0.502897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfPlain</th>\n",
       "      <td> 0.997177</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.996913</td>\n",
       "      <td> 0.502897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords</th>\n",
       "      <td> 0.997177</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.996913</td>\n",
       "      <td> 0.502897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords10k</th>\n",
       "      <td> 0.997282</td>\n",
       "      <td> 0.518519</td>\n",
       "      <td> 0.996957</td>\n",
       "      <td> 0.508733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords5k</th>\n",
       "      <td> 0.997177</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 0.996913</td>\n",
       "      <td> 0.502897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">toxic</th>\n",
       "      <th>CountNgram5</th>\n",
       "      <td> 0.947289</td>\n",
       "      <td> 0.801548</td>\n",
       "      <td> 0.951962</td>\n",
       "      <td> 0.845478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountPlain</th>\n",
       "      <td> 0.947289</td>\n",
       "      <td> 0.801548</td>\n",
       "      <td> 0.951962</td>\n",
       "      <td> 0.845478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords</th>\n",
       "      <td> 0.948606</td>\n",
       "      <td> 0.788689</td>\n",
       "      <td> 0.956096</td>\n",
       "      <td> 0.843303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords10k</th>\n",
       "      <td> 0.942334</td>\n",
       "      <td> 0.768309</td>\n",
       "      <td> 0.945339</td>\n",
       "      <td> 0.776567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountStopWords5k</th>\n",
       "      <td> 0.947289</td>\n",
       "      <td> 0.819693</td>\n",
       "      <td> 0.951962</td>\n",
       "      <td> 0.845478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfNgram5</th>\n",
       "      <td> 0.917243</td>\n",
       "      <td> 0.567728</td>\n",
       "      <td> 0.921266</td>\n",
       "      <td> 0.590688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfPlain</th>\n",
       "      <td> 0.917243</td>\n",
       "      <td> 0.567728</td>\n",
       "      <td> 0.921266</td>\n",
       "      <td> 0.590688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords</th>\n",
       "      <td> 0.920777</td>\n",
       "      <td> 0.586300</td>\n",
       "      <td> 0.925374</td>\n",
       "      <td> 0.612055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords10k</th>\n",
       "      <td> 0.944216</td>\n",
       "      <td> 0.719495</td>\n",
       "      <td> 0.945438</td>\n",
       "      <td> 0.725590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfStopWords5k</th>\n",
       "      <td> 0.948397</td>\n",
       "      <td> 0.747712</td>\n",
       "      <td> 0.951362</td>\n",
       "      <td> 0.763387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    f1dev    aucdev   f1train  auctrain\n",
       "label         set                                                      \n",
       "identity_hate CountNgram5        0.989629  0.557514  0.987937  0.600515\n",
       "              CountPlain         0.989629  0.557514  0.987937  0.600515\n",
       "              CountStopWords     0.990319  0.552641  0.989082  0.633474\n",
       "              CountStopWords10k  0.985301  0.702826  0.984393  0.724865\n",
       "              CountStopWords5k   0.989629  0.755866  0.987937  0.813041\n",
       "              TfidfNgram5        0.992055  0.500000  0.990738  0.499955\n",
       "              TfidfPlain         0.992055  0.500000  0.990738  0.499955\n",
       "              TfidfStopWords     0.992055  0.500000  0.990765  0.499968\n",
       "              TfidfStopWords10k  0.992138  0.565305  0.991337  0.579517\n",
       "              TfidfStopWords5k   0.992264  0.523600  0.991597  0.556450\n",
       "insult        CountNgram5        0.964581  0.766856  0.965510  0.813491\n",
       "              CountPlain         0.964581  0.766856  0.965510  0.813491\n",
       "              CountStopWords     0.965877  0.756472  0.968240  0.815609\n",
       "              CountStopWords10k  0.965250  0.785239  0.966871  0.794866\n",
       "              CountStopWords5k   0.964581  0.828546  0.966414  0.845151\n",
       "              TfidfNgram5        0.952893  0.514626  0.952660  0.526326\n",
       "              TfidfPlain         0.952893  0.514626  0.952660  0.526326\n",
       "              TfidfStopWords     0.953583  0.521545  0.953447  0.534579\n",
       "              TfidfStopWords10k  0.967320  0.712561  0.967873  0.723822\n",
       "              TfidfStopWords5k   0.967842  0.720007  0.969851  0.742841\n",
       "obscene       CountNgram5        0.968762  0.802596  0.967622  0.834807\n",
       "              CountPlain         0.968762  0.802596  0.967622  0.834807\n",
       "              CountStopWords     0.970916  0.799564  0.971998  0.846230\n",
       "              CountStopWords10k  0.973718  0.836659  0.974021  0.837948\n",
       "              CountStopWords5k   0.969871  0.856984  0.972285  0.874827\n",
       "              TfidfNgram5        0.952056  0.541055  0.952561  0.556259\n",
       "              TfidfPlain         0.952056  0.541055  0.952561  0.556259\n",
       "              TfidfStopWords     0.953625  0.556091  0.954619  0.575570\n",
       "              TfidfStopWords10k  0.973341  0.768068  0.973278  0.771631\n",
       "              TfidfStopWords5k   0.972798  0.768918  0.974459  0.787072\n",
       "severe_toxic  CountNgram5        0.988500  0.705723  0.987096  0.754863\n",
       "              CountPlain         0.988500  0.705723  0.987096  0.754863\n",
       "              CountStopWords     0.989295  0.715463  0.987946  0.765475\n",
       "              CountStopWords10k  0.985218  0.804718  0.984697  0.828027\n",
       "              CountStopWords5k   0.988500  0.812333  0.987096  0.865368\n",
       "              TfidfNgram5        0.990027  0.500000  0.989897  0.499950\n",
       "              TfidfPlain         0.990027  0.500000  0.989897  0.499950\n",
       "              TfidfStopWords     0.990027  0.500000  0.989932  0.499968\n",
       "              TfidfStopWords10k  0.990027  0.621406  0.990362  0.647607\n",
       "              TfidfStopWords5k   0.990382  0.561401  0.990854  0.600486\n",
       "threat        CountNgram5        0.996341  0.518047  0.995740  0.524108\n",
       "              CountPlain         0.996341  0.518047  0.995740  0.524108\n",
       "              CountStopWords     0.996801  0.533050  0.995955  0.548921\n",
       "              CountStopWords10k  0.990905  0.736914  0.989995  0.772637\n",
       "              CountStopWords5k   0.996341  0.769115  0.995740  0.835632\n",
       "              TfidfNgram5        0.997177  0.500000  0.996913  0.502897\n",
       "              TfidfPlain         0.997177  0.500000  0.996913  0.502897\n",
       "              TfidfStopWords     0.997177  0.500000  0.996913  0.502897\n",
       "              TfidfStopWords10k  0.997282  0.518519  0.996957  0.508733\n",
       "              TfidfStopWords5k   0.997177  0.500000  0.996913  0.502897\n",
       "toxic         CountNgram5        0.947289  0.801548  0.951962  0.845478\n",
       "              CountPlain         0.947289  0.801548  0.951962  0.845478\n",
       "              CountStopWords     0.948606  0.788689  0.956096  0.843303\n",
       "              CountStopWords10k  0.942334  0.768309  0.945339  0.776567\n",
       "              CountStopWords5k   0.947289  0.819693  0.951962  0.845478\n",
       "              TfidfNgram5        0.917243  0.567728  0.921266  0.590688\n",
       "              TfidfPlain         0.917243  0.567728  0.921266  0.590688\n",
       "              TfidfStopWords     0.920777  0.586300  0.925374  0.612055\n",
       "              TfidfStopWords10k  0.944216  0.719495  0.945438  0.725590\n",
       "              TfidfStopWords5k   0.948397  0.747712  0.951362  0.763387"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_all.groupby(['label','set']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
