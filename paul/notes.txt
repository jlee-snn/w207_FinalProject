- What are we being scored on?  Are they looking for us to use the techniques we saw in class or to advance
	on those?j
- Can have multiple labels, but no label for non-toxic.
	- means with 6 binary labels we can have 64 possible combinations
	- 1 of these has 100402 data points in training data
	- the other 63 have 11299 data points to share (173 instances of each)

- Do we train a classifier to find multiple labels?
	- do one at a time, train only on each label and then run through 6 classifiers?
	- create a unique combination for each and try to train on those?
- Homosexual slurs don't appear to be tagged as identity hate..actually in some cases they do,
	seems lots of identity_hate are mislabled unless bitch is identity hate
- definitely corrections required, ignored spaces misslabled here 2f21c422cced0cd7
- Are we allowed to fix mislabeled data in the training set?
- Remove all the inconsequential ones and then we can try bigram or n-gram
- We can have multiple methods for preprocessing the text and see the level of accuracy we get with each
	in each of the classifiers.  Maybe some types of preprocessing work better for some classifiers
	than others
	- Need to look up methods for normalizing text
- Normalizing text:
	- Fix spellings
	- Fix words with incorrect spacing (fore xample or forexample)
	- look at all words not in the dictionary as part of the EDA
	- do not uncapitolize
	- perhaps replace multiple punctuation marks (like !?) with a marker to indicate repeated.  So that !! and !!! match
	- Check for numbers replacing letters and fix
	- Remove all stop words, look at the resulting highest frequency words
	- think of other words that may not have come up but could indicate hate, find a corpus of hate words

BAYES
- do we need smoothing if we have a large corpus of data - suggested that if X or Y is large we don't need it
- figure out how to save a classifier once it is created

- Classifiers:
	- Regression
	- Naive Bayes
	- Random Forest
	- Neural networks
	- Nearest neighbors
Measure the accuracy of each on each of the labels, also verify if the set of incorrectly labeled data is the same, + number
of false positives
- Data sets:
	- As is
	- Corrected spellings and spacing errors
	- corrected labels (finding identity slurs where possible, can search on race, religion, politics, gender, sexual orientation)
	- unigram + combinations of multigram
- Should we do the final step of including training on the test data?  This was mentioned in one of the papers